{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial # for trials\n",
    "import numpy as np # for accuracy math\n",
    "import os # for paths\n",
    "import torch # for nn instantiation\n",
    "import torch.nn as nn # for nn objects\n",
    "import torch.nn.functional as F # for forward method\n",
    "import torch.optim as optim # for optimization\n",
    "from torch.utils.data import random_split # for train/test split\n",
    "import torchvision # for data transforms\n",
    "import torchvision.transforms as transforms # for transform methods\n",
    "from ray import tune # for trialing\n",
    "from ray.tune import CLIReporter # for trial reporting\n",
    "from ray.tune import JupyterNotebookReporter # for trial reporting\n",
    "from ray.tune.schedulers import ASHAScheduler # for trial scheduling\n",
    "from ray.tune.schedulers import HyperBandForBOHB # for trial scheduling\n",
    "from ray.tune.suggest.bohb import TuneBOHB # for trial selection/pruning\n",
    "import ConfigSpace as CS # for configuration bounds\n",
    "from collections import OrderedDict # for dynamic configuration definition\n",
    "from pathlib import Path # for OS agnostic path definition\n",
    "\n",
    "# import itertools package \n",
    "import itertools \n",
    "from itertools import combinations, combinations_with_replacement\n",
    "from itertools import product\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# allow configuration copying\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data and checkpoint locations\n",
    "p = Path('.')\n",
    "d = p / 'data'\n",
    "r = p / 'ray_results'\n",
    "l = p / 'checkpoints' / 'layers'\n",
    "n = p / 'checkpoints' / 'layers'\n",
    "\n",
    "## set number or fraction of GPUs (per training loop) you'd like to utilize, if any at all\n",
    "cpu_use = 1\n",
    "gpu_use = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the neuron configuration we want is dependent upon the number of layers we have, we need to work flatten the feature space a bit. We can reduce the high-dminesional setups to a slightly less high-dminesional string of base-n nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base                              13\n",
      "nodes_req                          4\n",
      "sparcity                        1066\n",
      "max_necc_base_value    [12, 6, 9, 0]\n",
      "nodes+_req                         3\n",
      "subsparcity                    25298\n",
      "unexplained                    75894\n",
      "sparcity_pcnt                3.73236\n",
      "subsparcity_pcnt             1151.48\n",
      "denoise_pcnt                   -1500\n",
      "complexity                      4268\n",
      "Name: 13, dtype: object \n",
      "\n",
      "base                                    6\n",
      "nodes_req                               6\n",
      "sparcity                             6946\n",
      "max_necc_base_value    [5, 0, 3, 5, 0, 2]\n",
      "nodes+_req                              5\n",
      "subsparcity                         31934\n",
      "unexplained                        159670\n",
      "sparcity_pcnt                     14.8877\n",
      "subsparcity_pcnt                  410.674\n",
      "denoise_pcnt                        -3500\n",
      "complexity                          41682\n",
      "Name: 6, dtype: object \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define feature space for hashing\n",
    "\n",
    "c_min = 3**2\n",
    "c_max = 3**5\n",
    "f_min = 2**2\n",
    "f_max = 2**6\n",
    "\n",
    "c = c_max - c_min\n",
    "f = f_max - f_min\n",
    "\n",
    "# conv = set(range(c_max)) - set(range(c_min))\n",
    "# full = set(range(f_max)) - set(range(f_min))\n",
    "conv = range(c_max)[c_min:]\n",
    "full = range(f_max)[f_min:]\n",
    "\n",
    "c_comb = list(combinations_with_replacement(conv,2))\n",
    "f_comb = []\n",
    "for layers in range(1,4):\n",
    "    f_comb += list(combinations_with_replacement(full,layers))\n",
    "\n",
    "# for conversion from dec to whatever we end up using\n",
    "# most to least significant digit\n",
    "def numberToBase(n, b):\n",
    "    if n == 0:\n",
    "        return [0]\n",
    "    digits = []\n",
    "    while n:\n",
    "        digits.append(int(n % b))\n",
    "        n //= b\n",
    "    rev = digits[::-1]\n",
    "    return rev\n",
    "\n",
    "def feature_spacing():\n",
    "    \n",
    "    # create empty list to store the \n",
    "    # combinations \n",
    "    unique_combinations = list(combinations([c_comb,f_comb],2))\n",
    "    total_uniques = len(unique_combinations)\n",
    "    total_points = total_uniques**2\n",
    "    total_cvs = len(c_comb)\n",
    "    total_fcs = len(f_comb)\n",
    "    \n",
    "#     print(total_cvs)\n",
    "#     print(total_fcs)\n",
    "    \n",
    "#     print(c_comb[np.random.randint(0,len(c_comb))])\n",
    "#     print(f_comb[np.random.randint(0,len(f_comb))])\n",
    "\n",
    "#     for ls in range(0,4):\n",
    "#         unique_combinations.append((c**2)*(f*(f+1)**ls))\n",
    "#         total_uniques += (c**2)*f*((f+1)**ls)\n",
    "#         total_fcs += f*((f+1)**ls)\n",
    "    \n",
    "#     total_uniques -= ((c**2)*f)\n",
    "#     total_points = total_uniques**2\n",
    "    \n",
    "#     print(\"number of combos: %s\" % [\"%s-fc model: %s\" % (l,v) for l,v in enumerate(unique_combinations, 1)])\n",
    "#     print(\"total uniques:\",total_uniques)\n",
    "#     print(\"number of points/indices (with sparicities/noise): %s\" % total_points)\n",
    "#     print(\"\\n\")\n",
    "    \n",
    "    columns = [\"base\",\"nodes_req\",\"sparcity\",\"sparcity_pcnt\",\"denoise_pcnt\"]\n",
    "    values = [1,total_uniques,total_points - total_uniques,(total_points - total_uniques) / total_points,0]\n",
    "#     results = {\n",
    "#         \"base\": [1],\n",
    "#         \"nodes_req\": [total_uniques],\n",
    "#         \"sparcity\": [total_points - total_uniques],\n",
    "#         \"max_necc_base_value\":[0],\n",
    "#         \"nodes+_req\": [0],\n",
    "#         \"subsparcity\": [0],\n",
    "#         \"unexplained\":[0],\n",
    "#         \"sparcity_pcnt\": [(total_points - total_uniques) / total_points * 100],\n",
    "#         \"subsparcity_pcnt\": [0],\n",
    "#         \"denoise_pcnt\":[0],\n",
    "#         \"complexity\":[0]\n",
    "#     }\n",
    "    \n",
    "    cf = []\n",
    "#     print(report.to_string())\n",
    "    for layer in [total_cvs,total_fcs]:#,total_uniques]:\n",
    "        results = {\n",
    "            \"base\": [1],\n",
    "            \"nodes_req\": [total_uniques],\n",
    "            \"sparcity\": [total_points - total_uniques],\n",
    "            \"max_necc_base_value\":[0],\n",
    "            \"nodes+_req\": [0],\n",
    "            \"subsparcity\": [0],\n",
    "            \"unexplained\":[0],\n",
    "            \"sparcity_pcnt\": [(total_points - total_uniques) / total_points * 100],\n",
    "            \"subsparcity_pcnt\": [0],\n",
    "            \"denoise_pcnt\":[0],\n",
    "            \"complexity\":[0]\n",
    "        }\n",
    "\n",
    "        report = pd.DataFrame(results)\n",
    "    \n",
    "        for base in range(2,17):\n",
    "            results[\"base\"] = [base]\n",
    "            results[\"nodes_req\"] = [math.ceil(math.log(layer,(base)))]\n",
    "            results[\"nodes+_req\"] = [math.floor(math.log(layer,(base)))]\n",
    "            \n",
    "            results[\"sparcity\"] = [base**math.ceil(math.log(layer,base)) - layer]\n",
    "            results[\"subsparcity\"] = [-(base**math.floor(math.log(layer,base)) - layer)]\n",
    "            \n",
    "            results[\"sparcity_pcnt\"] = [(base**math.ceil(math.log(layer,(base))) - base**math.log(layer,(base)))/(base**math.ceil(math.log(layer,(base))))*100]\n",
    "            results[\"subsparcity_pcnt\"] = [-((base**math.floor(math.log(layer,(base))) - base**math.log(layer,(base)))/(base**math.floor(math.log(layer,(base))))*100)]\n",
    "            \n",
    "#             results[\"max_necc_base_value\"] = [numberToBase((results[\"base\"][0]**results[\"nodes+_req\"][0]+results[\"subsparcity\"][0]),results[\"base\"][0])]\n",
    "            results[\"max_necc_base_value\"] = [numberToBase(layer,base)]\n",
    "            results[\"unexplained\"] = [(-(base**math.floor(math.log(layer,base)) - layer))*(math.floor(math.log(layer,(base))))]\n",
    "            \n",
    "            results[\"denoise_pcnt\"] = [math.floor(((total_points-(math.ceil(math.log(layer,base)))**2)/total_points)*100)]\n",
    "        \n",
    "            results[\"complexity\"] = [results[\"nodes_req\"][0]*(results[\"sparcity\"][0]+1)]\n",
    "\n",
    "            report = report.append(pd.DataFrame(results))\n",
    "            \n",
    "            \n",
    "        report.index = [x for x in range(1, len(report.values)+1)]\n",
    "#         report.set_index(range(len(report)),inplace=True)\n",
    "        report.drop([1],axis=0,inplace=True)\n",
    "#         print(\"value: %s \\n\" % layer)\n",
    "        report.sort_values([\"sparcity\",\"unexplained\",\"nodes+_req\",\"subsparcity\",\"sparcity_pcnt\",\"base\"],inplace=True)\n",
    "#         print(report)\n",
    "#         print(report.to_string(),\"\\n\")\n",
    "        \n",
    "#         print(report.max())\n",
    "#         print(report.min())\n",
    "        \n",
    "#         report_norm = (report + -1 * report.mean()) / (report.max() + -1 * report.min())\n",
    "#         print(report_norm.to_string(),\"\\n\")\n",
    "        \n",
    "        cf.append(report.iloc[0])\n",
    "    \n",
    "    return cf\n",
    "\n",
    "[print(r,\"\\n\") for r in feature_spacing()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the convolutional layers, base 9 seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\n",
    "For the linear layers, base 16 seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\n",
    "\n",
    "We can use the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bases = feature_spacing()\n",
    "\n",
    "base_c = bases[0][\"base\"]\n",
    "base_f = bases[1][\"base\"]\n",
    "\n",
    "def base_to_dec(num_list, base):\n",
    "    num_list = num_list[::-1]\n",
    "    num = 0\n",
    "    for k in range(len(num_list)):\n",
    "        dig = num_list[k]\n",
    "#         if dig.isdigit():\n",
    "#             dig = int(dig)\n",
    "        dig = int(dig)\n",
    "#         else:    #Assuming its either number or alphabet only\n",
    "#             dig = ord(dig.upper())-ord('A')+10\n",
    "        num += dig*(base**k)\n",
    "    return num\n",
    "\n",
    "def encode(config=[(24, 64),(13, 18, 41)]):\n",
    "    iconv = c_comb.index(config[0])\n",
    "    ifull = f_comb.index(config[1])\n",
    "    \n",
    "    conv_hash = numberToBase(iconv,base_c)\n",
    "    full_hash = numberToBase(ifull,base_f)\n",
    "    \n",
    "    return [conv_hash,full_hash]\n",
    "\n",
    "# print([(24, 64),(13, 18, 41)])\n",
    "# print(\"to\")\n",
    "# print(encode([(24, 64),(13, 18, 41)]))\n",
    "\n",
    "def decode(hash=([1, 7, 5, 0], [2, 0, 4, 3, 4, 4])):\n",
    "    conv = base_to_dec(hash[0], base_c)\n",
    "    full = base_to_dec(hash[1], base_f)\n",
    "\n",
    "    \n",
    "    return [c_comb[conv],f_comb[full]]\n",
    "\n",
    "\n",
    "# print([[1, 7, 5, 0], [2, 0, 4, 3, 4, 4]])\n",
    "# print(\"to\")\n",
    "# print(decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move data into sets for loading\n",
    "def load_data(data_dir=d.absolute()):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset,testset = [torchvision.datasets.CIFAR10(root=data_dir, train=is_train, download=True, transform=transform) for is_train in [True,False]]\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamically-generated nn that takes a 3-channel image and outputs a label\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_layers=[[6, 16],[120,84]]):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_convs,hidden_fcs = hidden_layers\n",
    "        print(hidden_convs)\n",
    "        print(hidden_fcs)\n",
    "        uf_input = 0\n",
    "        layer_list = OrderedDict()\n",
    "        \n",
    "        layer_list['conv1'] = nn.Conv2d(3, hidden_convs[0], 5)\n",
    "        layer_list['pool1'] = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        layer_input = layer_list['conv1'].out_channels\n",
    "        \n",
    "        for layer_num, channels in enumerate(hidden_convs[1:], 2):\n",
    "            layer_list[\"conv%s\" % layer_num]  = nn.Conv2d(layer_input, channels, 5)\n",
    "            layer_list[\"pool%s\" % layer_num] = nn.MaxPool2d(2, 2)\n",
    "            layer_input = layer_list[\"conv%s\" % layer_num].out_channels\n",
    "        \n",
    "        \n",
    "        layer_list[\"flat\"] = nn.Flatten()\n",
    "        \n",
    "        layer_list['fc1'] = nn.Linear(layer_input*5*5, hidden_fcs[0])\n",
    "        layer_list[\"relu1\"]  = nn.ReLU()\n",
    "        \n",
    "        layer_input = layer_list['fc1'].out_features\n",
    "        for (layer_num, features) in enumerate(hidden_fcs[1:], 2):\n",
    "            layer_list[\"fc%s\" % layer_num]  = nn.Linear(layer_input, features)\n",
    "            layer_list[\"relu%s\" % layer_num]  = nn.ReLU()\n",
    "            layer_input = layer_list[\"fc%s\" % layer_num].out_features\n",
    "            \n",
    "        \n",
    "        layer_list['fco'] = nn.Linear(hidden_fcs[-1], 10)\n",
    "    \n",
    "        self.layers = nn.Sequential(layer_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train nn on data\n",
    "def train_cifar(neuron_config, checkpoint_dir=None):\n",
    "    \n",
    "    data_dir=d.absolute()\n",
    "    \n",
    "    def cv_discrim(s): return 'conv_subindex_' in s\n",
    "    def fc_discrim(s): return 'full_subindex_' in s\n",
    "    cvs = [neuron_config[hp] for hp in list(filter(cv_discrim, neuron_config.keys()))]\n",
    "    fcs = [neuron_config[hp] for hp in list(filter(fc_discrim, neuron_config.keys()))]\n",
    "#     cvs = neuron_config[\"cvs\"]\n",
    "#     fcs = neuron_config[\"fcs\"]\n",
    "    \n",
    "    cfg = decode([cvs, fcs])\n",
    "    \n",
    "    net = Net(cfg)\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=neuron_config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader,valloader = [torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(neuron_config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=1) for subset in [train_subset,val_subset]]\n",
    "\n",
    "    for epoch in range(neuron_config[\"epochs\"]):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=(correct / total))\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy score\n",
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=1)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine configuration boundary for nn based on number of layers\n",
    "nodes_c = bases[0][\"nodes_req\"]\n",
    "nodes_f = bases[1][\"nodes_req\"]\n",
    "max_c = bases[0][\"max_necc_base_value\"]\n",
    "max_f = bases[1][\"max_necc_base_value\"]\n",
    "\n",
    "# def configure_neurons(num_convs,num_fcs):\n",
    "def configure_neurons():\n",
    "    config_space = CS.ConfigurationSpace()\n",
    "    \n",
    "    config_space.add_hyperparameter(\n",
    "        CS.UniformFloatHyperparameter(name=\"lr\", lower=1e-4, upper=1e-1, log=True))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"batch_size\", choices=[4, 8, 16, 32]))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"epochs\", choices=[20, 30, 40]))\n",
    "    \n",
    "#     conv_rules,full_rules = [],[]\n",
    "    conv_lims,full_lims = [],[]\n",
    "    \n",
    "    for subindex in range(nodes_c):\n",
    "        # define hyperparameter reference attributes\n",
    "        rule_name = \"conv_subindex_%s\" % subindex\n",
    "        conv_rule = CS.UniformIntegerHyperparameter(rule_name, lower=0, upper=base_c-1)\n",
    "        \n",
    "        # add hyperparameter to collections\n",
    "#         config_space.add_hyperparameter(\n",
    "#             CS.UniformIntegerHyperparameter(\"conv_subindex_%s\" % subindex, lower=0, upper=base_c-1))\n",
    "        config_space.add_hyperparameter(conv_rule)\n",
    "    \n",
    "        conv_rules = list(filter(lambda hp: \"conv_subindex_\" in hp.name, config_space.get_hyperparameters()))\n",
    "    \n",
    "        # build banlist from collections\n",
    "        rl = deepcopy(config_space)\n",
    "        rd = {}\n",
    "        for ri,rule in enumerate(conv_rules,1):\n",
    "#             print(len(conv_rules))\n",
    "#             print(max_c[ri-1])\n",
    "#             print(config_space.get_hyperparameter(rule_name).upper)\n",
    "            \n",
    "#             print(rule)\n",
    "    \n",
    "            if (len(conv_rules) == 1) & (max_c[ri-1] == config_space.get_hyperparameter(rule_name).upper):\n",
    "#                 print(\"breaking\")\n",
    "                break\n",
    "            elif ri != len(conv_rules):\n",
    "#                 rl.add_forbidden_clause(\n",
    "#                     CS.ForbiddenEqualsClause(\n",
    "# #                         config_space.get_hyperparameter(rule), \n",
    "#                         rule,\n",
    "#                         max_c[ri-1]\n",
    "#                     )\n",
    "#                 )\n",
    "                rd[rule.name] = CS.ForbiddenEqualsClause(\n",
    "#                         config_space.get_hyperparameter(rule), \n",
    "                        rule,\n",
    "                        max_c[ri-1]\n",
    "                    )\n",
    "            else:\n",
    "#                 rl.add_forbidden_clause(\n",
    "#                     CS.ForbiddenInClause(\n",
    "# #                         config_space.get_hyperparameter(rule), \n",
    "#                         rule,\n",
    "#                         range(\n",
    "#                             max_c[ri-1] + 1, \n",
    "# #                             config_space.get_hyperparameter(rule).upper + 1\n",
    "#                             rule.upper + 1\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "                rd[rule.name] = CS.ForbiddenInClause(\n",
    "#                         config_space.get_hyperparameter(rule), \n",
    "                        rule,\n",
    "                        range(\n",
    "                            max_c[ri-1] + 1, \n",
    "#                             config_space.get_hyperparameter(rule).upper + 1\n",
    "                            rule.upper + 1\n",
    "                        )\n",
    "                    )\n",
    "        \n",
    "        # package banlist for addition to config space\n",
    "#         print(rl.get_forbiddens())\n",
    "        \n",
    "        # add banlist to collection\n",
    "#         if rl.get_forbiddens():\n",
    "#             config_space.add_forbidden_clause(\n",
    "#                 CS.ForbiddenAndConjunction(\n",
    "#                     *rl.get_forbiddens()\n",
    "#                 )\n",
    "#             )\n",
    "        if rd.values():\n",
    "            config_space.add_forbidden_clause(\n",
    "                CS.ForbiddenAndConjunction(\n",
    "                    *rd.values()\n",
    "                )\n",
    "            )           \n",
    "                \n",
    "#     print(config_space.get_forbiddens())\n",
    "    \n",
    "#     for subindex in range(nodes_f):\n",
    "#         full_rules += CS.UniformIntegerHyperparameter(\"full_subindex_%s\" % subindex, lower=0, upper=base_f-1)\n",
    "# #         config_space.add_hyperparameter(\n",
    "# #             CS.UniformIntegerHyperparameter(\"full_subindex_%s\" % subindex, lower=0, upper=base_f-1))\n",
    "#         config_space.add_hyperparameter(full_rules[subindex])\n",
    "    \n",
    "    for subindex in range(nodes_f):\n",
    "        # define hyperparameter reference attributes\n",
    "        rule_name = \"full_subindex_%s\" % subindex\n",
    "        full_rule = CS.UniformIntegerHyperparameter(rule_name, lower=0, upper=base_f-1)\n",
    "        \n",
    "        # add hyperparameter to collections\n",
    "#         config_space.add_hyperparameter(\n",
    "#             CS.UniformIntegerHyperparameter(\"conv_subindex_%s\" % subindex, lower=0, upper=base_c-1))\n",
    "        config_space.add_hyperparameter(full_rule)\n",
    "    \n",
    "        full_rules = list(filter(lambda hp: \"full_subindex_\" in hp.name, config_space.get_hyperparameters()))\n",
    "    \n",
    "        # build banlist from collections\n",
    "        rl = deepcopy(config_space)\n",
    "        rd = {}\n",
    "        for ri,rule in enumerate(full_rules,1):\n",
    "#             print(len(conv_rules))\n",
    "#             print(max_c[ri-1])\n",
    "#             print(config_space.get_hyperparameter(rule_name).upper)\n",
    "            \n",
    "#             print(rule)\n",
    "    \n",
    "#             if (len(full_rules) == 1) & (max_f[ri-1] == config_space.get_hyperparameter(rule_name).upper):\n",
    "            if (len(full_rules) == 1) & (max_f[ri-1] == config_space.get_hyperparameter(rule_name).upper):\n",
    "#                 print(\"breaking\")\n",
    "                break\n",
    "            elif ri != len(full_rules):\n",
    "#                 rl.add_forbidden_clause(\n",
    "#                     CS.ForbiddenEqualsClause(\n",
    "# #                         config_space.get_hyperparameter(rule), \n",
    "#                         rule,\n",
    "#                         max_c[ri-1]\n",
    "#                     )\n",
    "#                 )\n",
    "                rd[rule.name] = CS.ForbiddenEqualsClause(\n",
    "#                         config_space.get_hyperparameter(rule), \n",
    "                        rule,\n",
    "                        max_f[ri-1]\n",
    "                    )\n",
    "            else:\n",
    "#                 rl.add_forbidden_clause(\n",
    "#                     CS.ForbiddenInClause(\n",
    "# #                         config_space.get_hyperparameter(rule), \n",
    "#                         rule,\n",
    "#                         range(\n",
    "#                             max_c[ri-1] + 1, \n",
    "# #                             config_space.get_hyperparameter(rule).upper + 1\n",
    "#                             rule.upper + 1\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "                rd[rule.name] = CS.ForbiddenInClause(\n",
    "#                         config_space.get_hyperparameter(rule), \n",
    "                        rule,\n",
    "                        range(\n",
    "                            max_f[ri-1] + 1, \n",
    "#                             config_space.get_hyperparameter(rule).upper + 1\n",
    "                            rule.upper + 1\n",
    "                        )\n",
    "                    )\n",
    "        \n",
    "        # package banlist for addition to config space\n",
    "#         print(rl.get_forbiddens())\n",
    "        \n",
    "        # add banlist to collection\n",
    "#         if rl.get_forbiddens():\n",
    "#             config_space.add_forbidden_clause(\n",
    "#                 CS.ForbiddenAndConjunction(\n",
    "#                     *rl.get_forbiddens()\n",
    "#                 )\n",
    "#             )\n",
    "        if rd.values():\n",
    "            config_space.add_forbidden_clause(\n",
    "                CS.ForbiddenAndConjunction(\n",
    "                    *rd.values()\n",
    "                )\n",
    "            )           \n",
    "                \n",
    "#     print(config_space.get_forbiddens())\n",
    "        \n",
    "#     #Define max subindices\n",
    "    \n",
    "#     max_conv_index = [[CS.ForbiddenEqualsClause(conv_rules[0],max_c[0] + 1)]]\n",
    "#     max_full_index = [[CS.ForbiddenEqualsClause(full_rules[0],max_f[0] + 1)]]\n",
    "    \n",
    "#     for subindex,max_necc in enumerate(1,max_c):\n",
    "#         banlist = [CS.ForbiddenEqualsClause(max_conv_index[0][0].hyperparameter,max_conv_index[0][0].value - 1)]\n",
    "#         for fbd in max_conv_index:\n",
    "# #             banlist += CS.ForbiddenEqualsClause(fbd.hyperparameter,fbd.value - 1)\n",
    "#             banlist += CS.ForbiddenEqualsClause(conv_rules[subindex],max_necc + 1)\n",
    "#         max_conv_index += CS.ForbiddenEqualsClause(conv_rules[subindex],max_necc + 1)\n",
    "    \n",
    "#     for hidden in range(2):\n",
    "#         config_space.add_hyperparameter(\n",
    "#             CS.UniformIntegerHyperparameter(\"cv%s\" % hidden, lower=3, upper=3**4))\n",
    "    \n",
    "#     for hidden in range(num_fcs):\n",
    "#         config_space.add_hyperparameter(\n",
    "#             CS.UniformIntegerHyperparameter(\"fc%s\" % hidden, lower=2**2, upper=2**4))\n",
    "        \n",
    "    return config_space\n",
    "\n",
    "def build_forbidden(max_digits=[12, 6, 9, 0],conf=None):\n",
    "    # list that holds all clauses for \"And\"-ing\n",
    "    full_forbidden = []\n",
    "    \n",
    "    # add each max possible index combination\n",
    "    for digit in range(1,len(max_digits)):\n",
    "        forbidden = []        \n",
    "        \n",
    "        max_slice = max_digits[:digit]\n",
    "        conf_slice = conf[:digit]\n",
    "        forbidden.append(build_subforbidden(max_slice,conf_slice))\n",
    "        \n",
    "    full_forbidden.append(forbidden)\n",
    "        \n",
    "    return CS.ForbiddenAndConjunction(full_forbidden)\n",
    "    \n",
    "    \n",
    "def build_subforbidden(ceiling=None,articles=None):\n",
    "    # list that holds index combination ceiling\n",
    "    sub_forbidden = {}\n",
    "    sf = CS.ConfigurationSpace()\n",
    "#     sub_forbidden = CS.ForbiddenAndConjunction()\n",
    "    \n",
    "    # collect absolute max digit(s) and soft max digit\n",
    "    reqs,cap = ceiling[:-1],ceiling[-1]\n",
    "    \n",
    "    # create rule disallowing any numbers higher than respective max\n",
    "    for sub,req in enumerate(reqs,1):\n",
    "        sub_forbidden[str(sub-1)] = CS.ForbiddenEqualsClause(articles[sub-1],reqs[sub-1])\n",
    "        sf.add_forbidden_clause(CS.ForbiddenEqualsClause(articles[sub-1],reqs[sub-1]))\n",
    "    sub_forbidden[str(len(reqs))] = CS.ForbiddenInClause(articles[-1],range(cap+1, articles[-1].upper+1))\n",
    "    \n",
    "#     print(sf)\n",
    "    \n",
    "    return CS.ForbiddenAndConjunction(sf)\n",
    "#     return sub_forbidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    batch_size, Type: Categorical, Choices: {4, 8, 16, 32}, Default: 4\n",
      "    conv_subindex_0, Type: UniformInteger, Range: [0, 12], Default: 6\n",
      "    conv_subindex_1, Type: UniformInteger, Range: [0, 12], Default: 6\n",
      "    conv_subindex_2, Type: UniformInteger, Range: [0, 12], Default: 6\n",
      "    conv_subindex_3, Type: UniformInteger, Range: [0, 12], Default: 6\n",
      "    epochs, Type: Categorical, Choices: {20, 30, 40}, Default: 20\n",
      "    full_subindex_0, Type: UniformInteger, Range: [0, 5], Default: 2\n",
      "    full_subindex_1, Type: UniformInteger, Range: [0, 5], Default: 2\n",
      "    full_subindex_2, Type: UniformInteger, Range: [0, 5], Default: 2\n",
      "    full_subindex_3, Type: UniformInteger, Range: [0, 5], Default: 2\n",
      "    full_subindex_4, Type: UniformInteger, Range: [0, 5], Default: 2\n",
      "    full_subindex_5, Type: UniformInteger, Range: [0, 5], Default: 2\n",
      "    lr, Type: UniformFloat, Range: [0.0001, 0.1], Default: 0.0031622777, on log-scale\n",
      "  Forbidden Clauses:\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 in {7, 8, 9, 10, 11, 12})\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 == 6 && Forbidden: conv_subindex_2 in {10, 11, 12})\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 == 6 && Forbidden: conv_subindex_2 == 9 && Forbidden: conv_subindex_3 in {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12})\n",
      "    (Forbidden: full_subindex_0 == 5 && Forbidden: full_subindex_1 in {1, 2, 3, 4, 5})\n",
      "    (Forbidden: full_subindex_0 == 5 && Forbidden: full_subindex_1 == 0 && Forbidden: full_subindex_2 in {4, 5})\n",
      "    (Forbidden: full_subindex_0 == 5 && Forbidden: full_subindex_1 == 0 && Forbidden: full_subindex_2 == 3 && Forbidden: full_subindex_3 in {})\n",
      "    (Forbidden: full_subindex_0 == 5 && Forbidden: full_subindex_1 == 0 && Forbidden: full_subindex_2 == 3 && Forbidden: full_subindex_3 == 5 && Forbidden: full_subindex_4 in {1, 2, 3, 4, 5})\n",
      "    (Forbidden: full_subindex_0 == 5 && Forbidden: full_subindex_1 == 0 && Forbidden: full_subindex_2 == 3 && Forbidden: full_subindex_3 == 5 && Forbidden: full_subindex_4 == 0 && Forbidden: full_subindex_5 in {3, 4, 5})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neuron_config_space = configure_neurons()\n",
    "print(neuron_config_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sf = {\n",
    "    \"c\": [12,6,9,0],\n",
    "    \"a\": [\n",
    "        CS.UniformIntegerHyperparameter(name=\"conv_subindex_1\", lower=0, upper=12),\n",
    "        CS.UniformIntegerHyperparameter(name=\"conv_subindex_2\", lower=0, upper=12),\n",
    "        CS.UniformIntegerHyperparameter(name=\"conv_subindex_3\", lower=0, upper=12),\n",
    "        CS.UniformIntegerHyperparameter(name=\"conv_subindex_4\", lower=0, upper=12)\n",
    "    ]\n",
    "}\n",
    "print(build_subforbidden(sf[\"c\"],sf[\"a\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform neuron configuration trials\n",
    "# def search_neurons(layer_config, checkpoint_dir=None):\n",
    "def search_neurons(checkpoint_dir=None):\n",
    "    num_samples=40\n",
    "    max_num_epochs=40\n",
    "    gpus_per_trial=1\n",
    "    \n",
    "#     print(layer_config)\n",
    "    \n",
    "#     neuron_config_space = configure_neurons(layer_config[\"num_convs\"], layer_config[\"num_fcs\"])\n",
    "    neuron_config_space = configure_neurons()\n",
    "    \n",
    "    experiment_metrics = dict(metric=\"accuracy\", mode=\"max\")\n",
    "    \n",
    "    #pre-load data to avoid races\n",
    "    load_data()\n",
    "    \n",
    "    scheduler = HyperBandForBOHB(\n",
    "#         metric=\"loss\",\n",
    "#         mode=\"min\",\n",
    "        max_t=20,\n",
    "        reduction_factor=2,\n",
    "        **experiment_metrics)\n",
    "    search = TuneBOHB(\n",
    "        neuron_config_space,\n",
    "        max_concurrent=8,\n",
    "#         metric=\"loss\",\n",
    "#         mode=\"min\",\n",
    "        **experiment_metrics)\n",
    "    reporter = JupyterNotebookReporter(\n",
    "        overwrite=True,\n",
    "#         parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\", \"epochs\"],\n",
    "        parameter_columns=neuron_config_space.get_hyperparameter_names(),\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_cifar),\n",
    "        verbose=2,\n",
    "        name=\"neurons\",\n",
    "        local_dir=r.absolute(),\n",
    "        resources_per_trial={\"cpu\": cpu_use, \"gpu\": gpu_use},\n",
    "        max_failures=3,\n",
    "#         config=neuron_config_space,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    \n",
    "    def cv_discrim(s): return 'conv_subindex_' in s\n",
    "    def fc_discrim(s): return 'full_subindex_' in s\n",
    "    best_cvs = [best_trial.config[hp] for hp in list(filter(cv_discrim, best_trial.config.keys()))]\n",
    "    best_fcs = [best_trial.config[hp] for hp in list(filter(fc_discrim, best_trial.config.keys()))]\n",
    "# #     best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
    "\n",
    "    cfg = decode([best_cvs, best_fcs])\n",
    "    best_trained_model = Net(cfg)\n",
    "    \n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    \n",
    "    if checkpoint_dir != None:\n",
    "        tune.report(accuracy=test_acc)\n",
    "    \n",
    "#     with tune.checkpoint_dir(\"nodes\") as checkpoint_dir:\n",
    "#         path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "#         torch.save(best_trained_model.state_dict(), path)\n",
    "    \n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "    \n",
    "    return best_trained_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# perform layer count trials\n",
    "def search_layers(num_samples=10, max_num_epochs=10, gpus_per_trial=0):\n",
    "    data_dir=d.absolute()\n",
    "    load_data(data_dir)\n",
    "    layer_config_space = CS.ConfigurationSpace()\n",
    "\n",
    "    layer_config_space.add_hyperparameter(\n",
    "        CS.Constant(\"num_convs\", value=2))\n",
    "    layer_config_space.add_hyperparameter(\n",
    "        CS.UniformIntegerHyperparameter(\"num_fcs\", lower=2, upper=2**2))\n",
    "    \n",
    "    experiment_metrics = dict(metric=\"accuracy\", mode=\"max\")\n",
    "    \n",
    "\n",
    "    scheduler = HyperBandForBOHB(\n",
    "        max_t=max_num_epochs,\n",
    "        reduction_factor=2,\n",
    "        **experiment_metrics)\n",
    "    search = TuneBOHB(\n",
    "        layer_config_space,\n",
    "        max_concurrent=4,\n",
    "        **experiment_metrics)\n",
    "    reporter = CLIReporter(\n",
    "#         overwrite=True,\n",
    "        parameter_columns=layer_config_space.get_hyperparameter_names(),\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(search_neurons),\n",
    "        verbose=2,\n",
    "        name=\"layers\",\n",
    "        local_dir=r.absolute(),\n",
    "#         config=layer_config_space,\n",
    "        resources_per_trial={\"gpu\": gpus_per_trial},\n",
    "        max_failures=3,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = Net([best_trial.config[\"num_convs\"], best_trial.config[\"num_fcs\"]])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"),map_location=torch.device('cpu'))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "    \n",
    "    return best_trained_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform test\n",
    "model = Net()\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    model = search_layers(num_samples=10, max_num_epochs=10, gpus_per_trial=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource usage can be viewed at port 127.0.0.1:8265 or higher\n"
     ]
    }
   ],
   "source": [
    "print(\"Resource usage can be viewed at port 127.0.0.1:8265 or higher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/31.3 GiB<br>Using HyperBand: num_stopped=30 total_brackets=5\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=1, Milestone (r)=12, completed=100.0%): {TERMINATED: 16} \n",
       "  Bracket(Max Size (n)=2, Milestone (r)=12, completed=100.0%): {TERMINATED: 10} \n",
       "  Bracket(Max Size (n)=2, Milestone (r)=10, completed=100.0%): {TERMINATED: 7} \n",
       "  Bracket(Max Size (n)=3, Milestone (r)=10, completed=100.0%): {TERMINATED: 5} \n",
       "  Bracket(Max Size (n)=5, Milestone (r)=20, completed=100.0%): {TERMINATED: 2} <br>Resources requested: 0/8 CPUs, 0.0/2 GPUs, 0.0/17.29 GiB heap, 0.0/5.96 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /home/grottesco/Source/CIFAR-Trainer/ray_results/neurons<br>Number of trials: 40/40 (40 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_subindex_0</th><th style=\"text-align: right;\">  conv_subindex_1</th><th style=\"text-align: right;\">  conv_subindex_2</th><th style=\"text-align: right;\">  conv_subindex_3</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  full_subindex_0</th><th style=\"text-align: right;\">  full_subindex_1</th><th style=\"text-align: right;\">  full_subindex_2</th><th style=\"text-align: right;\">  full_subindex_3</th><th style=\"text-align: right;\">  full_subindex_4</th><th style=\"text-align: right;\">  full_subindex_5</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">      loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DEFAULT_8684b754</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">0.00534174 </td><td style=\"text-align: right;\">  2.30667 </td><td style=\"text-align: right;\">  0.101075</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_868de63a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">0.00978275 </td><td style=\"text-align: right;\">  2.30563 </td><td style=\"text-align: right;\">  0.10035 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_8692a53a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">0.000863218</td><td style=\"text-align: right;\">  0.731154</td><td style=\"text-align: right;\">  0.73925 </td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>DEFAULT_86978b04</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.0252347  </td><td style=\"text-align: right;\">  1.58772 </td><td style=\"text-align: right;\">  0.435325</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_869ca652</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.0656635  </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">  0.10095 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_86ab91ee</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.0159174  </td><td style=\"text-align: right;\">  2.30479 </td><td style=\"text-align: right;\">  0.101325</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_86b0beda</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">0.000139136</td><td style=\"text-align: right;\">  2.29669 </td><td style=\"text-align: right;\">  0.105175</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_86b63e78</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.0616487  </td><td style=\"text-align: right;\">  2.32009 </td><td style=\"text-align: right;\">  0.10065 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_9c0ece16</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">0.00629427 </td><td style=\"text-align: right;\">  1.10687 </td><td style=\"text-align: right;\">  0.63645 </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_9e09e872</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">0.0112515  </td><td style=\"text-align: right;\">  2.31555 </td><td style=\"text-align: right;\">  0.09915 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_9e4e3e96</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">0.000923857</td><td style=\"text-align: right;\">  1.40963 </td><td style=\"text-align: right;\">  0.48865 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_abca96c8</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.000123362</td><td style=\"text-align: right;\">  2.28195 </td><td style=\"text-align: right;\">  0.1463  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_ac5de054</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.000273204</td><td style=\"text-align: right;\">  1.42591 </td><td style=\"text-align: right;\">  0.47725 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_b47522c0</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">0.000560694</td><td style=\"text-align: right;\">  2.03657 </td><td style=\"text-align: right;\">  0.26225 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_b6318298</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">0.00196541 </td><td style=\"text-align: right;\">  0.504899</td><td style=\"text-align: right;\">  0.82515 </td><td style=\"text-align: right;\">                  12</td></tr>\n",
       "<tr><td>DEFAULT_b9524ec6</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">0.000929586</td><td style=\"text-align: right;\">  1.12463 </td><td style=\"text-align: right;\">  0.5967  </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_c5e5d360</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.0834468  </td><td style=\"text-align: right;\">  2.31335 </td><td style=\"text-align: right;\">  0.099825</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_c8f8bf68</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">0.000467443</td><td style=\"text-align: right;\">  0.722224</td><td style=\"text-align: right;\">  0.749275</td><td style=\"text-align: right;\">                  12</td></tr>\n",
       "<tr><td>DEFAULT_cffb7de6</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">0.000208814</td><td style=\"text-align: right;\">  1.20379 </td><td style=\"text-align: right;\">  0.566525</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_d728c312</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">0.00137206 </td><td style=\"text-align: right;\">  0.508817</td><td style=\"text-align: right;\">  0.823975</td><td style=\"text-align: right;\">                  12</td></tr>\n",
       "<tr><td>DEFAULT_dc4d4106</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">0.00192609 </td><td style=\"text-align: right;\">  0.97747 </td><td style=\"text-align: right;\">  0.654425</td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>DEFAULT_dc6e7a56</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.00932702 </td><td style=\"text-align: right;\">  2.30871 </td><td style=\"text-align: right;\">  0.099575</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_e84c811a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.0753272  </td><td style=\"text-align: right;\">  2.31151 </td><td style=\"text-align: right;\">  0.0998  </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_f3a02490</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">0.0618308  </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">  0.09985 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_36012672</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">0.000667116</td><td style=\"text-align: right;\">  1.43022 </td><td style=\"text-align: right;\">  0.474225</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_3bc81bec</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.000134522</td><td style=\"text-align: right;\">  1.89373 </td><td style=\"text-align: right;\">  0.310525</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_3ccdf818</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.0139777  </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">  0.09995 </td><td style=\"text-align: right;\">                   5</td></tr>\n",
       "<tr><td>DEFAULT_47c6991e</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">0.000103052</td><td style=\"text-align: right;\">  1.08969 </td><td style=\"text-align: right;\">  0.607525</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_4cc10ecc</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.00284243 </td><td style=\"text-align: right;\">  1.44297 </td><td style=\"text-align: right;\">  0.48785 </td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_55bcffea</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">0.000279356</td><td style=\"text-align: right;\">  1.18637 </td><td style=\"text-align: right;\">  0.570575</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_5d4bfe78</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">0.000355518</td><td style=\"text-align: right;\">  1.93916 </td><td style=\"text-align: right;\">  0.286125</td><td style=\"text-align: right;\">                   5</td></tr>\n",
       "<tr><td>DEFAULT_69c1fe50</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">0.000147916</td><td style=\"text-align: right;\">  1.10581 </td><td style=\"text-align: right;\">  0.603375</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_63a3ec4e</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.0423611  </td><td style=\"text-align: right;\">  2.30754 </td><td style=\"text-align: right;\">  0.101225</td><td style=\"text-align: right;\">                   5</td></tr>\n",
       "<tr><td>DEFAULT_641c1656</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.0263542  </td><td style=\"text-align: right;\">  2.31136 </td><td style=\"text-align: right;\">  0.100075</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_6bc9cec0</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">0.00323608 </td><td style=\"text-align: right;\">  2.3034  </td><td style=\"text-align: right;\">  0.100375</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_721930ea</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.000349325</td><td style=\"text-align: right;\">  1.1477  </td><td style=\"text-align: right;\">  0.58775 </td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_20db1d5a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.0360562  </td><td style=\"text-align: right;\">  2.30518 </td><td style=\"text-align: right;\">  0.09975 </td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_452e733c</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">0.00213599 </td><td style=\"text-align: right;\">  0.789399</td><td style=\"text-align: right;\">  0.722175</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_56b44eec</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">0.00117704 </td><td style=\"text-align: right;\">  0.596035</td><td style=\"text-align: right;\">  0.7845  </td><td style=\"text-align: right;\">                  20</td></tr>\n",
       "<tr><td>DEFAULT_25e0ff44</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">0.000288031</td><td style=\"text-align: right;\">  0.93083 </td><td style=\"text-align: right;\">  0.6731  </td><td style=\"text-align: right;\">                  20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-28 00:18:32,184\tINFO tune.py:439 -- Total run time: 1977.78 seconds (1976.37 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'batch_size': 32, 'conv_subindex_0': 10, 'conv_subindex_1': 0, 'conv_subindex_2': 4, 'conv_subindex_3': 1, 'epochs': 20, 'full_subindex_0': 5, 'full_subindex_1': 0, 'full_subindex_2': 0, 'full_subindex_3': 3, 'full_subindex_4': 1, 'full_subindex_5': 5, 'lr': 0.001965405713503036}\n",
      "Best trial final validation loss: 0.504899407839775\n",
      "Best trial final validation accuracy: 0.82515\n",
      "(138, 231)\n",
      "(48, 56, 61)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Best trial test set accuracy: 0.6765\n"
     ]
    }
   ],
   "source": [
    "# layer_config_space = {}\n",
    "\n",
    "# # for hp in [\"num_convs\",\"num_fcs\"]:\n",
    "# #     layer_config_space[hp] = np.random.randint(2,2**3)\n",
    "# # layer_config_space[\"num_convs\"] = np.random.randint(2,3)\n",
    "# layer_config_space[\"num_convs\"] = 2\n",
    "# layer_config_space[\"num_fcs\"] = np.random.randint(2,2**2)\n",
    "\n",
    "# # cpu_use = 1\n",
    "# # gpu_use = 0\n",
    "# # data_dir = os.path.abspath(\"/home/grottesco/Source/RayTuneTut/data/\")\n",
    "# # checkpoint_dir = os.path.abspath(\"/home/grottesco/Source/RayTuneTut/checkpoints\")\n",
    "# print(\"Resource usage can be viewed at 127.0.0.1:8265\")\n",
    "    \n",
    "model = search_neurons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.conv1.weight \n",
      " 138\n",
      "layers.conv1.bias \n",
      " 138\n",
      "layers.conv2.weight \n",
      " 231\n",
      "layers.conv2.bias \n",
      " 231\n",
      "layers.fc1.weight \n",
      " 48\n",
      "layers.fc1.bias \n",
      " 48\n",
      "layers.fc2.weight \n",
      " 56\n",
      "layers.fc2.bias \n",
      " 56\n",
      "layers.fc3.weight \n",
      " 61\n",
      "layers.fc3.bias \n",
      " 61\n",
      "layers.fco.weight \n",
      " 10\n",
      "layers.fco.bias \n",
      " 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(k,\"\\n\",model[k].shape[0]) for k in model.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('layers.conv1.weight', tensor([[[[-0.0005, -0.1587, -0.0468, -0.0604,  0.0033],\n",
      "          [ 0.1313, -0.1065, -0.1142,  0.0591, -0.0319],\n",
      "          [ 0.0850,  0.1069, -0.1066,  0.0757,  0.1074],\n",
      "          [-0.0508,  0.1567, -0.0740,  0.0991, -0.0686],\n",
      "          [ 0.0005,  0.0140,  0.1365, -0.0556,  0.1351]],\n",
      "\n",
      "         [[ 0.0934, -0.1193,  0.0927,  0.0950, -0.0800],\n",
      "          [-0.0430, -0.0455,  0.0275, -0.0525, -0.0477],\n",
      "          [-0.0141, -0.0211, -0.0807,  0.0368, -0.0052],\n",
      "          [-0.0770,  0.0901,  0.1030, -0.0928, -0.0396],\n",
      "          [-0.1674, -0.0316,  0.0514, -0.0252,  0.0349]],\n",
      "\n",
      "         [[ 0.0723, -0.0440, -0.0361,  0.1443, -0.1108],\n",
      "          [ 0.1614, -0.0173,  0.0392,  0.0030, -0.0230],\n",
      "          [ 0.0031,  0.1087, -0.0266,  0.0539, -0.1212],\n",
      "          [-0.0009, -0.0095, -0.0177, -0.0017,  0.0381],\n",
      "          [-0.0741, -0.0290,  0.1046,  0.0680, -0.1052]]],\n",
      "\n",
      "\n",
      "        [[[-0.0806, -0.0905, -0.0799,  0.0242,  0.0875],\n",
      "          [-0.1311, -0.0396,  0.1189, -0.0139, -0.0957],\n",
      "          [ 0.2120, -0.1441, -0.1358,  0.0837, -0.0943],\n",
      "          [ 0.1371,  0.1555, -0.1268, -0.1182,  0.0627],\n",
      "          [-0.1356,  0.0321,  0.1062, -0.0367, -0.0677]],\n",
      "\n",
      "         [[ 0.0059,  0.0454,  0.0188,  0.0695,  0.1280],\n",
      "          [-0.1556, -0.0305,  0.1691, -0.0110,  0.0328],\n",
      "          [ 0.1909,  0.0709, -0.0782,  0.0286, -0.0675],\n",
      "          [ 0.1016,  0.1129, -0.0442,  0.0740, -0.0287],\n",
      "          [-0.2118, -0.0703,  0.1395,  0.1231,  0.0571]],\n",
      "\n",
      "         [[-0.0342, -0.1304, -0.0942,  0.0746,  0.0862],\n",
      "          [-0.0444,  0.0273,  0.1416, -0.0510, -0.0058],\n",
      "          [ 0.1927, -0.0855, -0.1156, -0.1214,  0.0668],\n",
      "          [ 0.0294,  0.0504, -0.1202, -0.1152, -0.0937],\n",
      "          [-0.1880, -0.0024,  0.2001, -0.0366, -0.0562]]],\n",
      "\n",
      "\n",
      "        [[[-0.0810,  0.0394,  0.0324,  0.0210,  0.0434],\n",
      "          [-0.0425, -0.0060,  0.0427,  0.0220,  0.0164],\n",
      "          [ 0.0129, -0.0648,  0.1351, -0.0440,  0.0483],\n",
      "          [ 0.0985, -0.1747,  0.1176,  0.0094, -0.0192],\n",
      "          [ 0.1310, -0.0421, -0.1148, -0.0871,  0.1226]],\n",
      "\n",
      "         [[-0.0247,  0.0214,  0.0393, -0.1027,  0.0343],\n",
      "          [-0.1101,  0.0703,  0.0883,  0.0615, -0.0566],\n",
      "          [-0.0529, -0.1040, -0.0070, -0.0095,  0.0042],\n",
      "          [-0.0860, -0.0508,  0.0769, -0.0639,  0.0416],\n",
      "          [ 0.1188, -0.1148, -0.1029, -0.0158,  0.1310]],\n",
      "\n",
      "         [[ 0.0438, -0.0821,  0.1275,  0.0797, -0.1169],\n",
      "          [ 0.0609, -0.0764,  0.0019,  0.0557, -0.0877],\n",
      "          [-0.0009, -0.0654,  0.1693, -0.0410,  0.0356],\n",
      "          [-0.0596, -0.1248,  0.1059,  0.0003,  0.1151],\n",
      "          [-0.0759, -0.0663,  0.0623, -0.0354,  0.1231]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2284,  0.1407,  0.0274, -0.0543, -0.1323],\n",
      "          [ 0.0785,  0.0601, -0.0589, -0.1439,  0.0629],\n",
      "          [ 0.0719,  0.0268, -0.0878,  0.0271, -0.1445],\n",
      "          [ 0.0526,  0.1321, -0.0809, -0.0353, -0.0291],\n",
      "          [ 0.1151, -0.0589,  0.0388, -0.1027, -0.1591]],\n",
      "\n",
      "         [[-0.0335, -0.0205, -0.0221, -0.0137,  0.0737],\n",
      "          [-0.0538, -0.0487,  0.1110,  0.0063, -0.0681],\n",
      "          [-0.0995, -0.0847, -0.0734,  0.0116,  0.0542],\n",
      "          [-0.1297, -0.0622, -0.0100,  0.0887,  0.1067],\n",
      "          [-0.0972, -0.0364, -0.0431, -0.0582,  0.1176]],\n",
      "\n",
      "         [[-0.1012, -0.0861, -0.0357, -0.0487, -0.0687],\n",
      "          [ 0.0063, -0.1424,  0.0699,  0.1477, -0.0170],\n",
      "          [-0.1252,  0.0415,  0.0356,  0.0605,  0.1576],\n",
      "          [-0.0908,  0.0356, -0.0498,  0.0499,  0.1634],\n",
      "          [ 0.0350,  0.0322,  0.0449, -0.0631,  0.1591]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0204, -0.1157, -0.0425,  0.0539,  0.0773],\n",
      "          [-0.0361, -0.0687,  0.0188, -0.1313, -0.0894],\n",
      "          [-0.1010,  0.0239, -0.0627, -0.0741, -0.0793],\n",
      "          [ 0.0296, -0.1216, -0.0972,  0.1511,  0.1199],\n",
      "          [ 0.0434,  0.1565,  0.1808, -0.0043,  0.1122]],\n",
      "\n",
      "         [[-0.0626, -0.0303,  0.1293,  0.0835,  0.0355],\n",
      "          [ 0.1092,  0.0135, -0.1257, -0.0461, -0.0186],\n",
      "          [ 0.0978, -0.0256,  0.0142, -0.1354, -0.1292],\n",
      "          [-0.0916, -0.0725, -0.0528, -0.0367, -0.0138],\n",
      "          [ 0.0939,  0.1342,  0.0666,  0.1633, -0.0535]],\n",
      "\n",
      "         [[ 0.0769,  0.0025, -0.0932,  0.0521,  0.0269],\n",
      "          [ 0.0170,  0.1058, -0.0630, -0.1035,  0.0314],\n",
      "          [-0.0184,  0.0441, -0.0362, -0.0211, -0.0168],\n",
      "          [-0.1341, -0.0427,  0.0670, -0.0299, -0.0134],\n",
      "          [ 0.0229,  0.0755,  0.0876,  0.0793,  0.0389]]],\n",
      "\n",
      "\n",
      "        [[[-0.0482,  0.0276, -0.0610, -0.0622,  0.0288],\n",
      "          [ 0.0117, -0.0370,  0.1097,  0.0282, -0.0443],\n",
      "          [ 0.0169, -0.0499,  0.0444, -0.0767,  0.0146],\n",
      "          [-0.0593, -0.1643, -0.0324,  0.1022,  0.1374],\n",
      "          [ 0.0879,  0.0988,  0.0253, -0.0624,  0.0236]],\n",
      "\n",
      "         [[ 0.0434,  0.0648,  0.0024, -0.0241, -0.1090],\n",
      "          [ 0.1135,  0.0754, -0.0631, -0.1859, -0.1353],\n",
      "          [ 0.0418,  0.0182, -0.1111,  0.0835, -0.0041],\n",
      "          [-0.0741, -0.0743, -0.1007,  0.1610,  0.0781],\n",
      "          [-0.0964, -0.0011,  0.0370, -0.1097, -0.0039]],\n",
      "\n",
      "         [[-0.0551, -0.0486,  0.0849,  0.1044, -0.0965],\n",
      "          [ 0.0650,  0.1035,  0.1030, -0.1340,  0.0320],\n",
      "          [-0.0110,  0.0015, -0.0245,  0.1304, -0.0714],\n",
      "          [-0.1512, -0.1675, -0.0326,  0.1952,  0.1894],\n",
      "          [-0.0567,  0.0196, -0.0084, -0.0566,  0.1211]]]], device='cuda:0')), ('layers.conv1.bias', tensor([-4.5970e-02, -6.2890e-02, -6.4969e-02, -1.4048e-01, -3.3962e-02,\n",
      "        -4.5693e-02, -9.0808e-02, -1.7240e-01,  9.4599e-05, -1.5970e-01,\n",
      "        -1.5574e-01, -9.0205e-02, -9.6073e-02, -1.1345e-01, -1.1023e-02,\n",
      "        -9.8972e-02, -1.0928e-01, -1.8758e-01, -9.2531e-02,  6.0117e-03,\n",
      "        -1.1160e-01, -1.4672e-01, -1.8498e-01, -8.5734e-02, -8.1097e-02,\n",
      "         4.4161e-02, -2.0354e-01, -1.3610e-01, -3.4172e-03, -1.1942e-01,\n",
      "        -5.9122e-02, -1.2868e-01, -5.7651e-02, -1.1365e-01, -1.1405e-01,\n",
      "        -4.2484e-02, -1.1543e-01, -1.8820e-02, -1.2978e-01, -8.9862e-02,\n",
      "        -4.1856e-02, -5.7633e-02, -2.4362e-02,  1.9417e-02, -5.4969e-02,\n",
      "        -1.3927e-01, -1.9764e-01, -9.4165e-02,  1.3554e-02, -5.0965e-02,\n",
      "        -2.0075e-01, -4.5819e-03, -9.7311e-03, -4.2055e-02, -1.8572e-01,\n",
      "        -3.7088e-02, -8.9161e-02, -3.2132e-02, -1.3546e-01,  1.1758e-02,\n",
      "        -2.3796e-01, -1.3678e-01, -1.1378e-01, -8.9461e-02, -6.7954e-02,\n",
      "        -1.6989e-01, -9.3485e-02, -5.8001e-02, -6.0091e-02, -6.7864e-02,\n",
      "        -8.8697e-02, -1.8051e-01, -4.7173e-02, -6.9223e-02, -9.1670e-02,\n",
      "        -6.9530e-03, -2.1950e-01, -1.1328e-01, -8.6676e-03,  3.9605e-03,\n",
      "        -3.6363e-02,  2.1642e-02, -8.4397e-02, -1.4211e-01, -1.7185e-01,\n",
      "        -1.4687e-01, -4.0342e-02, -9.9074e-02, -6.3253e-02, -1.4706e-01,\n",
      "        -1.1539e-01, -1.1585e-01, -1.1451e-01,  1.7854e-03, -9.4408e-02,\n",
      "        -1.4557e-01, -1.2229e-01, -5.3750e-02, -2.3643e-02, -3.5664e-02,\n",
      "        -2.9630e-03, -1.3543e-01, -3.7093e-02, -1.6995e-01,  1.4955e-02,\n",
      "        -1.0681e-01, -3.0678e-02, -1.7876e-01, -1.5535e-01, -7.2139e-02,\n",
      "        -4.2546e-02, -1.0982e-02, -3.1459e-02, -1.3774e-01,  6.3706e-02,\n",
      "        -1.1001e-01, -1.0744e-01, -1.4247e-01, -1.5641e-01,  1.6434e-02,\n",
      "        -6.7281e-02, -2.5837e-02, -1.3148e-01, -1.4343e-01,  3.2796e-02,\n",
      "        -3.0152e-02, -1.1830e-01, -1.3157e-01, -1.4851e-02, -4.5199e-02,\n",
      "        -1.7485e-02, -1.0972e-01, -1.1957e-01, -1.5489e-01, -1.2734e-01,\n",
      "        -1.4338e-01, -9.4520e-02, -7.0661e-02], device='cuda:0')), ('layers.conv2.weight', tensor([[[[-1.0361e-02, -1.2791e-02, -1.4508e-02, -3.8150e-03, -1.1984e-02],\n",
      "          [-7.6875e-03, -5.0435e-03,  2.6020e-03,  2.4105e-03, -2.7427e-02],\n",
      "          [ 1.7768e-02,  1.1324e-02,  1.2498e-02, -6.3147e-03, -1.8837e-02],\n",
      "          [-1.7529e-03, -3.7801e-03, -5.3808e-03, -1.0700e-02,  1.8893e-03],\n",
      "          [-1.0393e-02,  7.2131e-03, -1.1524e-02, -8.8550e-03, -7.2291e-03]],\n",
      "\n",
      "         [[ 1.2180e-02, -7.1381e-03, -2.2486e-02,  1.5186e-03,  6.1499e-03],\n",
      "          [-1.5826e-02, -1.4611e-02,  2.4344e-03,  5.8970e-03,  7.6086e-03],\n",
      "          [-4.8678e-03,  6.9323e-03,  7.1644e-03, -2.2267e-03,  3.9067e-03],\n",
      "          [-1.4832e-02, -1.7315e-02, -9.6066e-03,  3.7009e-03,  1.0474e-02],\n",
      "          [-6.4358e-03, -2.3029e-03, -1.1505e-02,  8.2135e-03, -1.1661e-02]],\n",
      "\n",
      "         [[-5.5908e-03,  6.7903e-03,  5.1919e-03, -3.5311e-04, -1.6678e-02],\n",
      "          [-1.0068e-02, -1.0972e-02, -1.5095e-02, -1.1783e-02, -2.6427e-02],\n",
      "          [ 4.1416e-03, -4.9405e-03, -2.5036e-02, -7.1413e-03, -1.3408e-03],\n",
      "          [ 6.0129e-04,  4.4913e-03, -4.9438e-03, -2.0544e-02, -3.2330e-02],\n",
      "          [-7.7399e-03, -5.1486e-03,  5.0855e-04, -1.9220e-03, -1.4849e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4239e-02, -2.6352e-02,  9.5509e-03, -8.3128e-03,  2.6296e-03],\n",
      "          [-1.0639e-02,  5.7007e-03, -1.4831e-02,  1.7137e-02,  9.3681e-03],\n",
      "          [ 8.0465e-03,  9.0593e-03, -1.2178e-02,  6.5512e-03,  1.5199e-02],\n",
      "          [-1.1193e-02, -1.3607e-02,  8.1580e-03,  5.6983e-03,  8.4477e-03],\n",
      "          [ 1.9971e-02,  1.1399e-02, -8.0781e-03,  1.0239e-02,  3.2093e-03]],\n",
      "\n",
      "         [[-4.0205e-02, -1.0955e-02, -2.9312e-03, -6.5821e-03, -1.1977e-02],\n",
      "          [-8.7430e-03,  1.7054e-03,  1.5401e-03,  2.3136e-02,  3.1377e-03],\n",
      "          [ 3.6356e-02,  3.1838e-02,  3.2282e-02,  4.6973e-02,  1.7550e-02],\n",
      "          [ 1.5458e-02, -1.4013e-02, -1.7418e-02, -1.6958e-02, -1.0600e-02],\n",
      "          [ 6.4613e-04,  5.6587e-03, -4.8461e-03, -1.6009e-02, -1.1484e-02]],\n",
      "\n",
      "         [[-2.5447e-03, -9.7541e-03,  1.8046e-02,  1.1554e-02, -3.0683e-03],\n",
      "          [-1.0064e-02,  5.5680e-04,  7.4832e-04,  9.3191e-04,  1.8390e-02],\n",
      "          [-2.8715e-03,  1.5374e-02,  3.5007e-02,  1.3449e-02,  5.8933e-03],\n",
      "          [-4.6472e-03,  3.6419e-03, -1.9330e-03, -1.7296e-02, -2.6213e-02],\n",
      "          [-1.5900e-02, -1.2944e-02, -1.4443e-02, -2.0698e-02, -1.8192e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.9591e-04, -7.3548e-03, -5.2730e-03, -1.1858e-02,  1.6074e-02],\n",
      "          [ 1.2289e-02, -9.2022e-03,  1.0554e-04, -1.8819e-02, -2.0116e-02],\n",
      "          [-9.7414e-03,  1.2445e-03, -7.2251e-03, -8.0685e-03, -7.8990e-03],\n",
      "          [ 8.7111e-03, -8.3743e-03, -2.9507e-03, -1.1134e-02,  3.1849e-03],\n",
      "          [-1.2293e-02, -9.8680e-03,  5.2444e-03, -2.2356e-02, -1.7174e-02]],\n",
      "\n",
      "         [[-2.4138e-03, -6.6296e-03,  4.5199e-03,  8.9869e-03,  1.7017e-02],\n",
      "          [-8.2484e-03,  1.5022e-02, -1.3922e-02,  1.0163e-02,  6.9622e-03],\n",
      "          [-8.0388e-04,  7.2614e-03, -5.1676e-03,  1.5819e-02,  1.0881e-03],\n",
      "          [ 1.0213e-02, -4.7837e-03, -6.0838e-03,  1.4856e-02,  1.0989e-02],\n",
      "          [-1.0332e-02,  1.7803e-02,  1.4502e-02, -1.3414e-02,  1.5234e-03]],\n",
      "\n",
      "         [[-1.5641e-02, -1.6175e-02,  3.1424e-03,  9.3247e-03, -3.0206e-03],\n",
      "          [-5.2622e-03, -1.0195e-02,  3.4752e-03, -9.6940e-03,  3.9797e-03],\n",
      "          [-6.7404e-03, -1.7188e-02, -8.9661e-03, -1.2298e-02, -1.7136e-02],\n",
      "          [-1.4804e-02, -1.7433e-02, -2.3685e-02, -1.4941e-02,  3.8703e-03],\n",
      "          [ 4.8130e-04, -3.9676e-03, -2.3158e-02,  6.8100e-03,  1.7825e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1787e-02,  4.4427e-03, -2.0163e-03, -2.7349e-03, -8.9959e-03],\n",
      "          [-1.6773e-02, -6.4554e-03, -1.7458e-02, -1.1003e-02, -1.4289e-02],\n",
      "          [ 1.1320e-02, -2.6604e-02, -6.2908e-03,  1.0599e-02, -1.4780e-02],\n",
      "          [ 1.8037e-02, -2.6764e-02,  8.0315e-03, -1.0694e-03,  9.7352e-03],\n",
      "          [ 1.5948e-03, -6.7504e-03, -4.5990e-03,  1.5801e-02,  1.1470e-02]],\n",
      "\n",
      "         [[-7.1249e-03, -2.1611e-02, -5.2654e-03, -3.0373e-02, -6.4501e-03],\n",
      "          [-3.8574e-03,  9.4243e-03, -1.0319e-02, -2.4546e-02, -1.8828e-02],\n",
      "          [-1.0299e-02,  8.6908e-03, -2.5647e-03,  7.2071e-03,  9.7577e-03],\n",
      "          [ 9.2853e-03, -6.6066e-03,  9.4465e-03, -2.1935e-02,  5.9806e-04],\n",
      "          [ 2.5078e-02,  1.2836e-02,  2.3049e-03,  1.0076e-02,  1.6685e-02]],\n",
      "\n",
      "         [[ 1.0344e-02,  1.5117e-02,  1.3840e-02, -3.4391e-03,  8.7080e-03],\n",
      "          [-2.0759e-02,  7.1105e-03, -1.8635e-02,  7.0332e-03, -2.1118e-04],\n",
      "          [-1.5908e-03, -2.2349e-02, -1.1811e-02,  1.4836e-03, -1.2376e-02],\n",
      "          [ 1.4328e-02, -1.7866e-02, -5.3790e-03,  1.5906e-02,  1.0224e-02],\n",
      "          [-1.0056e-02, -1.3070e-02, -8.2553e-03, -1.6819e-03, -8.5783e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.6007e-02, -1.3295e-02,  5.7259e-04,  1.5916e-03, -3.6510e-03],\n",
      "          [-1.5318e-02, -1.7765e-02,  1.7566e-03, -1.9248e-02, -1.3437e-02],\n",
      "          [-2.4882e-03, -1.2158e-02, -1.1424e-02, -1.3831e-02,  2.3160e-02],\n",
      "          [-6.5971e-03, -1.1512e-03,  8.4085e-03,  5.0324e-03,  1.3018e-02],\n",
      "          [ 1.3261e-02,  3.1946e-03,  1.0678e-02, -5.2086e-03, -4.3256e-03]],\n",
      "\n",
      "         [[-8.8807e-03,  7.9252e-04, -1.6285e-03,  5.2952e-03,  7.9807e-03],\n",
      "          [ 1.9051e-02,  1.0178e-03, -1.6543e-02, -2.5115e-04,  6.1925e-03],\n",
      "          [ 8.1502e-03, -9.8848e-03,  7.1789e-03,  1.3531e-02, -1.8641e-02],\n",
      "          [ 6.1120e-03, -1.1050e-03, -4.1943e-03, -4.5788e-03, -1.5294e-02],\n",
      "          [-1.3676e-02,  9.5285e-03,  4.5484e-03, -1.2621e-02, -1.5836e-02]],\n",
      "\n",
      "         [[-6.3989e-03,  1.3348e-02,  1.4954e-02, -1.0085e-02, -1.1721e-02],\n",
      "          [-1.2516e-02,  1.2022e-02,  1.2502e-02,  1.5038e-02, -1.0332e-02],\n",
      "          [-1.5440e-02, -5.8412e-03,  6.0801e-03,  2.0280e-02,  6.8750e-03],\n",
      "          [-8.8956e-03,  2.1020e-02, -2.7320e-03, -1.5409e-02, -1.6834e-02],\n",
      "          [-1.5188e-02, -8.4638e-03,  2.0658e-02,  5.9953e-03,  4.1154e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.4692e-03,  5.7104e-03,  1.6518e-03,  5.6705e-05, -1.8624e-02],\n",
      "          [-5.1371e-03,  1.1232e-02,  2.1772e-02, -2.8281e-03,  8.4180e-03],\n",
      "          [ 1.3559e-03, -5.6881e-03,  1.5204e-02,  1.7935e-04,  8.5318e-03],\n",
      "          [-3.4832e-03, -7.0420e-03, -1.4611e-02,  9.9871e-03, -1.2791e-02],\n",
      "          [ 4.0125e-03,  2.1037e-03,  7.1504e-03,  1.9568e-02,  4.4304e-03]],\n",
      "\n",
      "         [[ 1.9266e-02,  5.6417e-03,  2.1730e-02,  1.6068e-02,  8.5404e-03],\n",
      "          [-9.6086e-03,  1.4271e-02,  2.1522e-03, -3.2332e-03, -3.8510e-03],\n",
      "          [-3.7736e-04,  7.2939e-04,  1.2792e-03,  1.2881e-02, -8.1366e-03],\n",
      "          [ 4.7129e-03,  6.2192e-03,  5.5438e-03,  6.0228e-03,  8.9738e-03],\n",
      "          [ 1.5817e-03,  2.7710e-03,  7.7738e-03, -9.1598e-03,  3.8530e-03]],\n",
      "\n",
      "         [[-1.0893e-04,  1.5183e-02,  4.4355e-03, -5.7691e-03, -1.0285e-04],\n",
      "          [-8.2940e-03, -9.7854e-03, -1.0900e-02,  1.4137e-03,  7.0653e-03],\n",
      "          [ 1.4014e-02,  9.4088e-04,  1.2117e-02, -2.7325e-03,  1.3168e-03],\n",
      "          [ 4.2689e-04,  2.9691e-03, -7.6188e-03, -1.5886e-02,  7.7257e-03],\n",
      "          [-1.4991e-03, -1.8090e-02, -1.7060e-02,  1.1123e-02,  3.7979e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.2959e-04, -7.8627e-03, -4.8926e-04, -6.3919e-04,  3.0328e-03],\n",
      "          [ 1.7793e-02, -1.1631e-02,  1.8673e-02, -1.0873e-02, -2.3637e-03],\n",
      "          [-1.2113e-02,  5.2606e-03, -1.4696e-03,  8.9760e-03, -1.0493e-02],\n",
      "          [ 1.1980e-02, -3.6289e-03, -1.6740e-02, -1.3731e-02,  8.4635e-03],\n",
      "          [ 4.3098e-03, -3.1351e-03, -9.4997e-03, -1.5353e-03, -1.7110e-02]],\n",
      "\n",
      "         [[ 7.4414e-03, -1.2006e-02, -1.1102e-02, -7.1962e-03,  2.0558e-02],\n",
      "          [-9.9882e-03, -1.4936e-03, -1.8885e-02,  3.0232e-03,  6.5520e-03],\n",
      "          [-2.0226e-02, -1.5635e-02,  4.9747e-03,  4.8983e-04,  1.9506e-02],\n",
      "          [-4.5084e-03,  8.5633e-03, -1.5041e-02, -2.4133e-02, -1.7567e-03],\n",
      "          [ 7.2318e-03, -1.4685e-02, -1.0460e-02, -1.3171e-03, -5.8932e-03]],\n",
      "\n",
      "         [[ 1.9760e-02, -1.0097e-02,  1.2363e-02, -6.9766e-03, -5.3055e-03],\n",
      "          [-1.2454e-02, -5.2123e-04, -2.1198e-02, -1.1426e-02, -5.8805e-03],\n",
      "          [ 1.0819e-02,  1.0751e-02, -9.8910e-03, -1.3116e-02, -1.4373e-02],\n",
      "          [-3.9628e-03, -6.0749e-03, -5.1440e-03,  1.1516e-02, -1.0279e-02],\n",
      "          [-1.2042e-02, -3.4138e-04, -1.4874e-02, -2.0192e-02, -1.7908e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9918e-04,  1.6124e-02, -1.6311e-02, -1.1806e-02, -2.2929e-03],\n",
      "          [-8.6965e-03,  1.5088e-03, -1.0684e-02,  1.3706e-02,  2.8076e-02],\n",
      "          [ 9.4937e-03, -1.6631e-02, -7.1916e-03,  4.3443e-03,  1.2157e-03],\n",
      "          [-8.8628e-04, -1.1241e-02,  6.8295e-03, -9.7008e-04, -3.0500e-03],\n",
      "          [ 3.8363e-03,  1.0065e-02, -4.0658e-03, -9.9302e-03, -3.9025e-04]],\n",
      "\n",
      "         [[-1.3125e-02, -2.4106e-02,  6.2293e-03, -5.5765e-03, -1.3967e-03],\n",
      "          [ 1.8408e-02,  3.5837e-02,  7.2087e-03,  2.6343e-02,  1.0905e-02],\n",
      "          [-6.9980e-03, -6.7542e-03, -9.0454e-03, -2.6705e-02, -1.7500e-02],\n",
      "          [-1.8057e-02,  1.5855e-02,  9.3643e-04,  3.0032e-02,  2.6636e-02],\n",
      "          [-1.2460e-02, -1.6335e-02,  4.7875e-03, -1.3019e-02,  1.2153e-02]],\n",
      "\n",
      "         [[-6.9614e-03, -1.4479e-02, -4.1374e-03, -1.4580e-02, -5.5675e-03],\n",
      "          [ 1.3023e-02,  1.7117e-03, -2.0791e-02, -1.3905e-03,  1.1489e-02],\n",
      "          [ 5.3646e-03, -5.8904e-04,  1.5814e-03,  1.2382e-02, -1.9562e-02],\n",
      "          [-4.2091e-03, -4.7937e-03, -7.9430e-03,  7.8914e-03,  6.7173e-03],\n",
      "          [-2.5196e-02, -1.2201e-02,  7.0312e-03,  1.9450e-03,  1.4730e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0894e-02,  3.0285e-03, -1.3510e-02, -9.6198e-03, -1.5477e-02],\n",
      "          [-8.4965e-03,  2.0789e-02, -2.8296e-04, -6.6747e-03, -3.8400e-03],\n",
      "          [-1.2711e-02, -1.3333e-02,  9.6799e-03,  7.1418e-03, -8.6102e-03],\n",
      "          [-8.6484e-03, -3.2176e-03, -1.3923e-02,  1.6864e-02, -1.4287e-02],\n",
      "          [ 2.7390e-03,  1.7097e-02,  1.5332e-03, -2.1116e-02, -3.8618e-03]],\n",
      "\n",
      "         [[ 8.7256e-03, -1.8599e-03,  1.2194e-02, -3.0095e-02, -2.6050e-02],\n",
      "          [ 1.7914e-02, -8.8038e-03, -1.4118e-02, -1.9936e-02,  2.0569e-02],\n",
      "          [-1.5288e-02, -1.0349e-02,  6.2539e-03, -9.8881e-03, -2.1883e-02],\n",
      "          [ 3.1904e-02,  9.1580e-03, -1.9986e-02, -2.2490e-02,  8.6083e-03],\n",
      "          [-3.0654e-03,  3.2036e-03,  4.8899e-03, -9.3358e-03, -7.8106e-03]],\n",
      "\n",
      "         [[ 7.1655e-03, -1.5291e-02,  5.0549e-03, -2.2120e-02, -1.0280e-02],\n",
      "          [ 5.9865e-03,  1.2498e-02,  9.8386e-03,  4.8869e-03, -1.5651e-02],\n",
      "          [ 2.8490e-03,  2.2538e-02,  2.1624e-02,  1.4739e-02, -1.6419e-02],\n",
      "          [-1.5760e-02,  1.9427e-02, -7.2107e-03, -8.3868e-03, -5.9902e-04],\n",
      "          [-2.2321e-02,  5.0528e-03, -1.8516e-02, -3.5061e-03,  2.0831e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.7405e-03, -5.0020e-03, -6.4198e-03,  6.0130e-03,  2.2945e-02],\n",
      "          [ 2.0332e-02, -3.7249e-03, -1.0623e-03,  9.4102e-03, -9.2940e-04],\n",
      "          [ 2.4174e-02,  1.2416e-02, -6.7891e-03,  5.3804e-03,  2.5025e-03],\n",
      "          [-9.5993e-03,  6.7996e-03,  2.6298e-02,  1.0266e-02, -5.2946e-03],\n",
      "          [-5.0605e-03,  6.5367e-03,  1.4226e-02,  1.0924e-02,  1.4095e-02]],\n",
      "\n",
      "         [[-2.1957e-03,  9.1990e-03,  1.5714e-03,  1.2259e-02, -1.7715e-02],\n",
      "          [-7.8657e-03,  1.2198e-02,  3.2172e-03, -6.9254e-03, -1.2084e-02],\n",
      "          [-1.2266e-02, -7.3868e-03, -1.5777e-02, -1.0506e-02, -3.8199e-03],\n",
      "          [-4.2958e-03,  2.9711e-03, -5.9065e-03, -9.7208e-03, -7.3161e-03],\n",
      "          [ 7.1965e-04,  2.5020e-02,  4.5172e-04, -2.0859e-02, -1.2927e-02]],\n",
      "\n",
      "         [[-5.5059e-03, -1.4552e-02,  6.2679e-03,  1.1052e-03,  6.6121e-03],\n",
      "          [ 1.7320e-02,  1.5342e-02, -1.0645e-02,  1.7960e-03, -1.1579e-02],\n",
      "          [ 1.1864e-02,  1.9267e-02,  3.0793e-03,  1.2899e-02,  2.6060e-04],\n",
      "          [ 8.0576e-03,  1.0702e-02,  1.3399e-02, -1.2472e-02,  1.1383e-02],\n",
      "          [ 1.1930e-02, -1.5733e-02, -1.2850e-02, -8.6916e-03,  5.5269e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.7378e-02, -1.9922e-03, -2.1713e-02,  1.3893e-03, -2.2163e-02],\n",
      "          [ 2.7092e-03, -2.1452e-02, -1.1441e-03, -4.0209e-03,  6.6636e-03],\n",
      "          [ 3.0172e-04, -5.0012e-03, -1.9811e-02,  1.2695e-02, -1.0951e-02],\n",
      "          [ 1.1656e-02, -6.4139e-03,  6.4254e-03,  9.7302e-03, -4.1004e-03],\n",
      "          [-4.5393e-03, -7.1921e-03, -3.2518e-03,  1.3856e-02, -2.0258e-03]],\n",
      "\n",
      "         [[-1.2495e-02,  5.6872e-03,  7.0314e-03,  3.1446e-03,  1.3124e-02],\n",
      "          [ 3.8062e-03, -2.9448e-03,  1.2371e-02,  1.2541e-02, -9.1205e-03],\n",
      "          [ 6.8624e-03,  1.5018e-02, -1.1736e-04, -9.2904e-03,  4.3846e-03],\n",
      "          [-4.1127e-03, -6.9652e-03, -1.1238e-02, -2.8242e-02,  1.7097e-02],\n",
      "          [ 3.0308e-03, -2.7584e-02, -1.3337e-02,  6.1316e-03,  1.2464e-02]],\n",
      "\n",
      "         [[-7.9827e-03, -1.1172e-02, -1.0437e-02, -6.4215e-03,  2.1616e-02],\n",
      "          [ 5.3585e-03, -1.8184e-02, -1.3889e-02,  7.0488e-04,  2.1166e-02],\n",
      "          [ 7.8782e-03, -8.5222e-04,  1.9100e-02, -1.2566e-02,  6.7356e-03],\n",
      "          [ 1.6701e-03, -8.7474e-03, -1.6987e-02,  1.3393e-02, -2.1193e-02],\n",
      "          [-5.6000e-03, -1.3470e-02, -1.5747e-03,  1.5050e-02, -4.5827e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.4838e-03,  1.7131e-03,  1.1996e-02, -1.0271e-03, -1.2586e-02],\n",
      "          [ 5.5459e-03, -1.0645e-02, -1.0019e-02, -2.1060e-02,  2.4485e-02],\n",
      "          [-5.5337e-03, -1.0697e-02, -1.2025e-03,  2.1162e-02, -3.1675e-03],\n",
      "          [ 1.9014e-02, -2.8031e-03, -7.0220e-03,  1.7591e-02,  5.6554e-03],\n",
      "          [ 2.4804e-02,  2.2299e-02, -6.1969e-03,  1.6846e-02,  2.4297e-02]],\n",
      "\n",
      "         [[-2.4176e-03,  7.2982e-04,  6.5375e-03,  8.2776e-04, -9.5387e-04],\n",
      "          [-1.6663e-03,  9.6847e-03, -1.4048e-02, -1.8721e-02, -1.6810e-02],\n",
      "          [-1.7592e-02, -1.6628e-02, -1.5111e-03,  4.1699e-03,  1.2443e-02],\n",
      "          [ 2.2816e-03,  5.3465e-03, -3.6479e-03, -1.2190e-02,  1.6159e-02],\n",
      "          [ 1.4789e-02, -1.8295e-02,  1.4662e-02, -1.9544e-03, -5.3027e-03]],\n",
      "\n",
      "         [[-1.4508e-02, -9.7545e-03, -2.2406e-02, -1.6465e-02, -8.0341e-03],\n",
      "          [ 1.4132e-02, -1.6663e-02, -5.8130e-03, -1.3456e-02,  1.7027e-02],\n",
      "          [-6.2541e-03, -1.0458e-02,  6.5002e-03,  2.2695e-03,  9.6665e-05],\n",
      "          [ 1.1230e-02,  3.5675e-03,  8.3832e-03,  2.1547e-02, -1.3792e-02],\n",
      "          [ 2.1129e-03,  1.7365e-02,  6.6377e-04, -4.7903e-03,  1.0480e-02]]]],\n",
      "       device='cuda:0')), ('layers.conv2.bias', tensor([-0.0866,  0.0071, -0.0650, -0.0532, -0.0205, -0.0748, -0.0492, -0.0050,\n",
      "        -0.0151, -0.0310, -0.0576, -0.0247, -0.0444, -0.0418, -0.0317, -0.0452,\n",
      "        -0.0783, -0.0980, -0.0568, -0.0332, -0.0509, -0.0838, -0.0338, -0.0498,\n",
      "        -0.0815, -0.0774, -0.1115, -0.0555,  0.0031, -0.0318,  0.0100, -0.0871,\n",
      "        -0.0312, -0.0427, -0.0896, -0.0475, -0.0239, -0.0715, -0.0057, -0.0276,\n",
      "        -0.0826, -0.0406, -0.0888, -0.0886, -0.0677, -0.0542, -0.0012, -0.0538,\n",
      "        -0.0561, -0.0158, -0.0715, -0.0403, -0.0808, -0.0555, -0.0534, -0.0865,\n",
      "        -0.0698, -0.0237, -0.0554, -0.0394, -0.0323, -0.0138, -0.0487, -0.0346,\n",
      "        -0.0344, -0.0669, -0.0738, -0.0733, -0.0695, -0.0626, -0.0311, -0.0234,\n",
      "        -0.0357, -0.0183, -0.0373, -0.1099, -0.0634, -0.0585, -0.0819, -0.0513,\n",
      "        -0.0363, -0.0637, -0.0318, -0.0497, -0.0560, -0.0165, -0.0220, -0.0550,\n",
      "        -0.1090, -0.0702, -0.0688, -0.1035, -0.0069, -0.0117, -0.0498, -0.0494,\n",
      "        -0.0545, -0.0551, -0.0264, -0.0426, -0.0440, -0.0363, -0.0322, -0.0127,\n",
      "        -0.1139, -0.0678, -0.0466, -0.0597, -0.0929, -0.0300, -0.0387, -0.0700,\n",
      "        -0.0395, -0.0463, -0.0818, -0.0768, -0.0464, -0.1004, -0.0639, -0.0551,\n",
      "        -0.0701, -0.0114, -0.0859, -0.0501, -0.0583, -0.0199, -0.0902, -0.0989,\n",
      "        -0.0455, -0.1037, -0.0060, -0.0291, -0.0732, -0.0355, -0.0185, -0.1025,\n",
      "        -0.0690, -0.0031, -0.1073, -0.0136, -0.0413, -0.0574, -0.0184, -0.1167,\n",
      "        -0.0445, -0.0764, -0.0391, -0.0866, -0.0309, -0.0239, -0.0873, -0.0876,\n",
      "        -0.0016, -0.0283, -0.0891, -0.0872, -0.0281, -0.0994, -0.0172, -0.0247,\n",
      "        -0.0487, -0.0467, -0.1184, -0.0685, -0.0490, -0.0792, -0.0294, -0.0349,\n",
      "        -0.0418, -0.0468, -0.0065, -0.0637, -0.0255, -0.0568, -0.0263, -0.0478,\n",
      "        -0.0205, -0.0627, -0.0622, -0.0225, -0.0491, -0.0219, -0.0307,  0.0033,\n",
      "         0.0151, -0.0117, -0.0053, -0.0307, -0.0615, -0.0354, -0.0659, -0.0142,\n",
      "        -0.0575, -0.0592, -0.0633,  0.0076, -0.0421, -0.0642, -0.0687, -0.0213,\n",
      "        -0.0564, -0.0339, -0.0536, -0.0721,  0.0138, -0.0377, -0.0647, -0.0637,\n",
      "        -0.1275, -0.0679, -0.0703, -0.0405, -0.0691, -0.0852, -0.0496, -0.0426,\n",
      "        -0.0130, -0.0290, -0.0621, -0.0618, -0.0819, -0.0687, -0.0340, -0.0413,\n",
      "        -0.0478, -0.0878, -0.0634, -0.0762, -0.0712,  0.0016, -0.0558],\n",
      "       device='cuda:0')), ('layers.fc1.weight', tensor([[-0.0321, -0.0194,  0.0018,  ..., -0.0121, -0.0176, -0.0195],\n",
      "        [ 0.0167,  0.0358,  0.0199,  ..., -0.0035, -0.0106,  0.0060],\n",
      "        [-0.0276, -0.0190, -0.0455,  ..., -0.0044,  0.0036,  0.0084],\n",
      "        ...,\n",
      "        [ 0.0088,  0.0453,  0.0370,  ...,  0.0052,  0.0166,  0.0335],\n",
      "        [ 0.0260,  0.0259, -0.0321,  ..., -0.0137, -0.0197, -0.0036],\n",
      "        [ 0.0559, -0.0207, -0.0152,  ..., -0.0143, -0.0244, -0.0086]],\n",
      "       device='cuda:0')), ('layers.fc1.bias', tensor([-4.2155e-02, -3.5414e-02, -3.7657e-02, -7.9325e-03, -5.7386e-03,\n",
      "        -3.1426e-02, -1.1151e-02,  7.6841e-05,  1.8293e-02, -5.3825e-02,\n",
      "         6.3593e-02,  1.4392e-02,  4.2681e-03,  4.9228e-02, -2.7516e-03,\n",
      "         3.6060e-02,  8.7418e-03, -2.7645e-02,  4.6908e-02, -7.5458e-03,\n",
      "        -2.5403e-02, -6.6499e-03, -3.9861e-02,  7.5872e-02, -2.3411e-02,\n",
      "        -5.1671e-04, -2.1081e-02,  2.2905e-03,  1.2046e-01,  3.7629e-02,\n",
      "         7.7604e-03, -2.7867e-03, -6.4687e-03,  8.5778e-04,  8.4314e-02,\n",
      "         3.4298e-02,  3.5198e-02,  1.2694e-01,  2.6367e-03,  1.4351e-01,\n",
      "         6.0407e-02, -7.6692e-03,  2.9214e-02, -2.6999e-02, -4.7171e-02,\n",
      "        -2.5735e-02,  1.1895e-02, -3.2594e-02], device='cuda:0')), ('layers.fc2.weight', tensor([[ 0.0090,  0.2899,  0.0801,  ...,  0.2705,  0.1525, -0.0179],\n",
      "        [ 0.0854, -0.0442,  0.1088,  ..., -0.1206,  0.0514,  0.0583],\n",
      "        [ 0.0564, -0.0651,  0.0482,  ...,  0.1148,  0.0177, -0.2108],\n",
      "        ...,\n",
      "        [ 0.0318, -0.1042, -0.0515,  ...,  0.0483,  0.1012,  0.0165],\n",
      "        [-0.2125, -0.1164,  0.0566,  ..., -0.0465, -0.0672,  0.0836],\n",
      "        [ 0.1317,  0.0825,  0.0224,  ..., -0.1049, -0.0520, -0.1379]],\n",
      "       device='cuda:0')), ('layers.fc2.bias', tensor([-0.1341,  0.1034, -0.1418,  0.1325, -0.0298,  0.2075, -0.0887, -0.0272,\n",
      "        -0.0146,  0.0340,  0.1281, -0.0801,  0.0126, -0.1078,  0.1561,  0.0219,\n",
      "         0.3101,  0.1274,  0.2079,  0.0524,  0.2057,  0.0209,  0.0044, -0.1828,\n",
      "        -0.0918,  0.1082,  0.0486, -0.0340, -0.0753,  0.0420,  0.2456,  0.2018,\n",
      "        -0.1192, -0.0061, -0.1138, -0.0079, -0.0110,  0.2761, -0.1411, -0.0674,\n",
      "         0.1537,  0.1440,  0.1372,  0.0706, -0.1450,  0.1186, -0.0267,  0.1017,\n",
      "         0.1512,  0.0887,  0.1424,  0.1020,  0.0612,  0.0158, -0.0859,  0.1277],\n",
      "       device='cuda:0')), ('layers.fc3.weight', tensor([[ 0.0422, -0.0456, -0.0356,  ..., -0.0707, -0.0081, -0.1406],\n",
      "        [-0.0459,  0.0835,  0.0943,  ...,  0.0475,  0.1860, -0.1144],\n",
      "        [-0.0455, -0.0955, -0.1103,  ...,  0.0623, -0.0109, -0.0444],\n",
      "        ...,\n",
      "        [ 0.2415, -0.0393,  0.1692,  ..., -0.1268, -0.0789, -0.1527],\n",
      "        [-0.1084,  0.0606, -0.1011,  ...,  0.1277, -0.1700, -0.0354],\n",
      "        [-0.0770, -0.0185,  0.0356,  ..., -0.0960,  0.0549,  0.1090]],\n",
      "       device='cuda:0')), ('layers.fc3.bias', tensor([ 0.0208, -0.0896, -0.1245,  0.1216,  0.0553,  0.0731, -0.0686, -0.0840,\n",
      "         0.0844,  0.1782,  0.1342, -0.1230, -0.1285, -0.1349,  0.1090,  0.0302,\n",
      "         0.1598,  0.0408, -0.0667,  0.0791, -0.0824, -0.0476,  0.1883, -0.0812,\n",
      "        -0.0184,  0.2457, -0.0370, -0.1096,  0.0930, -0.1013, -0.1086,  0.0713,\n",
      "        -0.0026, -0.0677,  0.2589, -0.0742, -0.1546, -0.0615, -0.1295,  0.1836,\n",
      "         0.1487,  0.0827, -0.0062,  0.1936,  0.0900,  0.0559,  0.0020,  0.1147,\n",
      "        -0.0350,  0.1423, -0.0470,  0.0118, -0.0764, -0.0507, -0.0201, -0.0811,\n",
      "         0.1982,  0.1348, -0.1025,  0.1786, -0.1240], device='cuda:0')), ('layers.fco.weight', tensor([[-0.2557,  0.2087,  0.1414, -0.3557,  0.0473,  0.0061,  0.0556,  0.0771,\n",
      "          0.3066, -0.2298,  0.1171,  0.0037,  0.3834, -0.0201,  0.0107,  0.1301,\n",
      "         -0.2094,  0.2858, -0.2484,  0.1684, -0.1452, -0.0143,  0.0502, -0.0593,\n",
      "         -0.0081, -0.0580, -0.0692,  0.2471,  0.2498,  0.0183, -0.0201,  0.0816,\n",
      "          0.0113,  0.0600, -0.4920,  0.0849,  0.0370,  0.0849,  0.1497, -0.1470,\n",
      "          0.0772,  0.3956,  0.0812, -0.3833, -0.1435,  0.0162, -0.1254,  0.2187,\n",
      "         -0.0441,  0.1809, -0.0711,  0.1155,  0.0141,  0.0627,  0.2990,  0.0507,\n",
      "         -0.1358,  0.0890, -0.1171,  0.1174,  0.1753],\n",
      "        [ 0.0923, -0.1541,  0.0515,  0.0745, -0.1781,  0.3109,  0.0204, -0.1329,\n",
      "          0.0722, -0.3728,  0.1712, -0.1710, -0.2017, -0.1314,  0.1707,  0.0370,\n",
      "         -0.1284, -0.0983,  0.2549,  0.2490,  0.3799,  0.1253, -0.2260,  0.0332,\n",
      "         -0.0742, -0.3574, -0.0350, -0.1485,  0.0731, -0.0150,  0.1176,  0.2332,\n",
      "         -0.0400,  0.1028, -0.2519, -0.1184,  0.1743,  0.0136, -0.0466, -0.0459,\n",
      "         -0.1484, -0.2657,  0.2504, -0.3353, -0.1725,  0.2994,  0.2754, -0.2574,\n",
      "          0.1996,  0.1001,  0.0667,  0.1085, -0.0776, -0.0216, -0.1657,  0.1265,\n",
      "         -0.3200, -0.2500,  0.3334, -0.0869, -0.1566],\n",
      "        [-0.2006, -0.0826,  0.0732,  0.3989, -0.1515, -0.0213,  0.0557, -0.1094,\n",
      "         -0.2220, -0.2181, -0.1028,  0.0472,  0.0636,  0.0293, -0.2212, -0.1987,\n",
      "          0.0184,  0.2772, -0.1062, -0.0547, -0.0313, -0.0018,  0.1156, -0.0824,\n",
      "          0.0812,  0.1667,  0.0418, -0.1045,  0.1715,  0.0068,  0.1464, -0.2133,\n",
      "          0.0322,  0.1200,  0.1977, -0.0506,  0.0722,  0.1394,  0.0973,  0.3246,\n",
      "          0.4633, -0.0367, -0.2072, -0.2966,  0.2863,  0.1682, -0.1446,  0.1791,\n",
      "          0.0244, -0.0337,  0.1149,  0.0813, -0.1202,  0.2509,  0.1979, -0.1801,\n",
      "          0.2234,  0.1741, -0.2561,  0.1590,  0.1806],\n",
      "        [-0.0010,  0.0015,  0.1150,  0.0239, -0.2215, -0.1192, -0.1330,  0.0798,\n",
      "         -0.2597,  0.3800, -0.0692,  0.0947,  0.0425, -0.0721,  0.2055,  0.1068,\n",
      "          0.3721, -0.0960,  0.1123,  0.1214, -0.3173,  0.0392, -0.0019, -0.1164,\n",
      "         -0.0236,  0.1848, -0.0689,  0.1092,  0.0777, -0.0549, -0.0634, -0.0009,\n",
      "         -0.1720, -0.0244,  0.0793, -0.1943, -0.0421,  0.0105, -0.0175,  0.0765,\n",
      "         -0.1736, -0.1080,  0.1177,  0.1245, -0.0305,  0.2318, -0.1984, -0.0884,\n",
      "          0.0352, -0.2358,  0.0891,  0.0416, -0.1506,  0.0384, -0.0574,  0.1531,\n",
      "          0.0335,  0.3411, -0.2186, -0.1204, -0.0504],\n",
      "        [-0.0759, -0.1604, -0.1303,  0.2018, -0.0042,  0.2333,  0.1217, -0.1016,\n",
      "         -0.1338,  0.2385,  0.0833, -0.2494,  0.0707, -0.3161, -0.0985, -0.1206,\n",
      "          0.0951, -0.1153, -0.2968, -0.1764, -0.1895, -0.0228,  0.4439,  0.0057,\n",
      "          0.1052,  0.1404, -0.1884, -0.2520,  0.1462, -0.0172, -0.2170, -0.1406,\n",
      "          0.1346,  0.0809,  0.2894,  0.0909, -0.1583, -0.0837, -0.0079,  0.0049,\n",
      "         -0.2365,  0.0463, -0.1369,  0.2141,  0.1368, -0.1584, -0.0333,  0.3221,\n",
      "          0.0494,  0.0587,  0.0620, -0.0609,  0.0320, -0.4961, -0.1723,  0.0372,\n",
      "          0.0984,  0.2393,  0.1974,  0.3487, -0.1283],\n",
      "        [ 0.3693, -0.2086,  0.0839,  0.1627, -0.1955, -0.1436,  0.0836, -0.0107,\n",
      "         -0.1050,  0.2857, -0.0973,  0.0623,  0.0896,  0.0148, -0.0500,  0.3081,\n",
      "         -0.0064, -0.3786, -0.1039, -0.0954, -0.0769, -0.0863,  0.0140, -0.0112,\n",
      "         -0.0128,  0.1866,  0.2002,  0.2645, -0.0604,  0.0724, -0.0813, -0.2799,\n",
      "         -0.2128, -0.0556,  0.2336, -0.0699,  0.2406, -0.1129,  0.1501, -0.1556,\n",
      "          0.1799,  0.0907, -0.1600,  0.2731, -0.0456, -0.1575, -0.1243, -0.1818,\n",
      "         -0.2155, -0.1426, -0.0983,  0.0034, -0.0024,  0.1953, -0.0021, -0.0322,\n",
      "         -0.1408,  0.1652, -0.1166,  0.1635,  0.1173],\n",
      "        [-0.3235,  0.0741,  0.0563,  0.2033, -0.4436, -0.0432, -0.1444,  0.0279,\n",
      "          0.1286, -0.0561,  0.0494, -0.3432, -0.1107,  0.1293,  0.1773, -0.1010,\n",
      "         -0.0521, -0.2464,  0.1327, -0.2424,  0.1785, -0.1155, -0.2366, -0.1093,\n",
      "          0.0523,  0.1089, -0.1847,  0.2400, -0.2996,  0.0230, -0.0249,  0.2653,\n",
      "          0.1412,  0.1193,  0.3570, -0.0901, -0.4384,  0.0759, -0.1022,  0.2438,\n",
      "         -0.0610,  0.0311,  0.1820,  0.0291, -0.1187, -0.3881, -0.0671, -0.2032,\n",
      "         -0.0238, -0.1164,  0.0514,  0.0318,  0.0271,  0.2661,  0.1217,  0.0365,\n",
      "          0.4985,  0.0588,  0.0632,  0.0909,  0.0374],\n",
      "        [ 0.1633,  0.0824,  0.1166, -0.2029,  0.3189,  0.1894,  0.0289,  0.0102,\n",
      "         -0.1897, -0.1052,  0.0474,  0.2954,  0.0271, -0.0866, -0.3476, -0.1200,\n",
      "          0.0950, -0.3091, -0.2176, -0.0383, -0.2501, -0.1102,  0.0370, -0.1481,\n",
      "         -0.0034, -0.2000, -0.0211,  0.2051,  0.3055,  0.0034,  0.0917, -0.1451,\n",
      "         -0.2832, -0.0475,  0.2780,  0.3635,  0.0586, -0.1991, -0.1699, -0.0771,\n",
      "         -0.1229, -0.1680,  0.0294,  0.3618,  0.2646, -0.1215, -0.2416,  0.0880,\n",
      "         -0.1376, -0.1464, -0.0822,  0.0110,  0.1957, -0.1092, -0.1627, -0.1165,\n",
      "         -0.1236, -0.2487, -0.1734, -0.0952, -0.0680],\n",
      "        [ 0.2154,  0.2886,  0.1553, -0.1425,  0.2116, -0.1745, -0.0702,  0.0538,\n",
      "          0.2916, -0.1659, -0.3245, -0.0545, -0.2132,  0.1198,  0.0649, -0.0843,\n",
      "         -0.1387,  0.4626,  0.2840,  0.0311, -0.3377,  0.0063, -0.1850,  0.2231,\n",
      "          0.1255,  0.2519,  0.2470, -0.1267, -0.1810,  0.0074,  0.0720, -0.2287,\n",
      "         -0.2239, -0.0656, -0.5045, -0.2932, -0.3316, -0.0342,  0.1395, -0.1915,\n",
      "         -0.1551,  0.0351,  0.1260,  0.0364, -0.2213,  0.2311,  0.0051,  0.2013,\n",
      "          0.1085,  0.2661,  0.1086,  0.1122, -0.1187, -0.2492, -0.0558,  0.1090,\n",
      "         -0.1751, -0.1543,  0.3748,  0.1069,  0.0933],\n",
      "        [-0.0309, -0.0626,  0.1332,  0.1206,  0.6046, -0.1493, -0.0909,  0.0504,\n",
      "         -0.0609,  0.0789, -0.1559,  0.2276, -0.0590,  0.0456,  0.1019, -0.1388,\n",
      "         -0.3760,  0.1970,  0.1322,  0.1764,  0.2033, -0.0642, -0.1592, -0.1192,\n",
      "         -0.1201, -0.3376, -0.0820, -0.0870, -0.2163, -0.0530, -0.0053,  0.4825,\n",
      "          0.0015, -0.0282, -0.2142, -0.2391,  0.1511,  0.1084,  0.0638, -0.0738,\n",
      "         -0.1873,  0.0285, -0.0323, -0.1269, -0.3926, -0.0015,  0.1833, -0.1869,\n",
      "          0.2472,  0.1777,  0.0580,  0.0280, -0.1781, -0.0421,  0.1054, -0.0095,\n",
      "         -0.1403, -0.3723, -0.2404, -0.1253,  0.0033]], device='cuda:0')), ('layers.fco.bias', tensor([-0.2844, -0.3005,  0.1089,  0.0879,  0.4487, -0.0047,  0.1092, -0.1204,\n",
      "        -0.2055, -0.1599], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!rm -rf ./data/* ./ray_results/layers/* ./ray_results/neurons/* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
