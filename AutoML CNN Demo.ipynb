{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial # for trials\n",
    "import numpy as np # for accuracy math\n",
    "import os # for paths\n",
    "import torch # for nn instantiation\n",
    "import torch.nn as nn # for nn objects\n",
    "import torch.nn.functional as F # for forward method\n",
    "import torch.optim as optim # for optimization\n",
    "from torch.utils.data import random_split # for train/test split\n",
    "import torchvision # for data transforms\n",
    "import torchvision.transforms as transforms # for transform methods\n",
    "from ray import tune # for trialing\n",
    "from ray.tune import CLIReporter # for trial reporting\n",
    "from ray.tune import JupyterNotebookReporter # for trial reporting\n",
    "from ray.tune.schedulers import ASHAScheduler # for trial scheduling\n",
    "from ray.tune.schedulers import HyperBandForBOHB # for trial scheduling\n",
    "from ray.tune.suggest.bohb import TuneBOHB # for trial selection/pruning\n",
    "import ConfigSpace as CS # for configuration bounds\n",
    "from collections import OrderedDict # for dynamic configuration definition\n",
    "from pathlib import Path # for OS agnostic path definition\n",
    "\n",
    "# import itertools package \n",
    "import itertools \n",
    "from itertools import combinations, combinations_with_replacement\n",
    "from itertools import product\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# allow configuration copying\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data and checkpoint locations\n",
    "p = Path('.')\n",
    "d = p / 'data'\n",
    "r = p / 'ray_results'\n",
    "l = p / 'checkpoints' / 'layers'\n",
    "n = p / 'checkpoints' / 'layers'\n",
    "\n",
    "# set computation location(s)\n",
    "gpus = torch.cuda.device_count()\n",
    "device = \"cuda:0\" if gpus else \"cpu\"\n",
    "\n",
    "# set number or fraction of processing units (per training worker) you'd like to utilize, if any at all\n",
    "# cpu_use must be grater than zero\n",
    "cpu_use = 1 if gpus else 0.5\n",
    "gpu_use = 0.25 if gpus else 0\n",
    "\n",
    "# set experiment hyperparameters\n",
    "num_samples = 2 ** (5 if gpus else 4)\n",
    "max_num_epochs = 10 * (4 if gpus else 1)\n",
    "gpus_per_trial = 1 if gpus else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the neuron configuration we want is dependent upon the number of layers we have, we need to work flatten the feature space a bit. We can reduce the high-dminesional setups to a slightly less high-dminesional string of base-n nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base                              13\n",
      "nodes_req                          4\n",
      "sparcity                        1066\n",
      "max_necc_base_value    [12, 6, 9, 0]\n",
      "nodes+_req                         3\n",
      "subsparcity                    25298\n",
      "unexplained                    75894\n",
      "sparcity_pcnt                3.73236\n",
      "subsparcity_pcnt             1151.48\n",
      "denoise_pcnt                   -1500\n",
      "complexity                      4268\n",
      "Name: 13, dtype: object \n",
      "\n",
      "base                                  15\n",
      "nodes_req                              5\n",
      "sparcity                          124000\n",
      "max_necc_base_value    [12, 8, 3, 13, 5]\n",
      "nodes+_req                             4\n",
      "subsparcity                       584750\n",
      "unexplained                      2339000\n",
      "sparcity_pcnt                    16.3292\n",
      "subsparcity_pcnt                 1155.06\n",
      "denoise_pcnt                       -2400\n",
      "complexity                        620005\n",
      "Name: 15, dtype: object \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define feature space for hashing\n",
    "c_min = 3**2\n",
    "c_max = 3**5\n",
    "f_min = 2**2\n",
    "f_max = 2**6\n",
    "\n",
    "c = c_max - c_min\n",
    "f = f_max - f_min\n",
    "\n",
    "# conv = set(range(c_max)) - set(range(c_min))\n",
    "# full = set(range(f_max)) - set(range(f_min))\n",
    "conv = range(c_max)[c_min:]\n",
    "full = range(f_max)[f_min:]\n",
    "\n",
    "c_comb = list(combinations_with_replacement(conv,2))\n",
    "f_comb = []\n",
    "for layers in range(1,5):\n",
    "    f_comb += list(combinations_with_replacement(full,layers))\n",
    "#     print(\"Fully connected layer %s range: %s\" % (layers,len(f_comb)) )\n",
    "#     print(\"\\n\")\n",
    "\n",
    "# for conversion from dec to whatever we end up using\n",
    "# most to least significant digit\n",
    "def numberToBase(n, b):\n",
    "    if n == 0:\n",
    "        return [0]\n",
    "    digits = []\n",
    "    while n:\n",
    "        digits.append(int(n % b))\n",
    "        n //= b\n",
    "    rev = digits[::-1]\n",
    "    return rev\n",
    "\n",
    "def feature_spacing():\n",
    "    \n",
    "    # create empty list to store the \n",
    "    # combinations \n",
    "    unique_combinations = list(combinations([c_comb,f_comb],2))\n",
    "    total_uniques = len(unique_combinations)\n",
    "    total_points = total_uniques**2\n",
    "    total_cvs = len(c_comb)\n",
    "    total_fcs = len(f_comb)\n",
    "    \n",
    "    columns = [\"base\",\"nodes_req\",\"sparcity\",\"sparcity_pcnt\",\"denoise_pcnt\"]\n",
    "    values = [1,total_uniques,total_points - total_uniques,(total_points - total_uniques) / total_points,0]\n",
    "    \n",
    "    cf = []\n",
    "    \n",
    "    for layer in [total_cvs,total_fcs]:#,total_uniques]:\n",
    "        results = {\n",
    "            \"base\": [1],\n",
    "            \"nodes_req\": [total_uniques],\n",
    "            \"sparcity\": [total_points - total_uniques],\n",
    "            \"max_necc_base_value\":[0],\n",
    "            \"nodes+_req\": [0],\n",
    "            \"subsparcity\": [0],\n",
    "            \"unexplained\":[0],\n",
    "            \"sparcity_pcnt\": [(total_points - total_uniques) / total_points * 100],\n",
    "            \"subsparcity_pcnt\": [0],\n",
    "            \"denoise_pcnt\":[0],\n",
    "            \"complexity\":[0]\n",
    "        }\n",
    "\n",
    "        report = pd.DataFrame(results)\n",
    "    \n",
    "        for base in range(2,17):\n",
    "            results[\"base\"] = [base]\n",
    "            results[\"nodes_req\"] = [math.ceil(math.log(layer,(base)))]\n",
    "            results[\"nodes+_req\"] = [math.floor(math.log(layer,(base)))]\n",
    "            \n",
    "            results[\"sparcity\"] = [base**math.ceil(math.log(layer,base)) - layer]\n",
    "            results[\"subsparcity\"] = [-(base**math.floor(math.log(layer,base)) - layer)]\n",
    "            \n",
    "            results[\"sparcity_pcnt\"] = [(base**math.ceil(math.log(layer,(base))) - base**math.log(layer,(base)))/(base**math.ceil(math.log(layer,(base))))*100]\n",
    "            results[\"subsparcity_pcnt\"] = [-((base**math.floor(math.log(layer,(base))) - base**math.log(layer,(base)))/(base**math.floor(math.log(layer,(base))))*100)]\n",
    "            \n",
    "#             results[\"max_necc_base_value\"] = [numberToBase((results[\"base\"][0]**results[\"nodes+_req\"][0]+results[\"subsparcity\"][0]),results[\"base\"][0])]\n",
    "            results[\"max_necc_base_value\"] = [numberToBase(layer,base)]\n",
    "            results[\"unexplained\"] = [(-(base**math.floor(math.log(layer,base)) - layer))*(math.floor(math.log(layer,(base))))]\n",
    "            \n",
    "            results[\"denoise_pcnt\"] = [math.floor(((total_points-(math.ceil(math.log(layer,base)))**2)/total_points)*100)]\n",
    "        \n",
    "            results[\"complexity\"] = [results[\"nodes_req\"][0]*(results[\"sparcity\"][0]+1)]\n",
    "\n",
    "            report = report.append(pd.DataFrame(results))\n",
    "            \n",
    "            \n",
    "        report.index = [x for x in range(1, len(report.values)+1)]\n",
    "        report.drop([1],axis=0,inplace=True)\n",
    "        report.sort_values([\"sparcity\",\"unexplained\",\"nodes+_req\",\"subsparcity\",\"sparcity_pcnt\",\"base\"],inplace=True)\n",
    "        \n",
    "        cf.append(report.iloc[0])\n",
    "    \n",
    "    return cf\n",
    "\n",
    "[print(r,\"\\n\") for r in feature_spacing()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the convolutional layers, base 13 seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\n",
      "For the linear layers, base 15 seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\n"
     ]
    }
   ],
   "source": [
    "bases = feature_spacing()\n",
    "print(\"For the convolutional layers, base %s seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\" % bases[0][\"base\"])\n",
    "print(\"For the linear layers, base %s seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\" % bases[1][\"base\"])\n",
    "\n",
    "# print(\"We can use the \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_c = bases[0][\"base\"]\n",
    "base_f = bases[1][\"base\"]\n",
    "\n",
    "def base_to_dec(num_list, base):\n",
    "    num_list = num_list[::-1]\n",
    "    num = 0\n",
    "    for k in range(len(num_list)):\n",
    "        dig = num_list[k]\n",
    "        dig = int(dig)\n",
    "        num += dig*(base**k)\n",
    "    return num\n",
    "\n",
    "def encode(config=[(24, 64),(13, 41)]):\n",
    "    iconv = c_comb.index(config[0])\n",
    "    ifull = f_comb.index(config[1])\n",
    "    \n",
    "    conv_hash = numberToBase(iconv,base_c)\n",
    "    full_hash = numberToBase(ifull,base_f)\n",
    "    \n",
    "    return [conv_hash,full_hash]\n",
    "\n",
    "def decode(hash=([1, 7, 5, 0], [2, 9, 7])):\n",
    "    conv = base_to_dec(hash[0], base_c)\n",
    "    full = base_to_dec(hash[1], base_f)\n",
    "\n",
    "    \n",
    "    return [c_comb[conv],f_comb[full]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move data into sets for loading\n",
    "def load_data(data_dir=d.absolute()):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset,testset = [torchvision.datasets.CIFAR10(root=data_dir, train=is_train, download=True, transform=transform) for is_train in [True,False]]\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamically-generated nn that takes a 3-channel image and outputs a label\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_layers=[[6, 16],[120,84]]):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_convs,hidden_fcs = hidden_layers\n",
    "#         print(hidden_convs)\n",
    "#         print(hidden_fcs)\n",
    "        uf_input = 0\n",
    "        layer_list = OrderedDict()\n",
    "        \n",
    "        layer_list['conv1'] = nn.Conv2d(3, hidden_convs[0], 5)\n",
    "        layer_list['pool1'] = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        layer_input = layer_list['conv1'].out_channels\n",
    "        \n",
    "        for layer_num, channels in enumerate(hidden_convs[1:], 2):\n",
    "            layer_list[\"conv%s\" % layer_num]  = nn.Conv2d(layer_input, channels, 5)\n",
    "            layer_list[\"pool%s\" % layer_num] = nn.MaxPool2d(2, 2)\n",
    "            layer_input = layer_list[\"conv%s\" % layer_num].out_channels\n",
    "        \n",
    "        \n",
    "        layer_list[\"flat\"] = nn.Flatten()\n",
    "        \n",
    "        layer_list['fc1'] = nn.Linear(layer_input*5*5, hidden_fcs[0])\n",
    "        layer_list[\"relu1\"]  = nn.ReLU()\n",
    "        \n",
    "        layer_input = layer_list['fc1'].out_features\n",
    "        for (layer_num, features) in enumerate(hidden_fcs[1:], 2):\n",
    "            layer_list[\"fc%s\" % layer_num]  = nn.Linear(layer_input, features)\n",
    "            layer_list[\"relu%s\" % layer_num]  = nn.ReLU()\n",
    "            layer_input = layer_list[\"fc%s\" % layer_num].out_features\n",
    "            \n",
    "        \n",
    "        layer_list['fco'] = nn.Linear(hidden_fcs[-1], 10)\n",
    "    \n",
    "        self.layers = nn.Sequential(layer_list)\n",
    "        \n",
    "#         print(\"New model: %s\" % hidden_layers)\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train nn on data\n",
    "def train_cifar(neuron_config, checkpoint_dir=None):\n",
    "    \n",
    "    data_dir=d.absolute()\n",
    "    \n",
    "    def cv_discrim(s): return 'conv_subindex_' in s\n",
    "    def fc_discrim(s): return 'full_subindex_' in s\n",
    "    cvs = [neuron_config[hp] for hp in list(filter(cv_discrim, neuron_config.keys()))]\n",
    "    fcs = [neuron_config[hp] for hp in list(filter(fc_discrim, neuron_config.keys()))]\n",
    "    \n",
    "    cfg = decode([cvs, fcs])    \n",
    "    net = Net(cfg)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=neuron_config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader,valloader = [torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(neuron_config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=1) for subset in [train_subset,val_subset]]\n",
    "\n",
    "    for epoch in range(neuron_config[\"epochs\"]):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"Model: %s, Epoch: %d, Mini-batch: %5d, Loss: %.3f\" % (cfg,epoch + 1, i + 1, running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=(correct / total))\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy score\n",
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=1)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine configuration boundary for nn based on number of layers\n",
    "nodes_c = bases[0][\"nodes_req\"]\n",
    "nodes_f = bases[1][\"nodes_req\"]\n",
    "max_c = bases[0][\"max_necc_base_value\"]\n",
    "max_f = bases[1][\"max_necc_base_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def configure_neurons(num_convs,num_fcs):\n",
    "def configure_neurons():\n",
    "    config_space = CS.ConfigurationSpace()\n",
    "    \n",
    "    config_space.add_hyperparameter(\n",
    "        CS.UniformFloatHyperparameter(name=\"lr\", lower=1e-4, upper=1e-1, log=True))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"batch_size\", choices=[4, 8, 16, 32]))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"epochs\", choices=[20, 30, 40]))\n",
    "    \n",
    "    conv_lims,full_lims = [],[]\n",
    "    \n",
    "    for subindex in range(nodes_c):\n",
    "        # define hyperparameter reference attributes\n",
    "        rule_name = \"conv_subindex_%s\" % subindex\n",
    "        conv_rule = CS.UniformIntegerHyperparameter(rule_name, lower=0, upper=base_c-1, default_value=subindex%(base_c-1))\n",
    "        \n",
    "        # add hyperparameter to collections\n",
    "        config_space.add_hyperparameter(conv_rule)\n",
    "    \n",
    "        conv_rules = list(filter(lambda hp: \"conv_subindex_\" in hp.name, config_space.get_hyperparameters()))\n",
    "    \n",
    "        # build banlist from collections\n",
    "        rl = deepcopy(config_space)\n",
    "        rd = {}\n",
    "        for ri,rule in enumerate(conv_rules,1):\n",
    "    \n",
    "            if (len(conv_rules) == 1) & (max_c[ri-1] == config_space.get_hyperparameter(rule_name).upper):\n",
    "                break\n",
    "            elif ri != len(conv_rules):\n",
    "                rd[rule.name] = CS.ForbiddenEqualsClause(\n",
    "                        rule,\n",
    "                        max_c[ri-1]\n",
    "                    )\n",
    "            else:\n",
    "                rd[rule.name] = CS.ForbiddenInClause(\n",
    "                        rule,\n",
    "                        range(\n",
    "                            max_c[ri-1] + 1, \n",
    "                            rule.upper + 1\n",
    "                        )\n",
    "                    )\n",
    "        \n",
    "        # package banlist for addition to config space\n",
    "        if rd.values():\n",
    "            config_space.add_forbidden_clause(\n",
    "                CS.ForbiddenAndConjunction(\n",
    "                    *rd.values()\n",
    "                )\n",
    "            )           \n",
    "    \n",
    "    for subindex in range(nodes_f):\n",
    "        # define hyperparameter reference attributes\n",
    "        rule_name = \"full_subindex_%s\" % subindex\n",
    "        full_rule = CS.UniformIntegerHyperparameter(rule_name, lower=0, upper=base_f-1, default_value=subindex%(base_f-1))\n",
    "        \n",
    "        # add hyperparameter to collections\n",
    "        config_space.add_hyperparameter(full_rule)\n",
    "    \n",
    "        full_rules = list(filter(lambda hp: \"full_subindex_\" in hp.name, config_space.get_hyperparameters()))\n",
    "    \n",
    "        # build banlist from collections\n",
    "        rl = deepcopy(config_space)\n",
    "        rd = {}\n",
    "        for ri,rule in enumerate(full_rules,1):\n",
    "            if (len(full_rules) == 1) & (max_f[ri-1] == config_space.get_hyperparameter(rule_name).upper):\n",
    "#                 print(\"breaking\")\n",
    "                break\n",
    "            elif ri != len(full_rules):\n",
    "                rd[rule.name] = CS.ForbiddenEqualsClause(\n",
    "                        rule,\n",
    "                        max_f[ri-1]\n",
    "                    )\n",
    "            else:\n",
    "                rd[rule.name] = CS.ForbiddenInClause(\n",
    "                        rule,\n",
    "                        range(\n",
    "                            max_f[ri-1] + 1, \n",
    "                            rule.upper + 1\n",
    "                        )\n",
    "                    )\n",
    "        # add banlist to collection\n",
    "        if rd.values():\n",
    "            config_space.add_forbidden_clause(\n",
    "                CS.ForbiddenAndConjunction(\n",
    "                    *rd.values()\n",
    "                )\n",
    "            )           \n",
    "        \n",
    "    return config_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    batch_size, Type: Categorical, Choices: {4, 8, 16, 32}, Default: 4\n",
      "    conv_subindex_0, Type: UniformInteger, Range: [0, 12], Default: 0\n",
      "    conv_subindex_1, Type: UniformInteger, Range: [0, 12], Default: 1\n",
      "    conv_subindex_2, Type: UniformInteger, Range: [0, 12], Default: 2\n",
      "    conv_subindex_3, Type: UniformInteger, Range: [0, 12], Default: 3\n",
      "    epochs, Type: Categorical, Choices: {20, 30, 40}, Default: 20\n",
      "    full_subindex_0, Type: UniformInteger, Range: [0, 14], Default: 0\n",
      "    full_subindex_1, Type: UniformInteger, Range: [0, 14], Default: 1\n",
      "    full_subindex_2, Type: UniformInteger, Range: [0, 14], Default: 2\n",
      "    full_subindex_3, Type: UniformInteger, Range: [0, 14], Default: 3\n",
      "    full_subindex_4, Type: UniformInteger, Range: [0, 14], Default: 4\n",
      "    lr, Type: UniformFloat, Range: [0.0001, 0.1], Default: 0.0031622777, on log-scale\n",
      "  Forbidden Clauses:\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 in {7, 8, 9, 10, 11, 12})\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 == 6 && Forbidden: conv_subindex_2 in {10, 11, 12})\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 == 6 && Forbidden: conv_subindex_2 == 9 && Forbidden: conv_subindex_3 in {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12})\n",
      "    (Forbidden: full_subindex_0 in {13, 14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 in {9, 10, 11, 12, 13, 14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 == 8 && Forbidden: full_subindex_2 in {4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 == 8 && Forbidden: full_subindex_2 == 3 && Forbidden: full_subindex_3 in {14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 == 8 && Forbidden: full_subindex_2 == 3 && Forbidden: full_subindex_3 == 13 && Forbidden: full_subindex_4 in {6, 7, 8, 9, 10, 11, 12, 13, 14})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(configure_neurons())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform neuron configuration trials\n",
    "def search_neurons(checkpoint_dir=None):    \n",
    "    neuron_config_space = configure_neurons()\n",
    "    \n",
    "    experiment_metrics = dict(metric=\"accuracy\", mode=\"max\")\n",
    "    \n",
    "    #pre-load data to avoid races\n",
    "    load_data()\n",
    "    \n",
    "    scheduler = HyperBandForBOHB(\n",
    "        max_t=20,\n",
    "        reduction_factor=2,\n",
    "        **experiment_metrics)\n",
    "    search = TuneBOHB(\n",
    "        neuron_config_space,\n",
    "        max_concurrent=8,\n",
    "        **experiment_metrics)\n",
    "    reporter = JupyterNotebookReporter(\n",
    "        overwrite=True,\n",
    "        parameter_columns=neuron_config_space.get_hyperparameter_names(),\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_cifar),\n",
    "        verbose=2,\n",
    "        name=\"neurons\",\n",
    "        local_dir=r.absolute(),\n",
    "        resources_per_trial={\"cpu\": cpu_use, \"gpu\": gpu_use},\n",
    "        max_failures=3,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "    \n",
    "    def cv_discrim(s): return 'conv_subindex_' in s\n",
    "    def fc_discrim(s): return 'full_subindex_' in s\n",
    "    def other_discrim(s): return 'subindex' not in s\n",
    "    best_cvs = [best_trial.config[hp] for hp in list(filter(cv_discrim, best_trial.config.keys()))]\n",
    "    best_fcs = [best_trial.config[hp] for hp in list(filter(fc_discrim, best_trial.config.keys()))]\n",
    "    best_other = [best_trial.config[hp] for hp in list(filter(other_discrim, best_trial.config.keys()))]\n",
    "\n",
    "    cfg = decode([best_cvs, best_fcs])\n",
    "    \n",
    "    conv_report = [\"Connolutional Layer %s: %s\" % (i,c) for i,c in enumerate(cfg[0])]\n",
    "    full_report = [\"Fully-connected Layer %s: %s\" % (i,f) for i,f in enumerate(cfg[1])]\n",
    "    other_report = [\"%s: %s\" % (hp,f) for (hp,f) in zip([\"Batch Size\",\"Epochs\",\"Learning Rate\"],best_other)]\n",
    "\n",
    "#     print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial config:\")\n",
    "    [print(best) for best in [conv_report,full_report,other_report]]\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "    \n",
    "    best_trained_model = Net(cfg)\n",
    "    best_training_hyperparameters = zip([\"Batch Size\",\"Epochs\",\"Learning Rate\"],best_other)\n",
    "    \n",
    "    if gpus_per_trial > 1:\n",
    "        best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    \n",
    "    if checkpoint_dir != None:\n",
    "        tune.report(accuracy=test_acc)\n",
    "    \n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "    \n",
    "    return (best_trained_model.state_dict(), dict(best_training_hyperparameters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform test\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    model = search_layers(num_samples=10, max_num_epochs=10, gpus_per_trial=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource usage can be viewed at port http://127.0.0.1:8265/ or higher\n"
     ]
    }
   ],
   "source": [
    "print(\"Resource usage can be viewed at port http://127.0.0.1:8265/ or higher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 17.8/31.9 GiB<br>Using HyperBand: num_stopped=15 total_brackets=1\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=1, Milestone (r)=12, completed=100.0%): {TERMINATED: 16} <br>Resources requested: 0.0/4 CPUs, 0/0 GPUs, 0.0/9.72 GiB heap, 0.0/3.32 GiB objects<br>Result logdir: /home/francisn/Source/CIFAR-Trainer/ray_results/neurons<br>Number of trials: 16/16 (16 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_subindex_0</th><th style=\"text-align: right;\">  conv_subindex_1</th><th style=\"text-align: right;\">  conv_subindex_2</th><th style=\"text-align: right;\">  conv_subindex_3</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  full_subindex_0</th><th style=\"text-align: right;\">  full_subindex_1</th><th style=\"text-align: right;\">  full_subindex_2</th><th style=\"text-align: right;\">  full_subindex_3</th><th style=\"text-align: right;\">  full_subindex_4</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">      loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DEFAULT_d0f6be2a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">0.00685455 </td><td style=\"text-align: right;\">  1.527   </td><td style=\"text-align: right;\">  0.44505 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_d1dd0fb0</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">0.00169542 </td><td style=\"text-align: right;\">  0.797542</td><td style=\"text-align: right;\">  0.723925</td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>DEFAULT_d288eb46</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">               14</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">0.00657143 </td><td style=\"text-align: right;\">  1.34314 </td><td style=\"text-align: right;\">  0.5124  </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_d379fd10</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">0.000312478</td><td style=\"text-align: right;\">  2.04119 </td><td style=\"text-align: right;\">  0.19545 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_d4584c46</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.00048399 </td><td style=\"text-align: right;\">  2.29109 </td><td style=\"text-align: right;\">  0.173875</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_d7c42968</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">0.00541258 </td><td style=\"text-align: right;\">  1.40613 </td><td style=\"text-align: right;\">  0.537725</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_da8de38c</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">0.0665782  </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">  0.1013  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_df671c34</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">0.000469639</td><td style=\"text-align: right;\">  2.28008 </td><td style=\"text-align: right;\">  0.1683  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_a8e96530</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">0.00132687 </td><td style=\"text-align: right;\">  0.593206</td><td style=\"text-align: right;\">  0.7974  </td><td style=\"text-align: right;\">                  12</td></tr>\n",
       "<tr><td>DEFAULT_854c6842</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">0.00452009 </td><td style=\"text-align: right;\">  1.46858 </td><td style=\"text-align: right;\">  0.45735 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_a180c788</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">0.000220235</td><td style=\"text-align: right;\">  2.30446 </td><td style=\"text-align: right;\">  0.100075</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_84ce4218</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">0.0161336  </td><td style=\"text-align: right;\">  2.30529 </td><td style=\"text-align: right;\">  0.100425</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_aeaf296c</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">0.0070625  </td><td style=\"text-align: right;\">  1.2227  </td><td style=\"text-align: right;\">  0.5774  </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_d95d3104</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">0.000366552</td><td style=\"text-align: right;\">  1.94259 </td><td style=\"text-align: right;\">  0.24695 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_3b3ccb5a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">0.0142308  </td><td style=\"text-align: right;\">  1.52007 </td><td style=\"text-align: right;\">  0.4541  </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_b4206a04</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">               14</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">0.0587552  </td><td style=\"text-align: right;\">  2.30897 </td><td style=\"text-align: right;\">  0.100675</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-31 14:55:54,173\tINFO tune.py:439 -- Total run time: 10044.43 seconds (10039.54 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config:\n",
      "['Connolutional Layer 0: 111', 'Connolutional Layer 1: 205']\n",
      "['Fully-connected Layer 0: 24', 'Fully-connected Layer 1: 42', 'Fully-connected Layer 2: 49', 'Fully-connected Layer 3: 52']\n",
      "['Batch Size: 8', 'Epochs: 40', 'Learning Rate: 0.0013268716294267415']\n",
      "Best trial final validation loss: 0.5932061404310167\n",
      "Best trial final validation accuracy: 0.7974\n",
      "New model: [(111, 205), (24, 42, 49, 52)]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Best trial test set accuracy: 0.6565\n"
     ]
    }
   ],
   "source": [
    "model,trainers = search_neurons()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
