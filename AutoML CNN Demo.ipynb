{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial # for trials\n",
    "import numpy as np # for accuracy math\n",
    "import os # for paths\n",
    "import torch # for nn instantiation\n",
    "import torch.nn as nn # for nn objects\n",
    "import torch.nn.functional as F # for forward method\n",
    "import torch.optim as optim # for optimization\n",
    "from torch.utils.data import random_split # for train/test split\n",
    "import torchvision # for data transforms\n",
    "import torchvision.transforms as transforms # for transform methods\n",
    "from ray import tune # for trialing\n",
    "from ray.tune import CLIReporter # for trial reporting\n",
    "from ray.tune import JupyterNotebookReporter # for trial reporting\n",
    "from ray.tune.schedulers import ASHAScheduler # for trial scheduling\n",
    "from ray.tune.schedulers import HyperBandForBOHB # for trial scheduling\n",
    "from ray.tune.suggest.bohb import TuneBOHB # for trial selection/pruning\n",
    "import ConfigSpace as CS # for configuration bounds\n",
    "from collections import OrderedDict # for dynamic configuration definition\n",
    "from pathlib import Path # for OS agnostic path definition\n",
    "\n",
    "# import itertools package \n",
    "import itertools \n",
    "from itertools import combinations, combinations_with_replacement\n",
    "from itertools import product\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# allow configuration copying\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data and checkpoint locations\n",
    "p = Path('.')\n",
    "d = p / 'data'\n",
    "r = p / 'ray_results'\n",
    "l = p / 'checkpoints' / 'layers'\n",
    "n = p / 'checkpoints' / 'layers'\n",
    "\n",
    "# set computation location(s)\n",
    "gpus = torch.cuda.device_count()\n",
    "device = \"cuda:0\" if gpus else \"cpu\"\n",
    "\n",
    "# set number or fraction of processing units (per training worker) you'd like to utilize, if any at all\n",
    "# cpu_use must be grater than zero\n",
    "cpu_use = 1 if gpus else 0.5\n",
    "gpu_use = 0.25 if gpus else 0\n",
    "\n",
    "# set experiment hyperparameters\n",
    "num_samples = 2 ** (6 if gpus else 5)\n",
    "max_num_epochs = 10 * (4 if gpus else 1)\n",
    "gpus_per_trial = 1 if gpus else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the neuron configuration we want is dependent upon the number of layers we have, we need to work flatten the feature space a bit. We can reduce the high-dminesional setups to a slightly less high-dminesional string of base-n nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base                              13\n",
      "nodes_req                          4\n",
      "sparcity                        1066\n",
      "max_necc_base_value    [12, 6, 9, 0]\n",
      "nodes+_req                         3\n",
      "subsparcity                    25298\n",
      "unexplained                    75894\n",
      "sparcity_pcnt                3.73236\n",
      "subsparcity_pcnt             1151.48\n",
      "denoise_pcnt                   -1500\n",
      "complexity                      4268\n",
      "Name: 13, dtype: object \n",
      "\n",
      "base                                  15\n",
      "nodes_req                              5\n",
      "sparcity                          124000\n",
      "max_necc_base_value    [12, 8, 3, 13, 5]\n",
      "nodes+_req                             4\n",
      "subsparcity                       584750\n",
      "unexplained                      2339000\n",
      "sparcity_pcnt                    16.3292\n",
      "subsparcity_pcnt                 1155.06\n",
      "denoise_pcnt                       -2400\n",
      "complexity                        620005\n",
      "Name: 15, dtype: object \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define feature space for hashing\n",
    "c_min = 3**2\n",
    "c_max = 3**5\n",
    "f_min = 2**2\n",
    "f_max = 2**6\n",
    "\n",
    "c = c_max - c_min\n",
    "f = f_max - f_min\n",
    "\n",
    "# conv = set(range(c_max)) - set(range(c_min))\n",
    "# full = set(range(f_max)) - set(range(f_min))\n",
    "conv = range(c_max)[c_min:]\n",
    "full = range(f_max)[f_min:]\n",
    "\n",
    "c_comb = list(combinations_with_replacement(conv,2))\n",
    "f_comb = []\n",
    "for layers in range(1,5):\n",
    "    f_comb += list(combinations_with_replacement(full,layers))\n",
    "#     print(\"Fully connected layer %s range: %s\" % (layers,len(f_comb)) )\n",
    "#     print(\"\\n\")\n",
    "\n",
    "# for conversion from dec to whatever we end up using\n",
    "# most to least significant digit\n",
    "def numberToBase(n, b):\n",
    "    if n == 0:\n",
    "        return [0]\n",
    "    digits = []\n",
    "    while n:\n",
    "        digits.append(int(n % b))\n",
    "        n //= b\n",
    "    rev = digits[::-1]\n",
    "    return rev\n",
    "\n",
    "def feature_spacing():\n",
    "    \n",
    "    # create empty list to store the \n",
    "    # combinations \n",
    "    unique_combinations = list(combinations([c_comb,f_comb],2))\n",
    "    total_uniques = len(unique_combinations)\n",
    "    total_points = total_uniques**2\n",
    "    total_cvs = len(c_comb)\n",
    "    total_fcs = len(f_comb)\n",
    "    \n",
    "    columns = [\"base\",\"nodes_req\",\"sparcity\",\"sparcity_pcnt\",\"denoise_pcnt\"]\n",
    "    values = [1,total_uniques,total_points - total_uniques,(total_points - total_uniques) / total_points,0]\n",
    "    \n",
    "    cf = []\n",
    "    \n",
    "    for layer in [total_cvs,total_fcs]:#,total_uniques]:\n",
    "        results = {\n",
    "            \"base\": [1],\n",
    "            \"nodes_req\": [total_uniques],\n",
    "            \"sparcity\": [total_points - total_uniques],\n",
    "            \"max_necc_base_value\":[0],\n",
    "            \"nodes+_req\": [0],\n",
    "            \"subsparcity\": [0],\n",
    "            \"unexplained\":[0],\n",
    "            \"sparcity_pcnt\": [(total_points - total_uniques) / total_points * 100],\n",
    "            \"subsparcity_pcnt\": [0],\n",
    "            \"denoise_pcnt\":[0],\n",
    "            \"complexity\":[0]\n",
    "        }\n",
    "\n",
    "        report = pd.DataFrame(results)\n",
    "    \n",
    "        for base in range(2,17):\n",
    "            results[\"base\"] = [base]\n",
    "            results[\"nodes_req\"] = [math.ceil(math.log(layer,(base)))]\n",
    "            results[\"nodes+_req\"] = [math.floor(math.log(layer,(base)))]\n",
    "            \n",
    "            results[\"sparcity\"] = [base**math.ceil(math.log(layer,base)) - layer]\n",
    "            results[\"subsparcity\"] = [-(base**math.floor(math.log(layer,base)) - layer)]\n",
    "            \n",
    "            results[\"sparcity_pcnt\"] = [(base**math.ceil(math.log(layer,(base))) - base**math.log(layer,(base)))/(base**math.ceil(math.log(layer,(base))))*100]\n",
    "            results[\"subsparcity_pcnt\"] = [-((base**math.floor(math.log(layer,(base))) - base**math.log(layer,(base)))/(base**math.floor(math.log(layer,(base))))*100)]\n",
    "            \n",
    "#             results[\"max_necc_base_value\"] = [numberToBase((results[\"base\"][0]**results[\"nodes+_req\"][0]+results[\"subsparcity\"][0]),results[\"base\"][0])]\n",
    "            results[\"max_necc_base_value\"] = [numberToBase(layer,base)]\n",
    "            results[\"unexplained\"] = [(-(base**math.floor(math.log(layer,base)) - layer))*(math.floor(math.log(layer,(base))))]\n",
    "            \n",
    "            results[\"denoise_pcnt\"] = [math.floor(((total_points-(math.ceil(math.log(layer,base)))**2)/total_points)*100)]\n",
    "        \n",
    "            results[\"complexity\"] = [results[\"nodes_req\"][0]*(results[\"sparcity\"][0]+1)]\n",
    "\n",
    "            report = report.append(pd.DataFrame(results))\n",
    "            \n",
    "            \n",
    "        report.index = [x for x in range(1, len(report.values)+1)]\n",
    "        report.drop([1],axis=0,inplace=True)\n",
    "        report.sort_values([\"sparcity\",\"unexplained\",\"nodes+_req\",\"subsparcity\",\"sparcity_pcnt\",\"base\"],inplace=True)\n",
    "        \n",
    "        cf.append(report.iloc[0])\n",
    "    \n",
    "    return cf\n",
    "\n",
    "[print(r,\"\\n\") for r in feature_spacing()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the convolutional layers, base 13 seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\n",
      "For the linear layers, base 15 seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\n"
     ]
    }
   ],
   "source": [
    "bases = feature_spacing()\n",
    "print(\"For the convolutional layers, base %s seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\" % bases[0][\"base\"])\n",
    "print(\"For the linear layers, base %s seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\" % bases[1][\"base\"])\n",
    "\n",
    "# print(\"We can use the \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_c = bases[0][\"base\"]\n",
    "base_f = bases[1][\"base\"]\n",
    "\n",
    "def base_to_dec(num_list, base):\n",
    "    num_list = num_list[::-1]\n",
    "    num = 0\n",
    "    for k in range(len(num_list)):\n",
    "        dig = num_list[k]\n",
    "        dig = int(dig)\n",
    "        num += dig*(base**k)\n",
    "    return num\n",
    "\n",
    "def encode(config=[(24, 64),(13, 41)]):\n",
    "    iconv = c_comb.index(config[0])\n",
    "    ifull = f_comb.index(config[1])\n",
    "    \n",
    "    conv_hash = numberToBase(iconv,base_c)\n",
    "    full_hash = numberToBase(ifull,base_f)\n",
    "    \n",
    "    return [conv_hash,full_hash]\n",
    "\n",
    "def decode(hash=([1, 7, 5, 0], [2, 9, 7])):\n",
    "    conv = base_to_dec(hash[0], base_c)\n",
    "    full = base_to_dec(hash[1], base_f)\n",
    "\n",
    "    \n",
    "    return [c_comb[conv],f_comb[full]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move data into sets for loading\n",
    "def load_data(data_dir=d.absolute()):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset,testset = [torchvision.datasets.CIFAR10(root=data_dir, train=is_train, download=True, transform=transform) for is_train in [True,False]]\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamically-generated nn that takes a 3-channel image and outputs a label\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_layers=[[6, 16],[120,84]]):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_convs,hidden_fcs = hidden_layers\n",
    "#         print(hidden_convs)\n",
    "#         print(hidden_fcs)\n",
    "        uf_input = 0\n",
    "        layer_list = OrderedDict()\n",
    "        \n",
    "        layer_list['conv1'] = nn.Conv2d(3, hidden_convs[0], 5)\n",
    "        layer_list['pool1'] = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        layer_input = layer_list['conv1'].out_channels\n",
    "        \n",
    "        for layer_num, channels in enumerate(hidden_convs[1:], 2):\n",
    "            layer_list[\"conv%s\" % layer_num]  = nn.Conv2d(layer_input, channels, 5)\n",
    "            layer_list[\"pool%s\" % layer_num] = nn.MaxPool2d(2, 2)\n",
    "            layer_input = layer_list[\"conv%s\" % layer_num].out_channels\n",
    "        \n",
    "        \n",
    "        layer_list[\"flat\"] = nn.Flatten()\n",
    "        \n",
    "        layer_list['fc1'] = nn.Linear(layer_input*5*5, hidden_fcs[0])\n",
    "        layer_list[\"relu1\"]  = nn.ReLU()\n",
    "        \n",
    "        layer_input = layer_list['fc1'].out_features\n",
    "        for (layer_num, features) in enumerate(hidden_fcs[1:], 2):\n",
    "            layer_list[\"fc%s\" % layer_num]  = nn.Linear(layer_input, features)\n",
    "            layer_list[\"relu%s\" % layer_num]  = nn.ReLU()\n",
    "            layer_input = layer_list[\"fc%s\" % layer_num].out_features\n",
    "            \n",
    "        \n",
    "        layer_list['fco'] = nn.Linear(hidden_fcs[-1], 10)\n",
    "    \n",
    "        self.layers = nn.Sequential(layer_list)\n",
    "        \n",
    "        print(\"New model: %s\" % hidden_layers)\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train nn on data\n",
    "def train_cifar(neuron_config, checkpoint_dir=None):\n",
    "    \n",
    "    data_dir=d.absolute()\n",
    "    \n",
    "    def cv_discrim(s): return 'conv_subindex_' in s\n",
    "    def fc_discrim(s): return 'full_subindex_' in s\n",
    "    cvs = [neuron_config[hp] for hp in list(filter(cv_discrim, neuron_config.keys()))]\n",
    "    fcs = [neuron_config[hp] for hp in list(filter(fc_discrim, neuron_config.keys()))]\n",
    "    \n",
    "    cfg = decode([cvs, fcs])    \n",
    "    net = Net(cfg)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=neuron_config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader,valloader = [torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(neuron_config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=1) for subset in [train_subset,val_subset]]\n",
    "\n",
    "    for epoch in range(neuron_config[\"epochs\"]):  # loop over the dataset multiple times\n",
    "        print(\"Epoch:\",epoch)\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"Model: %s, Epoch: %d, Mini-batch: %5d, Loss: %.3f\" % (cfg,epoch + 1, i + 1, running_loss / epoch_steps))\n",
    "#                 print(\"Model: %s, Epoch: %s, Mini-batch: %5d, Loss: %.3f\" % (cfg, epoch + 1, i + 1, running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=(correct / total))\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cifar({\"lr\":0.00218168,\"batch_size\":32,\"epochs\":40,\"conv_subindex_0\":24,\"conv_subindex_1\":64,\"full_subindex_0\":13,\"full_subindex_o\":41})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy score\n",
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=1)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine configuration boundary for nn based on number of layers\n",
    "nodes_c = bases[0][\"nodes_req\"]\n",
    "nodes_f = bases[1][\"nodes_req\"]\n",
    "max_c = bases[0][\"max_necc_base_value\"]\n",
    "max_f = bases[1][\"max_necc_base_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def configure_neurons(num_convs,num_fcs):\n",
    "def configure_neurons():\n",
    "    config_space = CS.ConfigurationSpace()\n",
    "    \n",
    "    config_space.add_hyperparameter(\n",
    "        CS.UniformFloatHyperparameter(name=\"lr\", lower=1e-4, upper=1e-1, log=True))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"batch_size\", choices=[4, 8, 16, 32]))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"epochs\", choices=[20, 30, 40]))\n",
    "    \n",
    "    conv_lims,full_lims = [],[]\n",
    "    \n",
    "    for subindex in range(nodes_c):\n",
    "        # define hyperparameter reference attributes\n",
    "        rule_name = \"conv_subindex_%s\" % subindex\n",
    "        conv_rule = CS.UniformIntegerHyperparameter(rule_name, lower=0, upper=base_c-1, default_value=subindex%(base_c-1))\n",
    "        \n",
    "        # add hyperparameter to collections\n",
    "        config_space.add_hyperparameter(conv_rule)\n",
    "    \n",
    "        conv_rules = list(filter(lambda hp: \"conv_subindex_\" in hp.name, config_space.get_hyperparameters()))\n",
    "    \n",
    "        # build banlist from collections\n",
    "        rl = deepcopy(config_space)\n",
    "        rd = {}\n",
    "        for ri,rule in enumerate(conv_rules,1):\n",
    "    \n",
    "            if (len(conv_rules) == 1) & (max_c[ri-1] == config_space.get_hyperparameter(rule_name).upper):\n",
    "                break\n",
    "            elif ri != len(conv_rules):\n",
    "                rd[rule.name] = CS.ForbiddenEqualsClause(\n",
    "                        rule,\n",
    "                        max_c[ri-1]\n",
    "                    )\n",
    "            else:\n",
    "                rd[rule.name] = CS.ForbiddenInClause(\n",
    "                        rule,\n",
    "                        range(\n",
    "                            max_c[ri-1] + 1, \n",
    "                            rule.upper + 1\n",
    "                        )\n",
    "                    )\n",
    "        \n",
    "        # package banlist for addition to config space\n",
    "        if rd.values():\n",
    "            config_space.add_forbidden_clause(\n",
    "                CS.ForbiddenAndConjunction(\n",
    "                    *rd.values()\n",
    "                )\n",
    "            )           \n",
    "    \n",
    "    for subindex in range(nodes_f):\n",
    "        # define hyperparameter reference attributes\n",
    "        rule_name = \"full_subindex_%s\" % subindex\n",
    "        full_rule = CS.UniformIntegerHyperparameter(rule_name, lower=0, upper=base_f-1, default_value=subindex%(base_f-1))\n",
    "        \n",
    "        # add hyperparameter to collections\n",
    "        config_space.add_hyperparameter(full_rule)\n",
    "    \n",
    "        full_rules = list(filter(lambda hp: \"full_subindex_\" in hp.name, config_space.get_hyperparameters()))\n",
    "    \n",
    "        # build banlist from collections\n",
    "        rl = deepcopy(config_space)\n",
    "        rd = {}\n",
    "        for ri,rule in enumerate(full_rules,1):\n",
    "            if (len(full_rules) == 1) & (max_f[ri-1] == config_space.get_hyperparameter(rule_name).upper):\n",
    "#                 print(\"breaking\")\n",
    "                break\n",
    "            elif ri != len(full_rules):\n",
    "                rd[rule.name] = CS.ForbiddenEqualsClause(\n",
    "                        rule,\n",
    "                        max_f[ri-1]\n",
    "                    )\n",
    "            else:\n",
    "                rd[rule.name] = CS.ForbiddenInClause(\n",
    "                        rule,\n",
    "                        range(\n",
    "                            max_f[ri-1] + 1, \n",
    "                            rule.upper + 1\n",
    "                        )\n",
    "                    )\n",
    "        # add banlist to collection\n",
    "        if rd.values():\n",
    "            config_space.add_forbidden_clause(\n",
    "                CS.ForbiddenAndConjunction(\n",
    "                    *rd.values()\n",
    "                )\n",
    "            )           \n",
    "        \n",
    "    return config_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    batch_size, Type: Categorical, Choices: {4, 8, 16, 32}, Default: 4\n",
      "    conv_subindex_0, Type: UniformInteger, Range: [0, 12], Default: 0\n",
      "    conv_subindex_1, Type: UniformInteger, Range: [0, 12], Default: 1\n",
      "    conv_subindex_2, Type: UniformInteger, Range: [0, 12], Default: 2\n",
      "    conv_subindex_3, Type: UniformInteger, Range: [0, 12], Default: 3\n",
      "    epochs, Type: Categorical, Choices: {20, 30, 40}, Default: 20\n",
      "    full_subindex_0, Type: UniformInteger, Range: [0, 14], Default: 0\n",
      "    full_subindex_1, Type: UniformInteger, Range: [0, 14], Default: 1\n",
      "    full_subindex_2, Type: UniformInteger, Range: [0, 14], Default: 2\n",
      "    full_subindex_3, Type: UniformInteger, Range: [0, 14], Default: 3\n",
      "    full_subindex_4, Type: UniformInteger, Range: [0, 14], Default: 4\n",
      "    lr, Type: UniformFloat, Range: [0.0001, 0.1], Default: 0.0031622777, on log-scale\n",
      "  Forbidden Clauses:\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 in {7, 8, 9, 10, 11, 12})\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 == 6 && Forbidden: conv_subindex_2 in {10, 11, 12})\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 == 6 && Forbidden: conv_subindex_2 == 9 && Forbidden: conv_subindex_3 in {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12})\n",
      "    (Forbidden: full_subindex_0 in {13, 14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 in {9, 10, 11, 12, 13, 14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 == 8 && Forbidden: full_subindex_2 in {4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 == 8 && Forbidden: full_subindex_2 == 3 && Forbidden: full_subindex_3 in {14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 == 8 && Forbidden: full_subindex_2 == 3 && Forbidden: full_subindex_3 == 13 && Forbidden: full_subindex_4 in {6, 7, 8, 9, 10, 11, 12, 13, 14})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(configure_neurons())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform neuron configuration trials\n",
    "def search_neurons(checkpoint_dir=None):    \n",
    "    neuron_config_space = configure_neurons()\n",
    "    \n",
    "    experiment_metrics = dict(metric=\"accuracy\", mode=\"max\")\n",
    "    \n",
    "    #pre-load data to avoid races\n",
    "    load_data()\n",
    "    \n",
    "    scheduler = HyperBandForBOHB(\n",
    "        max_t=20,\n",
    "        reduction_factor=2,\n",
    "        **experiment_metrics)\n",
    "    search = TuneBOHB(\n",
    "        neuron_config_space,\n",
    "        max_concurrent=8,\n",
    "        **experiment_metrics)\n",
    "    reporter = JupyterNotebookReporter(\n",
    "        overwrite=True,\n",
    "        parameter_columns=neuron_config_space.get_hyperparameter_names(),\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_cifar),\n",
    "        verbose=2,\n",
    "        name=\"neurons\",\n",
    "        local_dir=r.absolute(),\n",
    "        resources_per_trial={\"cpu\": cpu_use, \"gpu\": gpu_use},\n",
    "        max_failures=3,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "    \n",
    "    def cv_discrim(s): return 'conv_subindex_' in s\n",
    "    def fc_discrim(s): return 'full_subindex_' in s\n",
    "    def other_discrim(s): return 'subindex' not in s\n",
    "    best_cvs = [best_trial.config[hp] for hp in list(filter(cv_discrim, best_trial.config.keys()))]\n",
    "    best_fcs = [best_trial.config[hp] for hp in list(filter(fc_discrim, best_trial.config.keys()))]\n",
    "    best_other = [best_trial.config[hp] for hp in list(filter(other_discrim, best_trial.config.keys()))]\n",
    "\n",
    "    cfg = decode([best_cvs, best_fcs])\n",
    "    \n",
    "    conv_report = [\"Connolutional Layer %s: %s\" % (i,c) for i,c in enumerate(cfg[0])]\n",
    "    full_report = [\"Fully-connected Layer %s: %s\" % (i,f) for i,f in enumerate(cfg[1])]\n",
    "    other_report = [\"%s: %s\" % (i,f) for (hp,f) in zip([\"Batch Size\",\"Epochs\",\"Learning Rate\"],best_other)]\n",
    "\n",
    "#     print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial config:\")\n",
    "    [print(best) for best in [conv_report,full_report,other_report]]\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "    \n",
    "    best_trained_model = Net(cfg)\n",
    "    best_training_hyperparameters = zip([\"Batch Size\",\"Epochs\",\"Learning Rate\"],best_other)\n",
    "    \n",
    "    if gpus_per_trial > 1:\n",
    "        best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    \n",
    "    if checkpoint_dir != None:\n",
    "        tune.report(accuracy=test_acc)\n",
    "    \n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "    \n",
    "    return (best_trained_model.state_dict(), dict(best_training_hyperparameters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform test\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    model = search_layers(num_samples=10, max_num_epochs=10, gpus_per_trial=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource usage can be viewed at port http://127.0.0.1:8265/ or higher\n"
     ]
    }
   ],
   "source": [
    "print(\"Resource usage can be viewed at port http://127.0.0.1:8265/ or higher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.1/31.9 GiB<br>Using HyperBand: num_stopped=12 total_brackets=3\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=4, Milestone (r)=4, completed=-32.5%): {RUNNING: 4, TERMINATED: 12} \n",
       "  Bracket(Max Size (n)=10, Milestone (r)=2, completed=-19.8%): {PAUSED: 9, RUNNING: 1} \n",
       "  Bracket(Max Size (n)=7, Milestone (r)=5, completed=-5.7%): {RUNNING: 3} <br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/11.62 GiB heap, 0.0/4.0 GiB objects<br>Result logdir: /home/francisn/Source/CIFAR-Trainer/ray_results/neurons<br>Number of trials: 29/32 (9 PAUSED, 8 RUNNING, 12 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_subindex_0</th><th style=\"text-align: right;\">  conv_subindex_1</th><th style=\"text-align: right;\">  conv_subindex_2</th><th style=\"text-align: right;\">  conv_subindex_3</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  full_subindex_0</th><th style=\"text-align: right;\">  full_subindex_1</th><th style=\"text-align: right;\">  full_subindex_2</th><th style=\"text-align: right;\">  full_subindex_3</th><th style=\"text-align: right;\">  full_subindex_4</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DEFAULT_16cbf4aa</td><td>RUNNING   </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">               14</td><td style=\"text-align: right;\">               14</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">0.000893799</td><td style=\"text-align: right;\">1.45525</td><td style=\"text-align: right;\">  0.464775</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_1f9bb202</td><td>RUNNING   </td><td>10.21.130.174:11431</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">0.000621951</td><td style=\"text-align: right;\">1.36896</td><td style=\"text-align: right;\">  0.49775 </td><td style=\"text-align: right;\">                   3</td></tr>\n",
       "<tr><td>DEFAULT_26357f6c</td><td>RUNNING   </td><td>10.21.130.174:11491</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">0.00563069 </td><td style=\"text-align: right;\">1.26892</td><td style=\"text-align: right;\">  0.545375</td><td style=\"text-align: right;\">                   3</td></tr>\n",
       "<tr><td>DEFAULT_64ec93c4</td><td>RUNNING   </td><td>                   </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">0.0083976  </td><td style=\"text-align: right;\">1.26912</td><td style=\"text-align: right;\">  0.54015 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_6684a918</td><td>RUNNING   </td><td>10.21.130.174:11364</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">               14</td><td style=\"text-align: right;\">0.00103015 </td><td style=\"text-align: right;\">1.56079</td><td style=\"text-align: right;\">  0.416575</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_a15094a8</td><td>RUNNING   </td><td>10.21.130.174:11402</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               14</td><td style=\"text-align: right;\">0.0452809  </td><td style=\"text-align: right;\">2.30734</td><td style=\"text-align: right;\">  0.1     </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_ee830e3c</td><td>RUNNING   </td><td>10.21.130.174:11297</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">0.00141085 </td><td style=\"text-align: right;\">1.48669</td><td style=\"text-align: right;\">  0.4401  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_41f691a4</td><td>PAUSED    </td><td>                   </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">0.000187149</td><td style=\"text-align: right;\">2.29474</td><td style=\"text-align: right;\">  0.20215 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_4eb7ff86</td><td>PAUSED    </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">0.000179526</td><td style=\"text-align: right;\">1.71681</td><td style=\"text-align: right;\">  0.35435 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_5b5f4674</td><td>PAUSED    </td><td>                   </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.00218168 </td><td style=\"text-align: right;\">1.59363</td><td style=\"text-align: right;\">  0.405925</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_6637d4bc</td><td>PAUSED    </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.0176525  </td><td style=\"text-align: right;\">2.30716</td><td style=\"text-align: right;\">  0.10015 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_791b4d20</td><td>PAUSED    </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">0.000153306</td><td style=\"text-align: right;\">1.84139</td><td style=\"text-align: right;\">  0.27815 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_c945de3c</td><td>PAUSED    </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">0.000391438</td><td style=\"text-align: right;\">1.52209</td><td style=\"text-align: right;\">  0.425925</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_ce5198f4</td><td>PAUSED    </td><td>                   </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">               14</td><td style=\"text-align: right;\">0.00256234 </td><td style=\"text-align: right;\">1.62734</td><td style=\"text-align: right;\">  0.37095 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_1d22b87c</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">0.000228532</td><td style=\"text-align: right;\">1.57694</td><td style=\"text-align: right;\">  0.421775</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_1dfe76be</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.000184719</td><td style=\"text-align: right;\">2.29781</td><td style=\"text-align: right;\">  0.16075 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_1eaae84a</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">               14</td><td style=\"text-align: right;\">0.000481334</td><td style=\"text-align: right;\">2.30205</td><td style=\"text-align: right;\">  0.1263  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_21308930</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">0.000463447</td><td style=\"text-align: right;\">2.30067</td><td style=\"text-align: right;\">  0.101175</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_23596a92</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">0.000756113</td><td style=\"text-align: right;\">1.61749</td><td style=\"text-align: right;\">  0.406925</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_2b649e5a</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">0.0325021  </td><td style=\"text-align: right;\">2.31008</td><td style=\"text-align: right;\">  0.0999  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_2cdb6c30</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">0.00170584 </td><td style=\"text-align: right;\">1.70358</td><td style=\"text-align: right;\">  0.3198  </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 9 more trials not shown (1 RUNNING, 2 PAUSED, 5 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-29 17:32:12,526\tWARNING util.py:137 -- The `process_trial_save` operation took 1.0507347583770752 seconds to complete, which may be a performance bottleneck.\n"
     ]
    }
   ],
   "source": [
    "model,trainers = search_neurons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(\"%s size:\" % k[7:],\"\\n\",list(model[k].shape)) for k in model.keys()]\n",
    "print(\"\\n\",trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
