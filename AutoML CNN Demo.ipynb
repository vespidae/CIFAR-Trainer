{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial # for trials\n",
    "import numpy as np # for accuracy math\n",
    "import os # for paths\n",
    "import torch # for nn instantiation\n",
    "import torch.nn as nn # for nn objects\n",
    "import torch.nn.functional as F # for forward method\n",
    "import torch.optim as optim # for optimization\n",
    "from torch.utils.data import random_split # for train/test split\n",
    "import torchvision # for data transforms\n",
    "import torchvision.transforms as transforms # for transform methods\n",
    "from ray import tune # for trialing\n",
    "from ray.tune import CLIReporter # for trial reporting\n",
    "from ray.tune import JupyterNotebookReporter # for trial reporting\n",
    "from ray.tune.schedulers import ASHAScheduler # for trial scheduling\n",
    "from ray.tune.schedulers import HyperBandForBOHB # for trial scheduling\n",
    "from ray.tune.suggest.bohb import TuneBOHB # for trial selection/pruning\n",
    "import ConfigSpace as CS # for configuration bounds\n",
    "from collections import OrderedDict # for dynamic configuration definition\n",
    "from pathlib import Path # for OS agnostic path definition\n",
    "\n",
    "# import itertools package \n",
    "import itertools \n",
    "from itertools import combinations, combinations_with_replacement\n",
    "from itertools import product\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# allow configuration copying\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data and checkpoint locations\n",
    "p = Path('.')\n",
    "d = p / 'data'\n",
    "r = p / 'ray_results'\n",
    "l = p / 'checkpoints' / 'layers'\n",
    "n = p / 'checkpoints' / 'layers'\n",
    "\n",
    "# set computation location(s)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# set number or fraction of GPUs (per training loop) you'd like to utilize, if any at all\n",
    "cpu_use = 1\n",
    "gpu_use = 0.25 if torch.cuda.is_available() else 0\n",
    "\n",
    "# set experiment hyperparameters\n",
    "num_samples = 40 if torch.cuda.is_available() else 10\n",
    "max_num_epochs = 40 if torch.cuda.is_available() else 10\n",
    "gpus_per_trial = 1 if torch.cuda.is_available() else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the neuron configuration we want is dependent upon the number of layers we have, we need to work flatten the feature space a bit. We can reduce the high-dminesional setups to a slightly less high-dminesional string of base-n nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully connected layer 1 range: 60\n",
      "\n",
      "\n",
      "Fully connected layer 2 range: 1890\n",
      "\n",
      "\n",
      "Fully connected layer 3 range: 39710\n",
      "\n",
      "\n",
      "Fully connected layer 4 range: 635375\n",
      "\n",
      "\n",
      "base                              13\n",
      "nodes_req                          4\n",
      "sparcity                        1066\n",
      "max_necc_base_value    [12, 6, 9, 0]\n",
      "nodes+_req                         3\n",
      "subsparcity                    25298\n",
      "unexplained                    75894\n",
      "sparcity_pcnt                3.73236\n",
      "subsparcity_pcnt             1151.48\n",
      "denoise_pcnt                   -1500\n",
      "complexity                      4268\n",
      "Name: 13, dtype: object \n",
      "\n",
      "base                                  15\n",
      "nodes_req                              5\n",
      "sparcity                          124000\n",
      "max_necc_base_value    [12, 8, 3, 13, 5]\n",
      "nodes+_req                             4\n",
      "subsparcity                       584750\n",
      "unexplained                      2339000\n",
      "sparcity_pcnt                    16.3292\n",
      "subsparcity_pcnt                 1155.06\n",
      "denoise_pcnt                       -2400\n",
      "complexity                        620005\n",
      "Name: 15, dtype: object \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define feature space for hashing\n",
    "c_min = 3**2\n",
    "c_max = 3**5\n",
    "f_min = 2**2\n",
    "f_max = 2**6\n",
    "\n",
    "c = c_max - c_min\n",
    "f = f_max - f_min\n",
    "\n",
    "# conv = set(range(c_max)) - set(range(c_min))\n",
    "# full = set(range(f_max)) - set(range(f_min))\n",
    "conv = range(c_max)[c_min:]\n",
    "full = range(f_max)[f_min:]\n",
    "\n",
    "c_comb = list(combinations_with_replacement(conv,2))\n",
    "f_comb = []\n",
    "for layers in range(1,5):\n",
    "    f_comb += list(combinations_with_replacement(full,layers))\n",
    "#     print(\"Fully connected layer %s range: %s\" % (layers,len(f_comb)) )\n",
    "#     print(\"\\n\")\n",
    "\n",
    "# for conversion from dec to whatever we end up using\n",
    "# most to least significant digit\n",
    "def numberToBase(n, b):\n",
    "    if n == 0:\n",
    "        return [0]\n",
    "    digits = []\n",
    "    while n:\n",
    "        digits.append(int(n % b))\n",
    "        n //= b\n",
    "    rev = digits[::-1]\n",
    "    return rev\n",
    "\n",
    "def feature_spacing():\n",
    "    \n",
    "    # create empty list to store the \n",
    "    # combinations \n",
    "    unique_combinations = list(combinations([c_comb,f_comb],2))\n",
    "    total_uniques = len(unique_combinations)\n",
    "    total_points = total_uniques**2\n",
    "    total_cvs = len(c_comb)\n",
    "    total_fcs = len(f_comb)\n",
    "    \n",
    "    columns = [\"base\",\"nodes_req\",\"sparcity\",\"sparcity_pcnt\",\"denoise_pcnt\"]\n",
    "    values = [1,total_uniques,total_points - total_uniques,(total_points - total_uniques) / total_points,0]\n",
    "    \n",
    "    cf = []\n",
    "    \n",
    "    for layer in [total_cvs,total_fcs]:#,total_uniques]:\n",
    "        results = {\n",
    "            \"base\": [1],\n",
    "            \"nodes_req\": [total_uniques],\n",
    "            \"sparcity\": [total_points - total_uniques],\n",
    "            \"max_necc_base_value\":[0],\n",
    "            \"nodes+_req\": [0],\n",
    "            \"subsparcity\": [0],\n",
    "            \"unexplained\":[0],\n",
    "            \"sparcity_pcnt\": [(total_points - total_uniques) / total_points * 100],\n",
    "            \"subsparcity_pcnt\": [0],\n",
    "            \"denoise_pcnt\":[0],\n",
    "            \"complexity\":[0]\n",
    "        }\n",
    "\n",
    "        report = pd.DataFrame(results)\n",
    "    \n",
    "        for base in range(2,17):\n",
    "            results[\"base\"] = [base]\n",
    "            results[\"nodes_req\"] = [math.ceil(math.log(layer,(base)))]\n",
    "            results[\"nodes+_req\"] = [math.floor(math.log(layer,(base)))]\n",
    "            \n",
    "            results[\"sparcity\"] = [base**math.ceil(math.log(layer,base)) - layer]\n",
    "            results[\"subsparcity\"] = [-(base**math.floor(math.log(layer,base)) - layer)]\n",
    "            \n",
    "            results[\"sparcity_pcnt\"] = [(base**math.ceil(math.log(layer,(base))) - base**math.log(layer,(base)))/(base**math.ceil(math.log(layer,(base))))*100]\n",
    "            results[\"subsparcity_pcnt\"] = [-((base**math.floor(math.log(layer,(base))) - base**math.log(layer,(base)))/(base**math.floor(math.log(layer,(base))))*100)]\n",
    "            \n",
    "#             results[\"max_necc_base_value\"] = [numberToBase((results[\"base\"][0]**results[\"nodes+_req\"][0]+results[\"subsparcity\"][0]),results[\"base\"][0])]\n",
    "            results[\"max_necc_base_value\"] = [numberToBase(layer,base)]\n",
    "            results[\"unexplained\"] = [(-(base**math.floor(math.log(layer,base)) - layer))*(math.floor(math.log(layer,(base))))]\n",
    "            \n",
    "            results[\"denoise_pcnt\"] = [math.floor(((total_points-(math.ceil(math.log(layer,base)))**2)/total_points)*100)]\n",
    "        \n",
    "            results[\"complexity\"] = [results[\"nodes_req\"][0]*(results[\"sparcity\"][0]+1)]\n",
    "\n",
    "            report = report.append(pd.DataFrame(results))\n",
    "            \n",
    "            \n",
    "        report.index = [x for x in range(1, len(report.values)+1)]\n",
    "        report.drop([1],axis=0,inplace=True)\n",
    "        report.sort_values([\"sparcity\",\"unexplained\",\"nodes+_req\",\"subsparcity\",\"sparcity_pcnt\",\"base\"],inplace=True)\n",
    "        \n",
    "        cf.append(report.iloc[0])\n",
    "    \n",
    "    return cf\n",
    "\n",
    "[print(r,\"\\n\") for r in feature_spacing()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the convolutional layers, base 13 seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\n",
      "For the linear layers, base 15 seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\n",
      "We can use the \n"
     ]
    }
   ],
   "source": [
    "bases = feature_spacing()\n",
    "print(\"For the convolutional layers, base %s seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\" % bases[0][\"base\"])\n",
    "print(\"For the linear layers, base %s seems to allow us to use the fewest nodes with the lowest number of invalid configuration indices (sparcity).\" % bases[1][\"base\"])\n",
    "\n",
    "# print(\"We can use the \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_c = bases[0][\"base\"]\n",
    "base_f = bases[1][\"base\"]\n",
    "\n",
    "def base_to_dec(num_list, base):\n",
    "    num_list = num_list[::-1]\n",
    "    num = 0\n",
    "    for k in range(len(num_list)):\n",
    "        dig = num_list[k]\n",
    "        dig = int(dig)\n",
    "        num += dig*(base**k)\n",
    "    return num\n",
    "\n",
    "def encode(config=[(24, 64),(13, 41)]):\n",
    "    iconv = c_comb.index(config[0])\n",
    "    ifull = f_comb.index(config[1])\n",
    "    \n",
    "    conv_hash = numberToBase(iconv,base_c)\n",
    "    full_hash = numberToBase(ifull,base_f)\n",
    "    \n",
    "    return [conv_hash,full_hash]\n",
    "\n",
    "def decode(hash=([1, 7, 5, 0], [2, 0, 4, 3, 4, 4])):\n",
    "    conv = base_to_dec(hash[0], base_c)\n",
    "    full = base_to_dec(hash[1], base_f)\n",
    "\n",
    "    \n",
    "    return [c_comb[conv],f_comb[full]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 7, 5, 0], [2, 9, 7]]\n"
     ]
    }
   ],
   "source": [
    "print(encode())\n",
    "print(decode(encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move data into sets for loading\n",
    "def load_data(data_dir=d.absolute()):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset,testset = [torchvision.datasets.CIFAR10(root=data_dir, train=is_train, download=True, transform=transform) for is_train in [True,False]]\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamically-generated nn that takes a 3-channel image and outputs a label\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_layers=[[6, 16],[120,84]]):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_convs,hidden_fcs = hidden_layers\n",
    "#         print(hidden_convs)\n",
    "#         print(hidden_fcs)\n",
    "        uf_input = 0\n",
    "        layer_list = OrderedDict()\n",
    "        \n",
    "        layer_list['conv1'] = nn.Conv2d(3, hidden_convs[0], 5)\n",
    "        layer_list['pool1'] = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        layer_input = layer_list['conv1'].out_channels\n",
    "        \n",
    "        for layer_num, channels in enumerate(hidden_convs[1:], 2):\n",
    "            layer_list[\"conv%s\" % layer_num]  = nn.Conv2d(layer_input, channels, 5)\n",
    "            layer_list[\"pool%s\" % layer_num] = nn.MaxPool2d(2, 2)\n",
    "            layer_input = layer_list[\"conv%s\" % layer_num].out_channels\n",
    "        \n",
    "        \n",
    "        layer_list[\"flat\"] = nn.Flatten()\n",
    "        \n",
    "        layer_list['fc1'] = nn.Linear(layer_input*5*5, hidden_fcs[0])\n",
    "        layer_list[\"relu1\"]  = nn.ReLU()\n",
    "        \n",
    "        layer_input = layer_list['fc1'].out_features\n",
    "        for (layer_num, features) in enumerate(hidden_fcs[1:], 2):\n",
    "            layer_list[\"fc%s\" % layer_num]  = nn.Linear(layer_input, features)\n",
    "            layer_list[\"relu%s\" % layer_num]  = nn.ReLU()\n",
    "            layer_input = layer_list[\"fc%s\" % layer_num].out_features\n",
    "            \n",
    "        \n",
    "        layer_list['fco'] = nn.Linear(hidden_fcs[-1], 10)\n",
    "    \n",
    "        self.layers = nn.Sequential(layer_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train nn on data\n",
    "def train_cifar(neuron_config, checkpoint_dir=None):\n",
    "    \n",
    "    data_dir=d.absolute()\n",
    "    \n",
    "    def cv_discrim(s): return 'conv_subindex_' in s\n",
    "    def fc_discrim(s): return 'full_subindex_' in s\n",
    "    cvs = [neuron_config[hp] for hp in list(filter(cv_discrim, neuron_config.keys()))]\n",
    "    fcs = [neuron_config[hp] for hp in list(filter(fc_discrim, neuron_config.keys()))]\n",
    "    \n",
    "    cfg = decode([cvs, fcs])\n",
    "    \n",
    "    print(\"New model: %s\" % cfg)\n",
    "    net = Net(cfg)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=neuron_config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader,valloader = [torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(neuron_config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=1) for subset in [train_subset,val_subset]]\n",
    "\n",
    "    for epoch in range(neuron_config[\"epochs\"]):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "#                 print(\"Model: %s, Epoch: %d, Mini-batch: %5d, Loss: %.3f\" % (cfg,epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=(correct / total))\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy score\n",
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=1)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine configuration boundary for nn based on number of layers\n",
    "nodes_c = bases[0][\"nodes_req\"]\n",
    "nodes_f = bases[1][\"nodes_req\"]\n",
    "max_c = bases[0][\"max_necc_base_value\"]\n",
    "max_f = bases[1][\"max_necc_base_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def configure_neurons(num_convs,num_fcs):\n",
    "def configure_neurons():\n",
    "    config_space = CS.ConfigurationSpace()\n",
    "    \n",
    "    config_space.add_hyperparameter(\n",
    "        CS.UniformFloatHyperparameter(name=\"lr\", lower=1e-4, upper=1e-1, log=True))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"batch_size\", choices=[4, 8, 16, 32]))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"epochs\", choices=[20, 30, 40]))\n",
    "    \n",
    "    conv_lims,full_lims = [],[]\n",
    "    \n",
    "    for subindex in range(nodes_c):\n",
    "        # define hyperparameter reference attributes\n",
    "        rule_name = \"conv_subindex_%s\" % subindex\n",
    "        conv_rule = CS.UniformIntegerHyperparameter(rule_name, lower=0, upper=base_c-1)\n",
    "        \n",
    "        # add hyperparameter to collections\n",
    "        config_space.add_hyperparameter(conv_rule)\n",
    "    \n",
    "        conv_rules = list(filter(lambda hp: \"conv_subindex_\" in hp.name, config_space.get_hyperparameters()))\n",
    "    \n",
    "        # build banlist from collections\n",
    "        rl = deepcopy(config_space)\n",
    "        rd = {}\n",
    "        for ri,rule in enumerate(conv_rules,1):\n",
    "    \n",
    "            if (len(conv_rules) == 1) & (max_c[ri-1] == config_space.get_hyperparameter(rule_name).upper):\n",
    "                break\n",
    "            elif ri != len(conv_rules):\n",
    "                rd[rule.name] = CS.ForbiddenEqualsClause(\n",
    "                        rule,\n",
    "                        max_c[ri-1]\n",
    "                    )\n",
    "            else:\n",
    "                rd[rule.name] = CS.ForbiddenInClause(\n",
    "                        rule,\n",
    "                        range(\n",
    "                            max_c[ri-1] + 1, \n",
    "                            rule.upper + 1\n",
    "                        )\n",
    "                    )\n",
    "        \n",
    "        # package banlist for addition to config space\n",
    "        if rd.values():\n",
    "            config_space.add_forbidden_clause(\n",
    "                CS.ForbiddenAndConjunction(\n",
    "                    *rd.values()\n",
    "                )\n",
    "            )           \n",
    "    \n",
    "    for subindex in range(nodes_f):\n",
    "        # define hyperparameter reference attributes\n",
    "        rule_name = \"full_subindex_%s\" % subindex\n",
    "        full_rule = CS.UniformIntegerHyperparameter(rule_name, lower=0, upper=base_f-1)\n",
    "        \n",
    "        # add hyperparameter to collections\n",
    "        config_space.add_hyperparameter(full_rule)\n",
    "    \n",
    "        full_rules = list(filter(lambda hp: \"full_subindex_\" in hp.name, config_space.get_hyperparameters()))\n",
    "    \n",
    "        # build banlist from collections\n",
    "        rl = deepcopy(config_space)\n",
    "        rd = {}\n",
    "        for ri,rule in enumerate(full_rules,1):\n",
    "            if (len(full_rules) == 1) & (max_f[ri-1] == config_space.get_hyperparameter(rule_name).upper):\n",
    "#                 print(\"breaking\")\n",
    "                break\n",
    "            elif ri != len(full_rules):\n",
    "                rd[rule.name] = CS.ForbiddenEqualsClause(\n",
    "                        rule,\n",
    "                        max_f[ri-1]\n",
    "                    )\n",
    "            else:\n",
    "                rd[rule.name] = CS.ForbiddenInClause(\n",
    "                        rule,\n",
    "                        range(\n",
    "                            max_f[ri-1] + 1, \n",
    "                            rule.upper + 1\n",
    "                        )\n",
    "                    )\n",
    "        # add banlist to collection\n",
    "        if rd.values():\n",
    "            config_space.add_forbidden_clause(\n",
    "                CS.ForbiddenAndConjunction(\n",
    "                    *rd.values()\n",
    "                )\n",
    "            )           \n",
    "        \n",
    "    return config_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    batch_size, Type: Categorical, Choices: {4, 8, 16, 32}, Default: 4\n",
      "    conv_subindex_0, Type: UniformInteger, Range: [0, 12], Default: 6\n",
      "    conv_subindex_1, Type: UniformInteger, Range: [0, 12], Default: 6\n",
      "    conv_subindex_2, Type: UniformInteger, Range: [0, 12], Default: 6\n",
      "    conv_subindex_3, Type: UniformInteger, Range: [0, 12], Default: 6\n",
      "    epochs, Type: Categorical, Choices: {20, 30, 40}, Default: 20\n",
      "    full_subindex_0, Type: UniformInteger, Range: [0, 14], Default: 7\n",
      "    full_subindex_1, Type: UniformInteger, Range: [0, 14], Default: 7\n",
      "    full_subindex_2, Type: UniformInteger, Range: [0, 14], Default: 7\n",
      "    full_subindex_3, Type: UniformInteger, Range: [0, 14], Default: 7\n",
      "    full_subindex_4, Type: UniformInteger, Range: [0, 14], Default: 7\n",
      "    lr, Type: UniformFloat, Range: [0.0001, 0.1], Default: 0.0031622777, on log-scale\n",
      "  Forbidden Clauses:\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 in {7, 8, 9, 10, 11, 12})\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 == 6 && Forbidden: conv_subindex_2 in {10, 11, 12})\n",
      "    (Forbidden: conv_subindex_0 == 12 && Forbidden: conv_subindex_1 == 6 && Forbidden: conv_subindex_2 == 9 && Forbidden: conv_subindex_3 in {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12})\n",
      "    (Forbidden: full_subindex_0 in {13, 14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 in {9, 10, 11, 12, 13, 14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 == 8 && Forbidden: full_subindex_2 in {4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 == 8 && Forbidden: full_subindex_2 == 3 && Forbidden: full_subindex_3 in {14})\n",
      "    (Forbidden: full_subindex_0 == 12 && Forbidden: full_subindex_1 == 8 && Forbidden: full_subindex_2 == 3 && Forbidden: full_subindex_3 == 13 && Forbidden: full_subindex_4 in {6, 7, 8, 9, 10, 11, 12, 13, 14})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(configure_neurons())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform neuron configuration trials\n",
    "def search_neurons(checkpoint_dir=None):    \n",
    "    neuron_config_space = configure_neurons()\n",
    "    \n",
    "    experiment_metrics = dict(metric=\"accuracy\", mode=\"max\")\n",
    "    \n",
    "    #pre-load data to avoid races\n",
    "    load_data()\n",
    "    \n",
    "    scheduler = HyperBandForBOHB(\n",
    "        max_t=20,\n",
    "        reduction_factor=2,\n",
    "        **experiment_metrics)\n",
    "    search = TuneBOHB(\n",
    "        neuron_config_space,\n",
    "        max_concurrent=8,\n",
    "        **experiment_metrics)\n",
    "    reporter = JupyterNotebookReporter(\n",
    "        overwrite=True,\n",
    "        parameter_columns=neuron_config_space.get_hyperparameter_names(),\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_cifar),\n",
    "        verbose=2,\n",
    "        name=\"neurons\",\n",
    "        local_dir=r.absolute(),\n",
    "        resources_per_trial={\"cpu\": cpu_use, \"gpu\": gpu_use},\n",
    "        max_failures=3,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "    \n",
    "    def cv_discrim(s): return 'conv_subindex_' in s\n",
    "    def fc_discrim(s): return 'full_subindex_' in s\n",
    "    def other_discrim(s): return 'subindex' not in s\n",
    "    best_cvs = [best_trial.config[hp] for hp in list(filter(cv_discrim, best_trial.config.keys()))]\n",
    "    best_fcs = [best_trial.config[hp] for hp in list(filter(fc_discrim, best_trial.config.keys()))]\n",
    "    best_other = [best_trial.config[hp] for hp in list(filter(other_discrim, best_trial.config.keys()))]\n",
    "\n",
    "    cfg = decode([best_cvs, best_fcs])\n",
    "    \n",
    "    conv_report = [\"Connolutional Layer %s: %s\" % (i,c) for i,c in enumerate(cfg[0])]\n",
    "    full_report = [\"Fully-connected Layer %s: %s\" % (i,f) for i,f in enumerate(cfg[1])]\n",
    "    other_report = [\"Other %s: %s\" % (i,f) for i,f in enumerate(cfg[1])]\n",
    "\n",
    "#     print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial config:\")\n",
    "    [print(best) for best in [conv_report,full_report,other_report]]\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "    \n",
    "    best_trained_model = Net(cfg)\n",
    "    \n",
    "    \n",
    "    if gpus_per_trial > 1:\n",
    "        best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    \n",
    "    if checkpoint_dir != None:\n",
    "        tune.report(accuracy=test_acc)\n",
    "    \n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "    \n",
    "    return best_trained_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform test\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    model = search_layers(num_samples=10, max_num_epochs=10, gpus_per_trial=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource usage can be viewed at port http://127.0.0.1:8265/ or higher\n"
     ]
    }
   ],
   "source": [
    "print(\"Resource usage can be viewed at port http://127.0.0.1:8265/ or higher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 17.2/31.9 GiB<br>Using HyperBand: num_stopped=9 total_brackets=1\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=1, Milestone (r)=12, completed=100.0%): {TERMINATED: 10} <br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/11.47 GiB heap, 0.0/3.96 GiB objects<br>Result logdir: /home/francisn/Source/CIFAR-Trainer/ray_results/neurons<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_subindex_0</th><th style=\"text-align: right;\">  conv_subindex_1</th><th style=\"text-align: right;\">  conv_subindex_2</th><th style=\"text-align: right;\">  conv_subindex_3</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  full_subindex_0</th><th style=\"text-align: right;\">  full_subindex_1</th><th style=\"text-align: right;\">  full_subindex_2</th><th style=\"text-align: right;\">  full_subindex_3</th><th style=\"text-align: right;\">  full_subindex_4</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">      loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DEFAULT_e9db22d0</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">0.0150035  </td><td style=\"text-align: right;\">  1.16868 </td><td style=\"text-align: right;\">  0.636   </td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>DEFAULT_ea91ffa0</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">               14</td><td style=\"text-align: right;\">0.0405221  </td><td style=\"text-align: right;\">  2.30767 </td><td style=\"text-align: right;\">  0.099125</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_eb225de8</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">0.00017814 </td><td style=\"text-align: right;\">  1.58097 </td><td style=\"text-align: right;\">  0.40775 </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_ebca7b9a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">0.0653362  </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">  0.09955 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_eea08738</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">               13</td><td style=\"text-align: right;\">0.00469764 </td><td style=\"text-align: right;\">  2.30998 </td><td style=\"text-align: right;\">  0.0993  </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_eeafb9a0</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.00349346 </td><td style=\"text-align: right;\">  0.595556</td><td style=\"text-align: right;\">  0.792425</td><td style=\"text-align: right;\">                  12</td></tr>\n",
       "<tr><td>DEFAULT_a62482a0</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">               14</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">0.00280746 </td><td style=\"text-align: right;\">  1.50148 </td><td style=\"text-align: right;\">  0.4874  </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_1d1e6a42</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                9</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">0.000112301</td><td style=\"text-align: right;\">  2.30618 </td><td style=\"text-align: right;\">  0.0989  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_459a326c</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">               11</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                6</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               12</td><td style=\"text-align: right;\">0.000231087</td><td style=\"text-align: right;\">  2.08461 </td><td style=\"text-align: right;\">  0.2023  </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_b6cd0df6</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">               10</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">                5</td><td style=\"text-align: right;\">               14</td><td style=\"text-align: right;\">0.0950384  </td><td style=\"text-align: right;\">  2.31842 </td><td style=\"text-align: right;\">  0.098725</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-28 13:58:24,336\tINFO tune.py:439 -- Total run time: 6339.44 seconds (6334.47 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config:\n",
      "['Connolutional Layer 0: 73', 'Connolutional Layer 1: 88']\n",
      "['Fully-connected Layer 0: 45', 'Fully-connected Layer 1: 48', 'Fully-connected Layer 2: 59', 'Fully-connected Layer 3: 62']\n",
      "['Other 0: 45', 'Other 1: 48', 'Other 2: 59', 'Other 3: 62']\n",
      "Best trial final validation loss: 0.5955558932900429\n",
      "Best trial final validation accuracy: 0.792425\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Best trial test set accuracy: 0.6679\n"
     ]
    }
   ],
   "source": [
    "model = search_neurons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.conv1.weight \n",
      " 73\n",
      "layers.conv1.bias \n",
      " 73\n",
      "layers.conv2.weight \n",
      " 88\n",
      "layers.conv2.bias \n",
      " 88\n",
      "layers.fc1.weight \n",
      " 45\n",
      "layers.fc1.bias \n",
      " 45\n",
      "layers.fc2.weight \n",
      " 48\n",
      "layers.fc2.bias \n",
      " 48\n",
      "layers.fc3.weight \n",
      " 59\n",
      "layers.fc3.bias \n",
      " 59\n",
      "layers.fc4.weight \n",
      " 62\n",
      "layers.fc4.bias \n",
      " 62\n",
      "layers.fco.weight \n",
      " 10\n",
      "layers.fco.bias \n",
      " 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(k,\"\\n\",model[k].shape[0]) for k in model.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('layers.conv1.weight', tensor([[[[ 0.0146,  0.0691, -0.0261, -0.0939, -0.0851],\n",
      "          [ 0.0042, -0.0116, -0.3609, -0.1985,  0.2033],\n",
      "          [ 0.0113, -0.1973, -0.0959,  0.2863, -0.0551],\n",
      "          [ 0.1324, -0.0786,  0.2304,  0.0639, -0.0095],\n",
      "          [ 0.0822,  0.1376,  0.1574, -0.1093,  0.0413]],\n",
      "\n",
      "         [[ 0.0680,  0.1778,  0.0706, -0.2093, -0.1188],\n",
      "          [-0.1064, -0.1661, -0.2693, -0.1127,  0.2203],\n",
      "          [-0.0864, -0.1125, -0.0340,  0.2666, -0.1089],\n",
      "          [-0.0143,  0.0338,  0.1327,  0.1371, -0.1462],\n",
      "          [-0.0636,  0.1015,  0.0779,  0.0319, -0.0448]],\n",
      "\n",
      "         [[ 0.0297,  0.1950,  0.1122, -0.0410, -0.0382],\n",
      "          [ 0.0121,  0.0094, -0.2923,  0.0197,  0.2055],\n",
      "          [-0.0704, -0.1157,  0.1092,  0.2288,  0.0561],\n",
      "          [ 0.1204,  0.0639,  0.0175, -0.0935, -0.1010],\n",
      "          [-0.1020, -0.0809, -0.0283, -0.0891,  0.0333]]],\n",
      "\n",
      "\n",
      "        [[[-0.0953, -0.2455, -0.1338, -0.0959,  0.0415],\n",
      "          [-0.1936, -0.0601, -0.0544,  0.0008, -0.0121],\n",
      "          [-0.0819, -0.0913, -0.0289,  0.1120,  0.1765],\n",
      "          [-0.0422,  0.0750,  0.0756,  0.2016,  0.0586],\n",
      "          [ 0.0563,  0.1394,  0.0966,  0.1191,  0.1593]],\n",
      "\n",
      "         [[ 0.0581,  0.0629,  0.0341, -0.0360, -0.0973],\n",
      "          [-0.0177,  0.0095,  0.0897,  0.1464,  0.0179],\n",
      "          [-0.0220,  0.0080,  0.1679, -0.0203,  0.1219],\n",
      "          [ 0.0723, -0.0434, -0.0512,  0.0418, -0.1060],\n",
      "          [-0.0046, -0.1697, -0.1250, -0.0731, -0.0630]],\n",
      "\n",
      "         [[ 0.1249,  0.1251,  0.1498, -0.0410,  0.0384],\n",
      "          [ 0.2045,  0.2107,  0.0452,  0.1259,  0.0633],\n",
      "          [ 0.1040,  0.1933,  0.1118, -0.0315, -0.1444],\n",
      "          [ 0.0826,  0.0611, -0.1879, -0.2924, -0.1718],\n",
      "          [-0.1121, -0.1649, -0.1868, -0.2511, -0.0997]]],\n",
      "\n",
      "\n",
      "        [[[-0.0166,  0.2086,  0.1994,  0.1911,  0.1464],\n",
      "          [-0.2491, -0.1088, -0.0243,  0.1930,  0.1027],\n",
      "          [-0.1736, -0.2538, -0.3398, -0.2558, -0.1898],\n",
      "          [ 0.1907,  0.1001,  0.0455,  0.1210, -0.0050],\n",
      "          [-0.1332, -0.0243,  0.0587, -0.0671, -0.0534]],\n",
      "\n",
      "         [[ 0.1024,  0.1289,  0.2031,  0.0271,  0.0740],\n",
      "          [-0.1116,  0.0222,  0.0368,  0.1315,  0.1715],\n",
      "          [-0.1618, -0.2578, -0.1512, -0.2092, -0.1546],\n",
      "          [ 0.1381,  0.2202,  0.0564,  0.0921,  0.0249],\n",
      "          [ 0.0463,  0.0538,  0.0624,  0.0312, -0.0471]],\n",
      "\n",
      "         [[ 0.0725,  0.1296,  0.0770, -0.0199, -0.1506],\n",
      "          [-0.0771, -0.0656, -0.1228,  0.0800,  0.1092],\n",
      "          [ 0.0112, -0.2115, -0.1237, -0.2896, -0.1954],\n",
      "          [ 0.0956,  0.1253,  0.1297,  0.0165,  0.0315],\n",
      "          [ 0.0224, -0.0645, -0.0076,  0.1190,  0.0569]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0225,  0.0397, -0.0523, -0.1512, -0.0673],\n",
      "          [-0.0030,  0.0998, -0.0477,  0.1535,  0.1440],\n",
      "          [-0.0552,  0.1294, -0.0390,  0.2054, -0.0176],\n",
      "          [-0.1664, -0.1115, -0.0977, -0.1360, -0.1921],\n",
      "          [ 0.0772,  0.1087,  0.1415,  0.0557,  0.1171]],\n",
      "\n",
      "         [[-0.1073,  0.0441, -0.0037, -0.1055, -0.0622],\n",
      "          [ 0.0991,  0.1344, -0.0863,  0.0417,  0.1224],\n",
      "          [ 0.0981, -0.0400,  0.0163,  0.1169, -0.0676],\n",
      "          [-0.0184, -0.1268, -0.2161, -0.0757, -0.1641],\n",
      "          [ 0.1563,  0.0234, -0.0108, -0.0476, -0.0549]],\n",
      "\n",
      "         [[-0.0738,  0.0208, -0.1214, -0.1199,  0.0815],\n",
      "          [ 0.0545,  0.0073, -0.0659,  0.0686,  0.1426],\n",
      "          [ 0.1298,  0.0050,  0.1406,  0.0356,  0.1688],\n",
      "          [ 0.0626, -0.1564, -0.1866,  0.0162,  0.0111],\n",
      "          [-0.0096, -0.0286, -0.0760,  0.0806, -0.0329]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0066,  0.0292, -0.2141,  0.2245, -0.0551],\n",
      "          [-0.2096,  0.0911, -0.3111,  0.0591, -0.1099],\n",
      "          [ 0.0418,  0.0972, -0.1170,  0.0614, -0.0044],\n",
      "          [ 0.0998,  0.3016,  0.0411,  0.0961,  0.0346],\n",
      "          [-0.1742, -0.0193, -0.2120, -0.0284, -0.1528]],\n",
      "\n",
      "         [[-0.0174,  0.0892, -0.1408,  0.0196, -0.0428],\n",
      "          [-0.1581,  0.1575, -0.2365,  0.2196, -0.0812],\n",
      "          [-0.0468,  0.1829, -0.1949,  0.2924,  0.0025],\n",
      "          [ 0.0965,  0.2128, -0.1221,  0.2444, -0.0364],\n",
      "          [-0.0316, -0.1355, -0.1067,  0.0257,  0.0719]],\n",
      "\n",
      "         [[ 0.0831,  0.2719, -0.0399,  0.2312, -0.0344],\n",
      "          [-0.1516,  0.0360, -0.2457,  0.0180, -0.2093],\n",
      "          [-0.0499,  0.0820, -0.2370,  0.2060, -0.1392],\n",
      "          [ 0.1352,  0.2025,  0.0480,  0.2573, -0.0012],\n",
      "          [-0.1879, -0.0681, -0.1766,  0.0029, -0.1462]]],\n",
      "\n",
      "\n",
      "        [[[-0.0594,  0.0249, -0.1938, -0.2622, -0.2110],\n",
      "          [ 0.1174,  0.1733,  0.0077,  0.0882, -0.1060],\n",
      "          [ 0.1112,  0.1704,  0.0729,  0.0198, -0.1336],\n",
      "          [ 0.0741, -0.0130, -0.1663, -0.1453, -0.0703],\n",
      "          [-0.0462, -0.0147,  0.0764,  0.0489,  0.0446]],\n",
      "\n",
      "         [[-0.1590, -0.1448, -0.1677, -0.1135, -0.0774],\n",
      "          [ 0.1251,  0.2312,  0.1906,  0.1287,  0.1428],\n",
      "          [ 0.0539,  0.1296,  0.1881,  0.1023,  0.1434],\n",
      "          [-0.1366, -0.0306, -0.0006, -0.0963, -0.0150],\n",
      "          [-0.0213, -0.0653, -0.1555, -0.0103,  0.0079]],\n",
      "\n",
      "         [[-0.1272, -0.2124, -0.1369,  0.0463,  0.0095],\n",
      "          [ 0.0269,  0.0530,  0.1365,  0.0876,  0.1710],\n",
      "          [ 0.0303,  0.0440, -0.0419,  0.0466,  0.1419],\n",
      "          [-0.1740, -0.2219, -0.0956, -0.0608, -0.1165],\n",
      "          [ 0.0737,  0.0201,  0.0218,  0.0826,  0.0430]]]])), ('layers.conv1.bias', tensor([-0.0395, -0.2606, -0.2911, -0.1707, -0.2151, -0.1291, -0.1760, -0.0699,\n",
      "        -0.0289, -0.0986, -0.1759, -0.1720, -0.1224, -0.0202, -0.0167, -0.3203,\n",
      "        -0.0407, -0.1550, -0.1410, -0.1484, -0.2774, -0.2298, -0.2564, -0.1576,\n",
      "        -0.0748, -0.1138, -0.1491, -0.0657, -0.1581, -0.0405, -0.1191, -0.1959,\n",
      "        -0.0485, -0.1292, -0.1273, -0.3273, -0.2894, -0.0846, -0.2694, -0.2533,\n",
      "        -0.1969, -0.2327, -0.1020, -0.2791, -0.1567, -0.0533, -0.1915, -0.0334,\n",
      "        -0.1155, -0.0939, -0.0661, -0.1910, -0.2120, -0.2251, -0.1860, -0.0855,\n",
      "        -0.1407, -0.2650, -0.2039, -0.1686, -0.2228, -0.0102, -0.0283, -0.1792,\n",
      "        -0.2226, -0.1036, -0.0538, -0.1429, -0.1930, -0.0370, -0.1659, -0.0899,\n",
      "        -0.2649])), ('layers.conv2.weight', tensor([[[[ 2.8156e-02,  2.9387e-02,  2.3442e-02,  3.2105e-02,  7.2182e-03],\n",
      "          [ 2.6009e-02,  9.2757e-03,  1.3401e-02, -4.2157e-05, -1.9344e-02],\n",
      "          [ 3.4023e-02, -1.5671e-02, -8.8112e-03, -4.0845e-02,  5.2628e-03],\n",
      "          [ 3.5405e-02, -1.9065e-02, -7.3202e-03, -2.8059e-02, -4.8972e-02],\n",
      "          [-1.2136e-02, -2.6327e-02, -1.9374e-03, -3.6263e-02, -2.5952e-03]],\n",
      "\n",
      "         [[ 3.2658e-02,  5.1040e-02,  6.3544e-02,  4.7553e-02,  3.3369e-02],\n",
      "          [ 6.1228e-02,  5.0275e-02,  4.4427e-02,  3.1594e-03,  1.2721e-02],\n",
      "          [ 3.2753e-02, -3.0248e-04, -4.6255e-03, -1.0678e-02, -2.6436e-02],\n",
      "          [-1.0768e-02, -1.6298e-02, -2.2399e-03, -2.8606e-02, -1.9232e-02],\n",
      "          [ 3.4198e-02, -8.6134e-03, -1.2880e-02,  4.1692e-03,  9.5184e-03]],\n",
      "\n",
      "         [[-2.7925e-02, -3.1979e-02,  5.2172e-03,  1.0976e-02,  8.1214e-03],\n",
      "          [ 4.2584e-03,  1.1768e-02,  4.7934e-03, -1.4527e-02,  6.2321e-03],\n",
      "          [ 1.9100e-02,  9.2631e-03, -1.7945e-02, -7.7981e-03, -1.9672e-05],\n",
      "          [-3.4735e-02, -3.1757e-02, -4.1353e-02, -1.9780e-02,  1.2157e-02],\n",
      "          [-3.3379e-02, -3.9521e-02, -1.8965e-03, -5.1734e-03, -3.1618e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5668e-02, -1.8829e-02, -9.0827e-03, -2.3395e-02,  9.4909e-03],\n",
      "          [-6.7357e-03, -3.6341e-03, -1.1672e-02, -5.2954e-03,  3.4686e-05],\n",
      "          [ 3.2751e-02, -2.4061e-02, -2.3798e-02, -1.4094e-02, -2.9655e-02],\n",
      "          [ 6.8640e-03, -2.1129e-02, -1.0176e-02,  2.3894e-06, -3.0098e-02],\n",
      "          [ 7.1523e-03, -1.8946e-02,  2.6339e-03, -4.0028e-03,  2.5988e-02]],\n",
      "\n",
      "         [[-1.2458e-02,  4.9474e-02,  1.6972e-02,  2.1621e-02,  1.4788e-02],\n",
      "          [-9.6576e-03,  1.3322e-02, -8.8906e-03, -8.7127e-03,  6.1936e-03],\n",
      "          [-7.3332e-03,  1.4547e-02,  3.3587e-03,  1.0050e-02, -2.2999e-02],\n",
      "          [ 2.0829e-02,  6.0368e-03, -2.7410e-03, -1.5312e-02, -1.3538e-02],\n",
      "          [ 2.4478e-02,  1.0256e-03,  5.1063e-03,  2.2460e-02,  2.7711e-02]],\n",
      "\n",
      "         [[ 1.9276e-02,  1.0865e-02,  2.8443e-02, -1.7848e-02, -5.2166e-03],\n",
      "          [ 3.5837e-03,  1.7031e-02, -6.3538e-03, -1.5256e-02,  1.0370e-02],\n",
      "          [-1.4654e-03,  2.4720e-02, -7.6990e-03, -2.3042e-02,  3.6605e-03],\n",
      "          [ 2.4310e-02, -2.0760e-02,  2.6719e-02, -1.1291e-02,  1.6086e-05],\n",
      "          [-2.8648e-03, -2.0474e-02,  2.4377e-03, -6.3367e-03, -2.0831e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.6186e-02,  8.3223e-04,  4.3675e-03, -2.5702e-02, -9.9197e-03],\n",
      "          [ 2.3973e-02,  6.8639e-03,  3.4661e-04, -1.1829e-02, -1.8922e-02],\n",
      "          [ 2.8432e-02, -8.0409e-03, -5.5678e-02, -4.1701e-04,  3.6684e-02],\n",
      "          [-3.9392e-02,  1.9633e-02,  4.1552e-02,  5.9108e-03, -1.1634e-02],\n",
      "          [ 4.4134e-02,  8.5420e-02,  3.4746e-02, -4.4272e-02, -2.7761e-02]],\n",
      "\n",
      "         [[ 1.3929e-02,  1.5970e-02,  4.0783e-02, -5.8049e-03,  2.8663e-02],\n",
      "          [ 3.8190e-03,  3.1045e-02, -6.3033e-03,  2.7577e-02,  2.5034e-02],\n",
      "          [-9.7142e-03,  2.4791e-02, -4.0584e-03,  1.2657e-02,  1.3914e-02],\n",
      "          [ 2.7121e-02, -3.3062e-02, -6.5501e-03,  7.5606e-03, -2.0792e-03],\n",
      "          [ 2.7118e-03,  2.2138e-02,  6.8143e-03,  3.7195e-02,  1.1090e-02]],\n",
      "\n",
      "         [[ 2.6529e-03,  2.1892e-02,  2.8196e-02,  5.0701e-02,  1.6140e-02],\n",
      "          [ 5.2776e-03,  1.9338e-02,  2.9725e-02, -1.4331e-02, -1.5322e-02],\n",
      "          [-4.4199e-02, -2.1364e-02, -3.2608e-02, -8.9517e-03,  5.6469e-03],\n",
      "          [ 9.1274e-03,  1.8918e-02,  3.3873e-02,  4.9691e-03, -6.8202e-02],\n",
      "          [ 4.9985e-02, -3.0814e-02, -3.6698e-02, -3.9948e-02,  1.1373e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9826e-02,  2.6246e-02,  9.0112e-04, -2.1857e-02,  1.2150e-02],\n",
      "          [ 2.9913e-03,  4.9940e-03, -1.8239e-02,  3.8845e-02,  2.3538e-02],\n",
      "          [ 3.2522e-03,  7.3054e-03,  3.1633e-02, -1.4966e-02,  2.1524e-02],\n",
      "          [ 4.4530e-02,  1.1465e-03, -4.8172e-03,  4.5727e-03, -2.2649e-02],\n",
      "          [-8.3405e-03,  5.1673e-03,  3.5119e-03,  1.0499e-02, -1.5288e-02]],\n",
      "\n",
      "         [[-7.3791e-03,  1.8813e-02, -2.1955e-02,  1.2161e-02, -6.9112e-03],\n",
      "          [-4.7409e-04,  1.6617e-02,  1.3925e-02,  1.5740e-02, -2.4123e-02],\n",
      "          [ 3.3822e-02,  1.2243e-02, -1.3066e-02, -1.5778e-02, -2.1956e-02],\n",
      "          [-1.7861e-02, -4.6511e-03, -1.5259e-02,  3.2335e-04,  2.2099e-02],\n",
      "          [-2.0646e-02,  1.1289e-02, -3.7001e-03,  1.3590e-03, -6.3313e-02]],\n",
      "\n",
      "         [[ 5.2284e-02,  1.3513e-02,  3.4231e-03, -5.0898e-03,  3.1606e-03],\n",
      "          [ 4.6928e-02,  2.9041e-02,  2.0554e-02,  3.9110e-02,  5.2172e-02],\n",
      "          [ 1.2714e-02,  4.1809e-02,  3.7410e-02,  1.3178e-02, -1.9761e-02],\n",
      "          [ 5.2111e-02, -1.0591e-02, -5.0917e-02, -8.3782e-03, -9.8018e-03],\n",
      "          [-1.8759e-03, -2.5982e-03,  1.2422e-02, -9.3021e-03, -5.6238e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5452e-02, -4.5784e-04,  3.8240e-03,  1.4932e-02, -1.2784e-02],\n",
      "          [-8.5931e-03,  1.0560e-02,  5.6329e-03,  2.3821e-02,  3.4946e-02],\n",
      "          [ 4.6553e-04,  8.3394e-03,  1.9704e-02,  4.1488e-03,  8.8886e-03],\n",
      "          [-3.4056e-03, -4.8102e-02, -2.1627e-02, -8.9036e-03,  6.3403e-03],\n",
      "          [-6.2868e-02, -5.4708e-02, -3.9472e-02, -5.7347e-02, -2.4306e-02]],\n",
      "\n",
      "         [[-8.0079e-03, -1.4668e-03, -9.3569e-03,  1.8885e-02,  1.2765e-02],\n",
      "          [ 5.6565e-02,  5.4360e-02,  2.4857e-02,  3.4739e-02,  1.9479e-02],\n",
      "          [ 5.0440e-02,  2.3172e-02,  2.0227e-02,  3.7758e-02, -1.2822e-02],\n",
      "          [ 8.3334e-03, -2.9780e-02, -1.8159e-02, -3.4200e-03,  9.3128e-03],\n",
      "          [ 3.3130e-02, -6.8735e-03, -3.7494e-03, -3.0392e-02, -3.8738e-03]],\n",
      "\n",
      "         [[ 3.8655e-02,  1.0505e-02,  1.8980e-02,  4.0332e-02,  4.7865e-02],\n",
      "          [-1.6877e-02, -3.1002e-02, -5.6587e-02, -2.9299e-02, -2.2280e-02],\n",
      "          [ 4.8045e-02,  6.2793e-03, -1.7250e-02, -2.4118e-02, -1.4801e-02],\n",
      "          [ 7.2985e-02,  1.9523e-02, -1.4699e-04,  3.4180e-03, -2.9273e-02],\n",
      "          [ 6.5164e-02,  9.4968e-03,  1.3631e-02,  2.8563e-02,  3.0372e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.5663e-03, -1.4855e-02, -8.1249e-03, -1.3019e-03,  6.2938e-03],\n",
      "          [ 3.5755e-03, -2.6256e-02,  1.4920e-02,  1.0527e-02, -1.0922e-02],\n",
      "          [ 2.8382e-02,  3.6273e-02, -2.0197e-03,  3.9536e-03,  1.8100e-02],\n",
      "          [ 2.9992e-02, -1.0835e-02,  4.3722e-03, -2.8710e-03,  1.9388e-02],\n",
      "          [ 4.2986e-02,  3.7249e-02, -1.2108e-02,  2.6763e-02,  3.0209e-02]],\n",
      "\n",
      "         [[-1.5734e-02, -6.2434e-03,  2.3453e-02, -6.5679e-03,  5.1477e-03],\n",
      "          [ 5.1801e-03,  6.6685e-04,  2.8657e-02,  2.6984e-02,  5.2506e-03],\n",
      "          [-1.2336e-02, -7.7677e-04, -7.6046e-03, -5.6960e-03,  2.5043e-02],\n",
      "          [-2.0500e-02, -1.8090e-03,  3.8288e-03,  3.0998e-02,  2.1696e-02],\n",
      "          [ 1.5632e-02, -1.0035e-02, -1.5057e-02, -3.6291e-03, -1.2105e-02]],\n",
      "\n",
      "         [[ 4.3575e-02,  3.2744e-02,  2.5933e-02, -1.4559e-02,  7.5022e-03],\n",
      "          [ 1.7084e-02,  3.0302e-02,  1.8411e-02, -4.2889e-03,  1.4817e-02],\n",
      "          [-6.3302e-03,  3.4061e-03,  1.6075e-02,  3.6235e-02,  2.2440e-02],\n",
      "          [ 2.5370e-02, -1.1693e-02,  3.9020e-03, -4.2874e-03,  9.4426e-03],\n",
      "          [-1.3052e-02,  1.6000e-02,  8.4074e-03,  1.9312e-02,  3.2250e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0773e-03, -4.7756e-03, -2.6075e-02,  7.0593e-04, -2.0724e-02],\n",
      "          [ 8.6347e-03,  3.1380e-02,  7.0248e-03,  6.9664e-04, -1.3843e-02],\n",
      "          [ 1.1562e-02, -2.5267e-03, -3.1230e-02, -7.0214e-02, -2.1667e-02],\n",
      "          [ 2.9985e-02, -2.9218e-02, -3.9314e-02, -5.7019e-02, -1.7566e-02],\n",
      "          [ 1.1145e-02,  1.7216e-02, -1.7798e-02, -7.5180e-03, -3.4850e-02]],\n",
      "\n",
      "         [[ 6.8056e-03, -2.2394e-03, -2.2389e-02, -2.9041e-02, -1.5022e-02],\n",
      "          [ 1.1402e-02,  2.2952e-03, -7.7950e-04,  1.5336e-02, -1.6059e-02],\n",
      "          [ 1.4813e-02,  1.0640e-02,  1.6357e-02, -7.2129e-03,  1.6183e-02],\n",
      "          [-2.9066e-02,  3.2242e-03,  1.6892e-03,  5.9828e-04,  2.2661e-02],\n",
      "          [-3.0449e-02, -1.3571e-02,  4.0671e-03,  2.1350e-02,  4.5814e-02]],\n",
      "\n",
      "         [[-1.4303e-03, -2.3961e-02,  4.6707e-03,  3.6754e-02,  3.8813e-02],\n",
      "          [-1.2965e-02,  7.2966e-03, -1.7047e-02, -4.5168e-03,  2.7444e-02],\n",
      "          [ 7.5062e-03, -1.5389e-02, -1.2647e-02,  2.2774e-02, -9.7620e-03],\n",
      "          [ 1.6637e-02, -8.3453e-03, -4.5586e-02,  1.9008e-02,  7.1367e-02],\n",
      "          [-5.1240e-02, -1.5092e-03, -1.6725e-02, -4.0964e-02, -1.1706e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6506e-03,  1.2139e-02,  2.8781e-02, -8.0509e-03,  1.5895e-02],\n",
      "          [ 1.0239e-02, -4.1854e-02, -2.3916e-02,  2.6856e-02, -4.4921e-02],\n",
      "          [ 7.8881e-03, -5.9166e-02, -2.2137e-02,  2.5146e-02, -1.6710e-02],\n",
      "          [ 3.2044e-02, -4.3532e-02, -1.1757e-02, -1.7552e-03, -1.8385e-02],\n",
      "          [-4.7417e-03, -2.5653e-02, -4.0672e-02,  7.0546e-03,  3.5900e-02]],\n",
      "\n",
      "         [[ 3.5661e-02,  1.5104e-02, -2.6415e-02, -3.7982e-02,  1.5504e-02],\n",
      "          [ 1.0505e-02, -1.7607e-02, -9.3305e-03,  9.6790e-04, -2.5903e-02],\n",
      "          [-1.2680e-02, -2.9056e-02, -3.2544e-02, -3.6679e-02, -1.3252e-02],\n",
      "          [ 1.2223e-02, -4.1775e-02, -3.4603e-02,  3.0720e-02,  1.3863e-02],\n",
      "          [-6.2249e-03, -1.8468e-02,  7.9194e-03,  3.1627e-02,  1.0434e-02]],\n",
      "\n",
      "         [[-1.2670e-02,  2.7794e-02, -3.1756e-02, -1.9545e-02, -1.5669e-02],\n",
      "          [-1.0748e-02, -1.8316e-02,  2.5383e-02,  2.7039e-02,  8.6383e-03],\n",
      "          [ 4.3478e-02,  2.1731e-02, -8.9791e-04,  9.1137e-03, -2.0767e-03],\n",
      "          [ 3.1436e-02, -1.4230e-02, -3.3946e-03, -2.0987e-02, -2.9764e-02],\n",
      "          [ 4.0309e-02, -1.0545e-02, -3.8607e-02,  1.1595e-02,  4.8088e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1716e-03, -6.9075e-03,  7.3945e-03,  4.6226e-02,  4.8241e-02],\n",
      "          [-4.7448e-02, -8.5029e-03,  8.1996e-03,  9.5392e-03, -8.7678e-03],\n",
      "          [-1.2243e-03, -1.9511e-02, -1.8004e-02,  4.9980e-03, -4.4034e-02],\n",
      "          [ 2.7607e-02,  1.8813e-02,  5.3168e-03,  1.6130e-02, -5.7260e-02],\n",
      "          [ 1.5967e-02, -4.1076e-03,  1.9380e-03, -2.5036e-02, -3.0140e-02]],\n",
      "\n",
      "         [[ 1.9123e-02,  2.6928e-02, -8.5267e-03, -2.5156e-02,  1.9606e-02],\n",
      "          [ 3.2547e-02, -9.7029e-03,  1.7721e-02,  3.3730e-03,  1.8454e-02],\n",
      "          [ 4.7949e-03,  7.5521e-03,  5.1694e-03, -1.8745e-02, -2.5131e-02],\n",
      "          [-1.4713e-02, -2.7054e-02, -1.5055e-02, -3.9259e-02, -4.2882e-02],\n",
      "          [-6.1763e-03,  4.2608e-03, -3.9871e-02, -2.0441e-02,  2.8255e-02]],\n",
      "\n",
      "         [[ 1.7911e-04, -2.7705e-02,  7.4567e-03, -7.7815e-03,  1.0754e-02],\n",
      "          [ 1.2968e-02,  1.8336e-02, -2.6162e-02,  8.5057e-03, -1.6728e-02],\n",
      "          [ 1.8662e-02, -5.0535e-03, -3.5682e-03,  4.7818e-03,  6.4465e-03],\n",
      "          [-8.0725e-03, -2.2225e-02, -1.5585e-02,  1.9765e-02,  2.6983e-02],\n",
      "          [-1.7744e-03,  3.1771e-02,  2.2464e-02,  4.9856e-02, -2.0052e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1636e-02,  3.6406e-03, -4.9798e-03, -3.2712e-02,  1.8686e-02],\n",
      "          [-2.4015e-02, -2.9529e-02,  2.8576e-03,  1.0004e-02,  3.5697e-02],\n",
      "          [ 1.3372e-03, -9.6411e-03,  2.8705e-03, -3.4739e-02, -3.4634e-03],\n",
      "          [-3.5694e-03, -9.9995e-03, -2.1466e-02, -4.2425e-02,  9.5719e-04],\n",
      "          [ 3.1898e-02,  1.8115e-02, -4.3609e-04, -2.2333e-02,  5.8269e-02]],\n",
      "\n",
      "         [[-1.4688e-02,  7.1689e-03,  1.5915e-02,  1.3031e-02,  1.4359e-05],\n",
      "          [-1.9244e-02,  3.5597e-03, -9.7087e-03,  4.3235e-03, -9.0674e-04],\n",
      "          [-2.2105e-02,  1.7777e-02,  2.7635e-02,  2.4699e-02, -3.5958e-03],\n",
      "          [ 1.8502e-02,  1.3185e-02,  3.8276e-02,  1.4577e-02,  3.7132e-03],\n",
      "          [ 1.2871e-02,  2.6597e-02, -3.5429e-02, -3.9985e-02,  3.7791e-03]],\n",
      "\n",
      "         [[-2.2851e-02, -1.5692e-02, -1.8015e-02, -3.3055e-02, -9.5762e-03],\n",
      "          [-2.8625e-02, -2.1499e-02, -7.1913e-04,  2.0229e-03,  2.8739e-02],\n",
      "          [-2.1588e-02,  6.3655e-03,  6.1064e-03,  1.6744e-02, -4.3112e-04],\n",
      "          [ 1.3859e-03, -4.0466e-02, -4.6002e-03, -6.7814e-03, -2.4726e-02],\n",
      "          [ 1.7854e-02,  2.8713e-02,  1.4501e-02,  4.3169e-02,  4.9306e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0892e-02,  7.1974e-03, -2.8859e-02, -1.4067e-02, -4.0946e-02],\n",
      "          [-6.2849e-03,  1.3068e-02,  2.6515e-02,  3.2869e-02,  3.8795e-04],\n",
      "          [-1.1046e-02, -3.1705e-02, -3.3232e-02, -1.4237e-02,  5.9231e-03],\n",
      "          [-2.9771e-02, -6.3033e-02, -1.6256e-02, -3.6637e-02,  1.0941e-03],\n",
      "          [-1.2793e-02, -4.7274e-02, -3.4209e-02, -4.2851e-02, -6.1728e-02]],\n",
      "\n",
      "         [[-1.6328e-02, -2.0266e-02, -4.5925e-02, -1.7571e-02,  3.4714e-03],\n",
      "          [ 7.8055e-03, -5.4706e-03, -1.4790e-02, -6.9649e-03, -1.2560e-03],\n",
      "          [ 1.1718e-02, -7.9241e-04, -4.4282e-04,  8.9964e-04,  3.3985e-02],\n",
      "          [-1.9284e-02, -8.9299e-04, -1.0150e-02,  2.6958e-02,  1.0335e-02],\n",
      "          [-3.6211e-02, -4.8618e-03,  2.7318e-02,  3.6467e-02,  8.0742e-03]],\n",
      "\n",
      "         [[ 2.0677e-02,  2.4666e-02, -2.9057e-02,  3.4566e-03, -1.8064e-02],\n",
      "          [-8.0914e-03, -1.8603e-03,  1.0439e-02,  4.3301e-02,  1.9674e-02],\n",
      "          [ 5.0481e-02,  4.4153e-03, -2.9713e-02, -4.1694e-02, -2.8885e-02],\n",
      "          [ 6.7306e-02,  6.4284e-02,  1.0161e-02,  7.1342e-03,  6.1471e-02],\n",
      "          [ 6.8040e-02,  1.1784e-02,  5.2976e-02,  2.9007e-04,  1.2841e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7379e-03,  6.0658e-03, -1.3832e-03, -3.6171e-02, -1.4843e-03],\n",
      "          [-7.0930e-03, -1.2878e-02,  1.4135e-02, -1.2419e-02, -4.9431e-03],\n",
      "          [ 1.8601e-02,  1.1590e-02,  3.7758e-02,  2.9792e-02,  1.0414e-02],\n",
      "          [-2.6243e-02, -7.0268e-03,  3.3730e-03, -5.5012e-03, -1.2038e-02],\n",
      "          [ 1.8668e-02,  2.1882e-02,  1.7373e-02,  2.6064e-02,  7.1715e-02]],\n",
      "\n",
      "         [[ 3.3746e-03,  1.3630e-03, -1.5595e-02, -2.0449e-02,  9.1014e-03],\n",
      "          [ 1.8770e-02,  1.0847e-02,  3.2893e-02,  7.0295e-03,  7.3982e-05],\n",
      "          [-4.0248e-03,  2.4646e-03,  5.7097e-03, -5.7029e-04,  8.1907e-04],\n",
      "          [ 2.5354e-02,  2.5421e-02,  2.5636e-02, -1.3615e-03,  2.1908e-02],\n",
      "          [-3.7938e-02, -2.5567e-02, -2.0588e-02, -1.6532e-02,  1.0787e-02]],\n",
      "\n",
      "         [[-2.7833e-02, -3.3187e-03, -4.9142e-02,  6.9386e-03, -1.0133e-02],\n",
      "          [-1.3573e-02, -3.8267e-03,  1.5522e-02, -6.2516e-03, -9.8197e-03],\n",
      "          [ 4.4737e-02,  2.7583e-02,  7.1284e-02,  5.1923e-02,  3.3277e-02],\n",
      "          [ 1.1604e-02,  2.1815e-02, -1.8878e-02, -8.8361e-03, -3.7243e-02],\n",
      "          [ 2.5180e-02, -9.5462e-03, -6.5099e-03,  1.0335e-02,  3.9928e-02]]]])), ('layers.conv2.bias', tensor([-0.2056, -0.1158, -0.1752, -0.0112, -0.1408, -0.1200, -0.2447, -0.2203,\n",
      "        -0.0533, -0.2383, -0.1442, -0.1619, -0.3433, -0.2228, -0.1151, -0.0699,\n",
      "        -0.1214, -0.1495, -0.1929, -0.1800, -0.2394, -0.1986, -0.1717, -0.3136,\n",
      "        -0.2552, -0.1498, -0.1285, -0.1279, -0.1910, -0.1982, -0.0473, -0.2023,\n",
      "        -0.0686, -0.2916, -0.0725, -0.0818, -0.1089, -0.1649, -0.1390, -0.1225,\n",
      "        -0.0968, -0.0076, -0.1452, -0.1032, -0.1445, -0.0678, -0.3530, -0.0647,\n",
      "        -0.2001, -0.1019, -0.2764, -0.1478, -0.1598, -0.1444, -0.2235, -0.0417,\n",
      "        -0.3906, -0.3320, -0.1224, -0.0824, -0.1366, -0.2355, -0.2195, -0.1494,\n",
      "        -0.1820, -0.3496, -0.0685, -0.1852, -0.0979, -0.0552, -0.0587, -0.1222,\n",
      "        -0.1607, -0.0987, -0.1318, -0.1276, -0.1527, -0.2442, -0.1604, -0.1841,\n",
      "        -0.1514, -0.1749, -0.1792, -0.1880, -0.2647, -0.1945, -0.2121, -0.1257])), ('layers.fc1.weight', tensor([[ 0.0255,  0.0434,  0.0211,  ..., -0.0142,  0.0072,  0.0158],\n",
      "        [-0.0334, -0.0026,  0.0194,  ...,  0.0069, -0.0635,  0.0247],\n",
      "        [ 0.0580, -0.0351, -0.0066,  ..., -0.0148,  0.0392, -0.0202],\n",
      "        ...,\n",
      "        [ 0.0033,  0.0312, -0.0124,  ..., -0.0085,  0.0193,  0.0054],\n",
      "        [-0.0345,  0.0243,  0.0079,  ..., -0.0161,  0.0208,  0.0449],\n",
      "        [-0.0198, -0.0145, -0.0594,  ..., -0.0173,  0.0198, -0.0457]])), ('layers.fc1.bias', tensor([-0.0458,  0.0064,  0.0602,  0.0068, -0.0657, -0.0527, -0.0180,  0.1359,\n",
      "        -0.1224, -0.0164,  0.0495,  0.0056, -0.0492, -0.0661,  0.1820, -0.0410,\n",
      "        -0.0635, -0.0882,  0.0973, -0.0706,  0.0642,  0.0055, -0.0208, -0.0150,\n",
      "         0.0183,  0.1227, -0.0299, -0.0614, -0.0220, -0.0141,  0.0041, -0.0014,\n",
      "        -0.1003,  0.0214, -0.0350, -0.0254, -0.1049, -0.0825, -0.0843, -0.0073,\n",
      "        -0.0467,  0.1026, -0.0253,  0.0229, -0.0316])), ('layers.fc2.weight', tensor([[ 0.0042,  0.0150, -0.0059,  ...,  0.1093, -0.0766,  0.1032],\n",
      "        [-0.0460, -0.2153, -0.1587,  ..., -0.1047, -0.1889, -0.1767],\n",
      "        [ 0.1011,  0.0832, -0.1889,  ..., -0.0507,  0.1864,  0.1390],\n",
      "        ...,\n",
      "        [ 0.0390,  0.1221,  0.0717,  ..., -0.0572,  0.0346, -0.0381],\n",
      "        [-0.2166, -0.0864,  0.0405,  ...,  0.0504, -0.0597, -0.1264],\n",
      "        [-0.1480,  0.2386,  0.0101,  ..., -0.1646, -0.0509, -0.1385]])), ('layers.fc2.bias', tensor([-0.3583, -0.1381,  0.1003,  0.0507,  0.0528,  0.0465, -0.0011, -0.1648,\n",
      "         0.3174,  0.0854,  0.1417, -0.0777, -0.0837, -0.0749, -0.1102, -0.1009,\n",
      "         0.1887,  0.0162, -0.0728, -0.1890,  0.1553,  0.5822, -0.0320, -0.1354,\n",
      "         0.3162, -0.2110, -0.0678, -0.2542,  0.2161,  0.1340, -0.0973, -0.2116,\n",
      "         0.2207,  0.1408,  0.1680,  0.1158, -0.0756,  0.0046,  0.0778,  0.0250,\n",
      "         0.0615,  0.2674,  0.2129,  0.1064,  0.0217,  0.1567,  0.1420,  0.1910])), ('layers.fc3.weight', tensor([[-0.2581, -0.0430, -0.1128,  ...,  0.0143, -0.0119, -0.1057],\n",
      "        [-0.2318, -0.1492,  0.0338,  ..., -0.0350, -0.0147, -0.0426],\n",
      "        [ 0.1388,  0.1283, -0.0987,  ..., -0.2485,  0.1386,  0.1170],\n",
      "        ...,\n",
      "        [-0.0507, -0.1285, -0.1045,  ..., -0.0496,  0.0910, -0.0317],\n",
      "        [-0.0236,  0.1130,  0.1583,  ...,  0.1497, -0.1245, -0.1716],\n",
      "        [-0.1789,  0.0125,  0.0148,  ...,  0.0211,  0.0231, -0.1194]])), ('layers.fc3.bias', tensor([-0.0537,  0.1571, -0.2316,  0.3119,  0.0157, -0.1130, -0.1027, -0.1213,\n",
      "        -0.0543, -0.0351,  0.1836, -0.1279,  0.0029,  0.0024,  0.3741, -0.1337,\n",
      "         0.2323, -0.1124, -0.0655, -0.1274,  0.0774, -0.0023, -0.0391,  0.0576,\n",
      "         0.1509,  0.0727,  0.1985,  0.1129, -0.0638,  0.1008, -0.0575,  0.1577,\n",
      "        -0.0089,  0.5957,  0.1898,  0.0274, -0.2516,  0.1715, -0.0188,  0.0762,\n",
      "        -0.1388,  0.0350, -0.1582,  0.0863,  0.2382, -0.0560, -0.0572,  0.2554,\n",
      "         0.3028, -0.1194, -0.1319, -0.0586,  0.0150,  0.2779, -0.1402, -0.0501,\n",
      "         0.0097, -0.1476,  0.2674])), ('layers.fc4.weight', tensor([[ 0.1625, -0.0949, -0.2259,  ..., -0.0308,  0.0811, -0.0642],\n",
      "        [ 0.0457, -0.0282, -0.1100,  ...,  0.1064, -0.0489, -0.1204],\n",
      "        [-0.1592,  0.0244,  0.0141,  ...,  0.0520,  0.0686,  0.1606],\n",
      "        ...,\n",
      "        [ 0.1075, -0.0259, -0.0930,  ..., -0.1269, -0.1203, -0.0560],\n",
      "        [-0.0071, -0.0729, -0.1015,  ...,  0.1184,  0.1224, -0.1219],\n",
      "        [-0.0682, -0.0239,  0.1744,  ..., -0.0150, -0.1896, -0.0399]])), ('layers.fc4.bias', tensor([ 0.2765,  0.0166,  0.0142, -0.0321, -0.1026, -0.0700,  0.0124,  0.2208,\n",
      "         0.0497,  0.0066,  0.0417,  0.0039,  0.1682, -0.0460, -0.1193, -0.2985,\n",
      "        -0.1685, -0.1133,  0.1428, -0.0011,  0.1474,  0.0960,  0.0175,  0.3466,\n",
      "         0.1906, -0.0160, -0.2361, -0.1321, -0.0953,  0.0652,  0.0484, -0.0933,\n",
      "         0.0058,  0.1075,  0.3195,  0.1631, -0.1119, -0.1166, -0.0291,  0.1982,\n",
      "         0.0417, -0.0994,  0.2354,  0.5239,  0.0506,  0.0297, -0.0789, -0.1067,\n",
      "         0.0434, -0.1332, -0.1135,  0.1882,  0.4569,  0.0666, -0.1000, -0.0059,\n",
      "         0.2235, -0.0419, -0.0049, -0.0325, -0.0800, -0.0037])), ('layers.fco.weight', tensor([[-0.2044, -0.0944,  0.0692,  0.0115,  0.0886, -0.1746, -0.0727, -0.3381,\n",
      "          0.0343, -0.2013,  0.1429,  0.1045, -0.2873, -0.0106, -0.1445,  0.2881,\n",
      "          0.0052,  0.0356, -0.1123,  0.1649,  0.1559,  0.0762, -0.0154,  0.0484,\n",
      "         -0.2421, -0.1248, -0.1393, -0.0032,  0.1129,  0.1915,  0.2492,  0.1495,\n",
      "         -0.0878,  0.2346,  0.0757,  0.1276, -0.1335, -0.0543,  0.1989,  0.3184,\n",
      "         -0.0306,  0.0363, -0.0404, -0.1648, -0.1391,  0.0116, -0.0259, -0.0048,\n",
      "          0.0875, -0.0416,  0.1328, -0.2432, -0.3093,  0.2007, -0.0257, -0.0357,\n",
      "         -0.1667,  0.0599,  0.0259,  0.0398, -0.0103,  0.3488],\n",
      "        [-0.2800, -0.0342, -0.1302,  0.0350,  0.0469, -0.1631, -0.0605,  0.0265,\n",
      "          0.1767,  0.0156,  0.0832,  0.2276,  0.0717, -0.0250,  0.2574,  0.1791,\n",
      "          0.2906,  0.2051, -0.3602, -0.1114, -0.3003, -0.0480,  0.0864, -0.1345,\n",
      "         -0.1807, -0.0572,  0.4384,  0.0297, -0.0621,  0.1498,  0.0904, -0.0138,\n",
      "          0.0301, -0.2184, -0.0649, -0.0745,  0.0889,  0.0596,  0.1416, -0.1694,\n",
      "          0.2505,  0.0852, -0.3389, -0.4047,  0.2823, -0.0604, -0.0350,  0.1217,\n",
      "         -0.1690,  0.1540,  0.0497, -0.2392,  0.0365,  0.1268, -0.0099,  0.0956,\n",
      "         -0.1431, -0.0840, -0.0451,  0.0210, -0.1135,  0.2035],\n",
      "        [ 0.0295,  0.0426,  0.1960, -0.0435,  0.1109,  0.0796, -0.1017,  0.3778,\n",
      "          0.1751, -0.0523, -0.1601, -0.1223, -0.0298, -0.0126, -0.0479, -0.0470,\n",
      "         -0.0967,  0.1241, -0.0754, -0.1248,  0.0454, -0.0126, -0.0803, -0.1456,\n",
      "          0.1289,  0.1208, -0.1457, -0.0485, -0.0768,  0.0436, -0.1870,  0.1797,\n",
      "          0.1007,  0.0382, -0.0486,  0.0384,  0.0142,  0.0820, -0.0360,  0.3205,\n",
      "          0.0098,  0.0267,  0.3789,  0.2484,  0.0611, -0.2190, -0.0534,  0.0207,\n",
      "          0.3800, -0.1577, -0.0278,  0.2420,  0.1671, -0.0238, -0.0488, -0.1683,\n",
      "         -0.0384, -0.0634,  0.0656,  0.1023,  0.0438,  0.0604],\n",
      "        [ 0.3080,  0.0301,  0.1250, -0.0059,  0.0108,  0.0187,  0.0470,  0.1360,\n",
      "          0.0263, -0.1706, -0.2061, -0.1102,  0.1613,  0.1560, -0.1044,  0.0807,\n",
      "         -0.2036,  0.0227,  0.1456,  0.0211,  0.1844, -0.0346, -0.1861,  0.0659,\n",
      "          0.0977, -0.0442, -0.1390, -0.0092, -0.1245, -0.2244, -0.1701, -0.0859,\n",
      "         -0.1229,  0.1884,  0.0856,  0.1219, -0.0711,  0.0306, -0.0908, -0.3218,\n",
      "          0.1819, -0.0169,  0.1087,  0.1883, -0.2201,  0.1343, -0.0262, -0.1073,\n",
      "         -0.0858, -0.1639,  0.0351,  0.0805,  0.0579, -0.1028, -0.0887,  0.3079,\n",
      "          0.2052,  0.0154,  0.0816,  0.1223, -0.0811, -0.0174],\n",
      "        [-0.1386, -0.0042, -0.0827, -0.2869,  0.1120, -0.1687,  0.1897,  0.0357,\n",
      "         -0.2384,  0.0567,  0.0233,  0.1801,  0.1559, -0.0749,  0.0341, -0.2831,\n",
      "         -0.2497, -0.1517, -0.0610,  0.0244,  0.0453, -0.1242,  0.0886,  0.3531,\n",
      "         -0.1117,  0.0890, -0.2123, -0.1239, -0.0285,  0.0571, -0.1180, -0.1800,\n",
      "          0.1029, -0.1523,  0.3623,  0.0887, -0.0704, -0.0468, -0.2214,  0.1832,\n",
      "         -0.0343, -0.1618,  0.1649,  0.5164, -0.0737, -0.0082,  0.0520,  0.0488,\n",
      "         -0.2954,  0.0718,  0.0132,  0.1365,  0.2931, -0.0186,  0.0860, -0.1746,\n",
      "         -0.1218,  0.1279, -0.0474, -0.0847,  0.0748, -0.2386],\n",
      "        [ 0.2116,  0.0522,  0.0693,  0.0846, -0.0897,  0.1922, -0.0153,  0.0612,\n",
      "          0.1240,  0.2717, -0.0873, -0.0268,  0.3510, -0.0867,  0.1252,  0.0370,\n",
      "         -0.0424, -0.0260, -0.0518, -0.1115,  0.2050,  0.0072,  0.1113, -0.0070,\n",
      "         -0.0317, -0.0586, -0.1202,  0.1234,  0.1187, -0.1002, -0.0470, -0.0902,\n",
      "          0.0327,  0.2746, -0.1292, -0.2124, -0.0103,  0.0652, -0.1500, -0.2721,\n",
      "         -0.0614, -0.0621,  0.1570,  0.3421, -0.2090,  0.3078,  0.0903,  0.0884,\n",
      "         -0.0942, -0.0337, -0.0353,  0.1149, -0.0869, -0.1558,  0.1128,  0.1934,\n",
      "          0.0948, -0.0792,  0.0210,  0.0881, -0.0509, -0.3143],\n",
      "        [ 0.2084, -0.1034, -0.1842,  0.1338, -0.1407,  0.1704, -0.1616,  0.2144,\n",
      "         -0.2574, -0.1264, -0.1381,  0.0022,  0.0508, -0.1184,  0.1019, -0.0619,\n",
      "          0.1804, -0.0606,  0.3120, -0.1228,  0.2330, -0.0369,  0.0861,  0.0711,\n",
      "          0.2820, -0.1246, -0.0406,  0.0499,  0.0910, -0.3654, -0.3070,  0.2178,\n",
      "         -0.0704,  0.0181, -0.2009, -0.2949, -0.1468, -0.0825,  0.1316,  0.1316,\n",
      "          0.2417, -0.0212, -0.1199,  0.0562, -0.1430, -0.0309,  0.0735,  0.1026,\n",
      "         -0.0901, -0.1264, -0.0391,  0.1167,  0.4715,  0.0009,  0.0684, -0.0786,\n",
      "         -0.3464, -0.1484, -0.0091, -0.1199, -0.0775, -0.2400],\n",
      "        [-0.0081,  0.0431, -0.2556,  0.0956, -0.1352, -0.0227, -0.2097,  0.0168,\n",
      "          0.0540,  0.2873, -0.1623, -0.1458,  0.4376, -0.0798, -0.1158, -0.1260,\n",
      "         -0.0937,  0.0827, -0.0470,  0.1169, -0.0322,  0.1166, -0.0223,  0.1271,\n",
      "         -0.0011, -0.0837, -0.1956, -0.1119, -0.1098,  0.2457,  0.0371,  0.0364,\n",
      "          0.0587, -0.0274,  0.2384, -0.0970,  0.0909,  0.0502,  0.0963, -0.2679,\n",
      "         -0.2817,  0.3290,  0.4150, -0.0319, -0.2482, -0.2148, -0.0881, -0.0033,\n",
      "         -0.0909,  0.1895, -0.0249,  0.1861, -0.3132, -0.1497, -0.1336,  0.1982,\n",
      "          0.1437, -0.1621,  0.0676,  0.0295,  0.1153, -0.2328],\n",
      "        [-0.2679,  0.1109,  0.0739,  0.1319, -0.2094,  0.1016,  0.0472, -0.3565,\n",
      "         -0.0599,  0.1845,  0.1318,  0.1838, -0.3166, -0.1037,  0.0123, -0.2767,\n",
      "          0.1651, -0.0651, -0.1347, -0.0595, -0.0101, -0.1542, -0.0687, -0.2341,\n",
      "          0.3027, -0.0721,  0.1526,  0.0781, -0.0672,  0.1057,  0.5054, -0.1013,\n",
      "         -0.0389, -0.2540, -0.2605,  0.3961,  0.0201,  0.0237, -0.2525,  0.1738,\n",
      "          0.1945,  0.0757, -0.2944, -0.2703,  0.1196,  0.0761, -0.0506, -0.0366,\n",
      "          0.1072, -0.0812, -0.1011, -0.3297, -0.1774,  0.2274,  0.0396, -0.0564,\n",
      "         -0.0174,  0.0250,  0.0258, -0.0417,  0.1210,  0.1522],\n",
      "        [ 0.0752, -0.0227, -0.2447,  0.1195,  0.0087, -0.0666, -0.0632,  0.0264,\n",
      "         -0.0033, -0.1730,  0.3859, -0.1239,  0.0203,  0.0648,  0.1345, -0.1549,\n",
      "          0.0688,  0.0557,  0.0547,  0.1026, -0.2453, -0.0209,  0.2822, -0.2200,\n",
      "         -0.2740, -0.0720,  0.1038, -0.0161, -0.0822,  0.1182,  0.0875, -0.0807,\n",
      "         -0.1192, -0.1243,  0.1247, -0.0721,  0.0107,  0.0468,  0.2913, -0.1686,\n",
      "         -0.0080, -0.0621, -0.3003, -0.4714,  0.4283, -0.0996, -0.0027,  0.0357,\n",
      "          0.0293,  0.0455,  0.0810, -0.0532, -0.1837,  0.2583,  0.0435,  0.1244,\n",
      "          0.0276, -0.0346, -0.0636,  0.0289,  0.1011,  0.2277]])), ('layers.fco.bias', tensor([-0.3017, -0.5769,  0.1089,  0.5034,  0.6899,  0.2438,  0.0875, -0.0981,\n",
      "        -0.1159, -0.1708]))])\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!rm -rf ./data/* ./ray_results/layers/* ./ray_results/neurons/* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
