{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial # for trials\n",
    "import numpy as np # for accuracy math\n",
    "import os # for paths\n",
    "import torch # for nn instantiation\n",
    "import torch.nn as nn # for nn objects\n",
    "import torch.nn.functional as F # for forward method\n",
    "import torch.optim as optim # for optimization\n",
    "from torch.utils.data import random_split # for train/test split\n",
    "import torchvision # for data transforms\n",
    "import torchvision.transforms as transforms # for transform methods\n",
    "from ray import tune # for trialing\n",
    "from ray.tune import CLIReporter # for trial reporting\n",
    "from ray.tune import JupyterNotebookReporter # for trial reporting\n",
    "from ray.tune.schedulers import ASHAScheduler # for trial scheduling\n",
    "from ray.tune.schedulers import HyperBandForBOHB # for trial scheduling\n",
    "from ray.tune.suggest.bohb import TuneBOHB # for trial selection/pruning\n",
    "import ConfigSpace as CS # for configuration bounds\n",
    "from collections import OrderedDict # for dynamic configuration definition\n",
    "from pathlib import Path # for OS agnostic path definition\n",
    "\n",
    "# import itertools package \n",
    "import itertools \n",
    "from itertools import permutations\n",
    "from itertools import product\n",
    "\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data and checkpoint locations\n",
    "p = Path('.')\n",
    "d = p / 'data'\n",
    "r = p / 'ray_results'\n",
    "l = p / 'checkpoints' / 'layers'\n",
    "n = p / 'checkpoints' / 'layers'\n",
    "\n",
    "## set number (or fraction) of GPUs (per training loop) you'd like to utilize if any at all\n",
    "cpu_use = 1\n",
    "gpu_use = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#define feature space for hashing\n",
    "def feature_spacing():\n",
    "    conv = set(range(3**5)) - set(range(3**2))\n",
    "    full = set(range(2**5)) - set(range(2**2))\n",
    "    \n",
    "    c = 3**5 - 3**2\n",
    "    f = 2**5 - 2**2\n",
    "    \n",
    "    # create empty list to store the \n",
    "    # combinations \n",
    "    unique_combinations = []\n",
    "    total_uniques = 0\n",
    "    total_points = 1\n",
    "    \n",
    "    # do combo\n",
    "#     for combo in product(conv,conv,full):\n",
    "#         unique_combinations.append(combo)\n",
    "        \n",
    "#     for combo in product(conv,conv,full,full):\n",
    "#         unique_combinations.append(combo)\n",
    "        \n",
    "#     for combo in product(conv,conv,full,full,full):\n",
    "#         unique_combinations.append(combo)\n",
    "        \n",
    "#     for combo in product(conv,conv,full,full,full,full):\n",
    "#         unique_combinations.append(combo)\n",
    "\n",
    "    for ls in range(0,4):\n",
    "#         print(ls)\n",
    "        unique_combinations.append((c**2)*(f*(f+1)**ls))\n",
    "        total_uniques += (c**2)*f*((f+1)**ls)\n",
    "#         total_points = ((c**2)*f*((f+1)**ls))\n",
    "    \n",
    "    total_uniques -= ((c**2)*f)\n",
    "    total_points = total_uniques**2\n",
    "#     print(\"number of combos: %s\" % [\"%s-fc model: %s\" % (l,v) for l,v in enumerate(unique_combinations, 1)])\n",
    "#     print(\"total uniques:\",total_uniques)\n",
    "#     print(\"number of points/indices (with sparicities/noise): %s\" % total_points)\n",
    "#     print(\"\\n\")\n",
    "    \n",
    "    columns = [\"base\",\"nodes_req\",\"sparcity\",\"sparcity_pcnt\",\"denoise_pcnt\"]\n",
    "    values = [1,total_uniques,total_points - total_uniques,(total_points - total_uniques) / total_points,0]\n",
    "    results = {\n",
    "        \"base\": [1],\n",
    "        \"nodes_req\": [total_uniques],\n",
    "        \"sparcity\": [total_points - total_uniques],\n",
    "        \"sparcity_pcnt\": [(total_points - total_uniques) / total_points * 100],\n",
    "        \"denoise_pcnt\":[0]\n",
    "    }\n",
    "    \n",
    "    report = pd.DataFrame(results)\n",
    "    \n",
    "#     print(report.to_string())\n",
    "    \n",
    "    for base in range(2,11):\n",
    "        results[\"base\"] = [base]\n",
    "        results[\"nodes_req\"] = [math.ceil(math.log(total_uniques,(base)))]\n",
    "# #         print(\"number of base %s complex nodes required:\" % (base), math.ceil(math.log(total_uniques,(base))))\n",
    "#         print(\"number of base %s complex nodes required:\" % (base), results[\"nodes_req\"])\n",
    "        results[\"sparcity\"] = [base**math.ceil(math.log(total_uniques,base)) - total_uniques]\n",
    "# #         print(\"sparcity:\",base**math.ceil(math.log(total_uniques,base)) - total_uniques,'points')\n",
    "#         print(\"sparcity:\",results[\"sparcity\"],'points')\n",
    "        results[\"sparcity_pcnt\"] = [(base**math.ceil(math.log(total_uniques,(base))) - base**math.log(total_uniques,(base)))/(base**math.ceil(math.log(total_uniques,(base))))*100]\n",
    "# #         print(\"sparcity percentage:\",(base**math.ceil(math.log(total_uniques,(base))) - base**math.log(total_uniques,(base)))/(base**math.ceil(math.log(total_uniques,(base))))*100,'%')\n",
    "#         print(\"sparcity percentage:\",results[\"sparcity percentage\"],'%')\n",
    "#         print(\"%s root-%s nodes per layer\" % (math.ceil(math.log(total_uniques,base+1)),base+1))\n",
    "#         print(\"\\n\")\n",
    "        results[\"denoise_pcnt\"] = [math.floor(((total_points-(math.ceil(math.log(total_uniques,base)))**2)/total_points)*100)]\n",
    "# #         print(\"noise reduced from total points:\",math.floor(((total_points-(math.ceil(math.log(total_uniques,base)))**2)/total_points)*100),'%')\n",
    "#         print(\"noise reduced from total points:\",results[\"denoise_pcnt\"],'%')\n",
    "    \n",
    "        report = report.append(pd.DataFrame(results))\n",
    "#     for root in range(1,8):\n",
    "#         print(\"ceilinged %s-root (%s-value per number component) of combos with complex numbers: %s\\n\" % (root*2, root+1, [[math.ceil(combo**(1/(root*2))),\"sparsity: %s%s\" % ((math.ceil(combo**(1/(root*2))) - combo**(1/(root*2)))/combo**(1/(root*2))*100,'%')] for combo in unique_combinations]))\n",
    "    \n",
    "    print(report.sort_values([\"sparcity_pcnt\",\"nodes_req\",\"base\"]).to_string())\n",
    "#     report.head()\n",
    "    \n",
    "#     print(len(product(conv,conv,full)))\n",
    "#     print(f1)\n",
    "feature_spacing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base = 8\n",
    "c = 3**5 - 3**2\n",
    "f = 2**5 - 2**2\n",
    "def decode(code=None):\n",
    "    conv = []\n",
    "    full = []\n",
    "    \n",
    "    print(math.ceil(math.log(c,base)))\n",
    "    print(base**math.ceil(math.log(c,base)) - c)\n",
    "    print(math.ceil(math.log(f,base)))\n",
    "    print(base**math.ceil(math.log(f,base)) - f)\n",
    "    \n",
    "    model = [conv,full]\n",
    "#     return model\n",
    "    print()\n",
    "    \n",
    "decode()\n",
    "[print(math.log(278,b)) for b in range(2,9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# math.sqrt(3**5)\n",
    "poss = ((2**5 - 2**2)+1)**3\n",
    "print(\"%s possibilities\" % poss)\n",
    "[print(\"%s root-%s nodes per layer\" % (math.ceil(math.log(poss,root)),root)) for root in range(2,5)]\n",
    "[print(\"%s root-%s nodes per layer\" % (math.log(poss,root),root)) for root in range(2,5)]\n",
    "# print(math.ceil(poss**(1/2)))\n",
    "# print(math.log(poss,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2**5 - 2**2)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = ['1', '2', '3']\n",
    "b = ['1', '2', '3']\n",
    "c = ['1', '2', '3']\n",
    "d = ['1', '2', '3']\n",
    "\n",
    "# for r in product(product(a, b, d),c): print(r)\n",
    "r = [comb for comb in product(a, b, d)]\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move data into sets for loading\n",
    "def load_data(data_dir=d.absolute()):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset,testset = [torchvision.datasets.CIFAR10(root=data_dir, train=is_train, download=True, transform=transform) for is_train in [True,False]]\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamically-generated nn that takes a 3-channel image and outputs a label\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_layers=[[6, 16],[120,84]]):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_convs,hidden_fcs = hidden_layers\n",
    "        print(hidden_convs)\n",
    "        print(hidden_fcs)\n",
    "        uf_input = 0\n",
    "        layer_list = OrderedDict()\n",
    "        \n",
    "        layer_list['conv1'] = nn.Conv2d(3, hidden_convs[0], 5)\n",
    "        layer_list['pool1'] = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        layer_input = layer_list['conv1'].out_channels\n",
    "        \n",
    "        for layer_num, channels in enumerate(hidden_convs[1:], 2):\n",
    "            layer_list[\"conv%s\" % layer_num]  = nn.Conv2d(layer_input, channels, 5)\n",
    "            layer_list[\"pool%s\" % layer_num] = nn.MaxPool2d(2, 2)\n",
    "            layer_input = layer_list[\"conv%s\" % layer_num].out_channels\n",
    "        \n",
    "        \n",
    "        layer_list[\"flat\"] = nn.Flatten()\n",
    "        \n",
    "        layer_list['fc1'] = nn.Linear(layer_input*5*5, hidden_fcs[0])\n",
    "        layer_list[\"relu1\"]  = nn.ReLU()\n",
    "        \n",
    "        layer_input = layer_list['fc1'].out_features\n",
    "        for (layer_num, features) in enumerate(hidden_fcs[1:], 2):\n",
    "            layer_list[\"fc%s\" % layer_num]  = nn.Linear(layer_input, features)\n",
    "            layer_list[\"relu%s\" % layer_num]  = nn.ReLU()\n",
    "            layer_input = layer_list[\"fc%s\" % layer_num].out_features\n",
    "            \n",
    "        \n",
    "        layer_list['fco'] = nn.Linear(hidden_fcs[-1], 10)\n",
    "    \n",
    "        self.layers = nn.Sequential(layer_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# train nn on data\n",
    "def train_cifar(neuron_config, checkpoint_dir=None):\n",
    "    \n",
    "    data_dir=d.absolute()\n",
    "    \n",
    "    def cv_discrim(s): return 'cv' in s\n",
    "    def fc_discrim(s): return 'fc' in s\n",
    "    cvs = [neuron_config[hp] for hp in list(filter(cv_discrim, neuron_config.keys()))]\n",
    "    fcs = [neuron_config[hp] for hp in list(filter(fc_discrim, neuron_config.keys()))]\n",
    "#     cvs = neuron_config[\"cvs\"]\n",
    "#     fcs = neuron_config[\"fcs\"]\n",
    "    \n",
    "    net = Net([cvs, fcs])\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=neuron_config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader,valloader = [torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(neuron_config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=1) for subset in [train_subset,val_subset]]\n",
    "\n",
    "    for epoch in range(neuron_config[\"epochs\"]):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=(correct / total))\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy score\n",
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=1)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine configuration boundary for nn based on number of layers\n",
    "def configure_neurons(num_convs,num_fcs):\n",
    "    config_space = CS.ConfigurationSpace()\n",
    "    \n",
    "    config_space.add_hyperparameter(\n",
    "        CS.UniformFloatHyperparameter(name=\"lr\", lower=1e-4, upper=1e-1, log=True))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"batch_size\", choices=[4, 8, 16, 32]))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"epochs\", choices=[20, 30, 40]))\n",
    "    \n",
    "    for hidden in range(2):\n",
    "        config_space.add_hyperparameter(\n",
    "            CS.UniformIntegerHyperparameter(\"cv%s\" % hidden, lower=3, upper=3**4))\n",
    "    \n",
    "    for hidden in range(num_fcs):\n",
    "        config_space.add_hyperparameter(\n",
    "            CS.UniformIntegerHyperparameter(\"fc%s\" % hidden, lower=2**2, upper=2**6))\n",
    "        \n",
    "    return config_space\n",
    "\n",
    "# def configure_neurons():\n",
    "#     config_space = {\n",
    "#         \"batch_size_seed\": tune.randint(2, 6),\n",
    "#         \"cv_seed\": tune.grid_search([2]),\n",
    "#         \"fc_seed\": tune.randint(2, 4),\n",
    "        \n",
    "#         \"lr\": tune.loguniform(1e-4,1e-1),\n",
    "#         \"batch_size\": tune.sample_from(lambda spec: 2**spec.config.batch_size_seed),\n",
    "#         \"epochs\": tune.qrandint(20, 40, 10),\n",
    "        \n",
    "#         \"cvs\": tune.sample_from(lambda spec: [tune.randint(3, 3**4) for layer in range(spec.config.cv_seed)]),\n",
    "#         \"fcs\": tune.sample_from(lambda spec: [tune.randint(2**2, 2**4) for layer in range(spec.config.fc_seed)])        \n",
    "#     }\n",
    "        \n",
    "#     return config_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neuron_config_space = configure_neurons()\n",
    "print(neuron_config_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform neuron configuration trials\n",
    "def search_neurons(layer_config, checkpoint_dir=None):\n",
    "    num_samples=40\n",
    "    max_num_epochs=40\n",
    "    gpus_per_trial=1\n",
    "    \n",
    "#     print(layer_config)\n",
    "    \n",
    "    neuron_config_space = configure_neurons(layer_config[\"num_convs\"], layer_config[\"num_fcs\"])\n",
    "#     neuron_config_space = configure_neurons()\n",
    "    \n",
    "    experiment_metrics = dict(metric=\"accuracy\", mode=\"max\")\n",
    "    \n",
    "    scheduler = HyperBandForBOHB(\n",
    "#         metric=\"loss\",\n",
    "#         mode=\"min\",\n",
    "        max_t=20,\n",
    "        reduction_factor=2,\n",
    "        **experiment_metrics)\n",
    "    search = TuneBOHB(\n",
    "        neuron_config_space,\n",
    "        max_concurrent=8,\n",
    "#         metric=\"loss\",\n",
    "#         mode=\"min\",\n",
    "        **experiment_metrics)\n",
    "    reporter = JupyterNotebookReporter(\n",
    "        overwrite=True,\n",
    "#         parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\", \"epochs\"],\n",
    "        parameter_columns=neuron_config_space.get_hyperparameter_names(),\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_cifar),\n",
    "        verbose=2,\n",
    "        name=\"neurons\",\n",
    "        local_dir=r.absolute(),\n",
    "        resources_per_trial={\"cpu\": cpu_use, \"gpu\": gpu_use},\n",
    "        max_failures=3,\n",
    "#         config=neuron_config_space,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    \n",
    "    def cv_discrim(s): return 'cv' in s\n",
    "    def fc_discrim(s): return 'fc' in s\n",
    "    best_cvs = [best_trial.config[hp] for hp in list(filter(cv_discrim, best_trial.config.keys()))]\n",
    "    best_fcs = [best_trial.config[hp] for hp in list(filter(fc_discrim, best_trial.config.keys()))]\n",
    "# #     best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
    "    \n",
    "#     best_trained_model = Net(best_trial.config[\"cvs\"], best_trial.config[\"fcs\"])\n",
    "    best_trained_model = Net([best_cvs, best_fcs])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    \n",
    "    if checkpoint_dir != None:\n",
    "        tune.report(accuracy=test_acc)\n",
    "    \n",
    "#     with tune.checkpoint_dir(\"nodes\") as checkpoint_dir:\n",
    "#         path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "#         torch.save(best_trained_model.state_dict(), path)\n",
    "    \n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "    \n",
    "    return best_trained_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform layer count trials\n",
    "def search_layers(num_samples=10, max_num_epochs=10, gpus_per_trial=0):\n",
    "    data_dir=d.absolute()\n",
    "    load_data(data_dir)\n",
    "    layer_config_space = CS.ConfigurationSpace()\n",
    "\n",
    "    layer_config_space.add_hyperparameter(\n",
    "        CS.Constant(\"num_convs\", value=2))\n",
    "    layer_config_space.add_hyperparameter(\n",
    "        CS.UniformIntegerHyperparameter(\"num_fcs\", lower=2, upper=2**2))\n",
    "    \n",
    "    experiment_metrics = dict(metric=\"accuracy\", mode=\"max\")\n",
    "    \n",
    "\n",
    "    scheduler = HyperBandForBOHB(\n",
    "        max_t=max_num_epochs,\n",
    "        reduction_factor=2,\n",
    "        **experiment_metrics)\n",
    "    search = TuneBOHB(\n",
    "        layer_config_space,\n",
    "        max_concurrent=4,\n",
    "        **experiment_metrics)\n",
    "    reporter = CLIReporter(\n",
    "#         overwrite=True,\n",
    "        parameter_columns=layer_config_space.get_hyperparameter_names(),\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(search_neurons),\n",
    "        verbose=2,\n",
    "        name=\"layers\",\n",
    "        local_dir=r.absolute(),\n",
    "#         config=layer_config_space,\n",
    "        resources_per_trial={\"gpu\": gpus_per_trial},\n",
    "        max_failures=3,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = Net([best_trial.config[\"num_convs\"], best_trial.config[\"num_fcs\"]])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"),map_location=torch.device('cpu'))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "    \n",
    "    return best_trained_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform test\n",
    "model = Net()\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    model = search_layers(num_samples=10, max_num_epochs=10, gpus_per_trial=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using HyperBand: num_stopped=30 total_brackets=5\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=1, Milestone (r)=12, completed=100.0%): {TERMINATED: 16} \n",
       "  Bracket(Max Size (n)=2, Milestone (r)=12, completed=100.0%): {TERMINATED: 10} \n",
       "  Bracket(Max Size (n)=2, Milestone (r)=10, completed=100.0%): {TERMINATED: 7} \n",
       "  Bracket(Max Size (n)=3, Milestone (r)=10, completed=100.0%): {TERMINATED: 5} \n",
       "  Bracket(Max Size (n)=5, Milestone (r)=20, completed=100.0%): {TERMINATED: 2} <br>Resources requested: 0/8 CPUs, 0.0/2 GPUs, 0.0/14.5 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /home/grottesco/Source/CIFAR-Trainer/ray_results/neurons<br>Number of trials: 40/40 (40 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  cv0</th><th style=\"text-align: right;\">  cv1</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  fc0</th><th style=\"text-align: right;\">  fc1</th><th style=\"text-align: right;\">  fc2</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DEFAULT_ccf91220</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   79</td><td style=\"text-align: right;\">   64</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   44</td><td style=\"text-align: right;\">   11</td><td style=\"text-align: right;\">   25</td><td style=\"text-align: right;\">0.00225158 </td><td style=\"text-align: right;\">1.10831 </td><td style=\"text-align: right;\">  0.60245 </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_ccfd7068</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   79</td><td style=\"text-align: right;\">   65</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   60</td><td style=\"text-align: right;\">   51</td><td style=\"text-align: right;\">   58</td><td style=\"text-align: right;\">0.0381659  </td><td style=\"text-align: right;\">1.97126 </td><td style=\"text-align: right;\">  0.262575</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_ccfe637e</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   44</td><td style=\"text-align: right;\">   37</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   59</td><td style=\"text-align: right;\">   16</td><td style=\"text-align: right;\">   18</td><td style=\"text-align: right;\">0.000715338</td><td style=\"text-align: right;\">0.643974</td><td style=\"text-align: right;\">  0.777375</td><td style=\"text-align: right;\">                  12</td></tr>\n",
       "<tr><td>DEFAULT_ccff802e</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   73</td><td style=\"text-align: right;\">   66</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   51</td><td style=\"text-align: right;\">   39</td><td style=\"text-align: right;\">   35</td><td style=\"text-align: right;\">0.000190119</td><td style=\"text-align: right;\">2.29163 </td><td style=\"text-align: right;\">  0.174175</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_cd099884</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   43</td><td style=\"text-align: right;\">   30</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   21</td><td style=\"text-align: right;\">   17</td><td style=\"text-align: right;\">   31</td><td style=\"text-align: right;\">0.000259618</td><td style=\"text-align: right;\">1.9894  </td><td style=\"text-align: right;\">  0.2644  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_cd0b16e6</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   55</td><td style=\"text-align: right;\">   11</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   50</td><td style=\"text-align: right;\">   55</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">0.000179981</td><td style=\"text-align: right;\">1.57088 </td><td style=\"text-align: right;\">  0.4273  </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_cd0c8832</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   68</td><td style=\"text-align: right;\">   21</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   40</td><td style=\"text-align: right;\">   48</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">0.000834027</td><td style=\"text-align: right;\">2.14141 </td><td style=\"text-align: right;\">  0.212425</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_cd0df8f2</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   10</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\">    8</td><td style=\"text-align: right;\">   32</td><td style=\"text-align: right;\">0.00158996 </td><td style=\"text-align: right;\">1.53941 </td><td style=\"text-align: right;\">  0.4252  </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_df30c032</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   22</td><td style=\"text-align: right;\">   65</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">   15</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">0.000888001</td><td style=\"text-align: right;\">0.883722</td><td style=\"text-align: right;\">  0.692975</td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>DEFAULT_dfba6e5e</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   22</td><td style=\"text-align: right;\">   17</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   30</td><td style=\"text-align: right;\">   15</td><td style=\"text-align: right;\">   25</td><td style=\"text-align: right;\">0.0267864  </td><td style=\"text-align: right;\">1.89328 </td><td style=\"text-align: right;\">  0.2644  </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_dff11bd4</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   44</td><td style=\"text-align: right;\">   24</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   27</td><td style=\"text-align: right;\">   54</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">0.000921064</td><td style=\"text-align: right;\">2.08501 </td><td style=\"text-align: right;\">  0.196575</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_e71f8756</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   54</td><td style=\"text-align: right;\">   21</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   54</td><td style=\"text-align: right;\">   16</td><td style=\"text-align: right;\">   55</td><td style=\"text-align: right;\">0.00232487 </td><td style=\"text-align: right;\">1.06093 </td><td style=\"text-align: right;\">  0.628075</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_f11cc5de</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   45</td><td style=\"text-align: right;\">   40</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   50</td><td style=\"text-align: right;\">    9</td><td style=\"text-align: right;\">   64</td><td style=\"text-align: right;\">0.000178959</td><td style=\"text-align: right;\">2.00729 </td><td style=\"text-align: right;\">  0.245575</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_f12be320</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">   54</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   13</td><td style=\"text-align: right;\">   16</td><td style=\"text-align: right;\">   40</td><td style=\"text-align: right;\">0.0493432  </td><td style=\"text-align: right;\">2.33431 </td><td style=\"text-align: right;\">  0.100525</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_0a95e4e6</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   74</td><td style=\"text-align: right;\">   67</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   61</td><td style=\"text-align: right;\">   20</td><td style=\"text-align: right;\">   19</td><td style=\"text-align: right;\">0.0317286  </td><td style=\"text-align: right;\">2.30793 </td><td style=\"text-align: right;\">  0.100025</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_0ff84c6c</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">    3</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   47</td><td style=\"text-align: right;\">   44</td><td style=\"text-align: right;\">   57</td><td style=\"text-align: right;\">0.00497565 </td><td style=\"text-align: right;\">1.44752 </td><td style=\"text-align: right;\">  0.4807  </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_104130bc</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">   15</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   34</td><td style=\"text-align: right;\">   35</td><td style=\"text-align: right;\">   44</td><td style=\"text-align: right;\">0.000749068</td><td style=\"text-align: right;\">1.60699 </td><td style=\"text-align: right;\">  0.414575</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_108e2a70</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   63</td><td style=\"text-align: right;\">   39</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   23</td><td style=\"text-align: right;\">   48</td><td style=\"text-align: right;\">   42</td><td style=\"text-align: right;\">0.00113727 </td><td style=\"text-align: right;\">0.859735</td><td style=\"text-align: right;\">  0.706925</td><td style=\"text-align: right;\">                  12</td></tr>\n",
       "<tr><td>DEFAULT_12056616</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">    6</td><td style=\"text-align: right;\">   63</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   28</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">   32</td><td style=\"text-align: right;\">0.00398826 </td><td style=\"text-align: right;\">2.18131 </td><td style=\"text-align: right;\">  0.19725 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_22636fe4</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">    3</td><td style=\"text-align: right;\">    6</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   42</td><td style=\"text-align: right;\">   12</td><td style=\"text-align: right;\">   20</td><td style=\"text-align: right;\">0.00727273 </td><td style=\"text-align: right;\">2.26189 </td><td style=\"text-align: right;\">  0.1358  </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_22d6fd1a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   40</td><td style=\"text-align: right;\">   75</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   11</td><td style=\"text-align: right;\">   59</td><td style=\"text-align: right;\">   35</td><td style=\"text-align: right;\">0.000530794</td><td style=\"text-align: right;\">2.0634  </td><td style=\"text-align: right;\">  0.213475</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_27ecdcfc</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   67</td><td style=\"text-align: right;\">   73</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   13</td><td style=\"text-align: right;\">   21</td><td style=\"text-align: right;\">   33</td><td style=\"text-align: right;\">0.0331588  </td><td style=\"text-align: right;\">2.31233 </td><td style=\"text-align: right;\">  0.09955 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_2fc40586</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   20</td><td style=\"text-align: right;\">   79</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">   15</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">0.030043   </td><td style=\"text-align: right;\">2.31007 </td><td style=\"text-align: right;\">  0.10115 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_34d064b6</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   71</td><td style=\"text-align: right;\">   79</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">   18</td><td style=\"text-align: right;\">   35</td><td style=\"text-align: right;\">0.000590848</td><td style=\"text-align: right;\">0.669382</td><td style=\"text-align: right;\">  0.76665 </td><td style=\"text-align: right;\">                  12</td></tr>\n",
       "<tr><td>DEFAULT_8c8e83b8</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">   80</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   59</td><td style=\"text-align: right;\">   11</td><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">0.000147786</td><td style=\"text-align: right;\">1.24912 </td><td style=\"text-align: right;\">  0.547325</td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>DEFAULT_9493693e</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   75</td><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">   54</td><td style=\"text-align: right;\">   62</td><td style=\"text-align: right;\">0.0311991  </td><td style=\"text-align: right;\">2.19732 </td><td style=\"text-align: right;\">  0.138775</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_9503cb52</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   75</td><td style=\"text-align: right;\">   35</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    9</td><td style=\"text-align: right;\">   32</td><td style=\"text-align: right;\">    6</td><td style=\"text-align: right;\">0.0626273  </td><td style=\"text-align: right;\">2.31544 </td><td style=\"text-align: right;\">  0.0997  </td><td style=\"text-align: right;\">                   5</td></tr>\n",
       "<tr><td>DEFAULT_a2b3e76e</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   51</td><td style=\"text-align: right;\">    6</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   16</td><td style=\"text-align: right;\">   26</td><td style=\"text-align: right;\">   28</td><td style=\"text-align: right;\">0.000299832</td><td style=\"text-align: right;\">1.46823 </td><td style=\"text-align: right;\">  0.4612  </td><td style=\"text-align: right;\">                   5</td></tr>\n",
       "<tr><td>DEFAULT_ad7fe9ae</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   20</td><td style=\"text-align: right;\">   72</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   59</td><td style=\"text-align: right;\">   37</td><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\">0.0252911  </td><td style=\"text-align: right;\">2.31281 </td><td style=\"text-align: right;\">  0.10035 </td><td style=\"text-align: right;\">                   5</td></tr>\n",
       "<tr><td>DEFAULT_ae316490</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   36</td><td style=\"text-align: right;\">   12</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   47</td><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\">   60</td><td style=\"text-align: right;\">0.00908895 </td><td style=\"text-align: right;\">1.14773 </td><td style=\"text-align: right;\">  0.609625</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_20eefb14</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   52</td><td style=\"text-align: right;\">   24</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   54</td><td style=\"text-align: right;\">   27</td><td style=\"text-align: right;\">   18</td><td style=\"text-align: right;\">0.00053167 </td><td style=\"text-align: right;\">0.806028</td><td style=\"text-align: right;\">  0.715975</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_38490f70</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">   32</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">0.00635167 </td><td style=\"text-align: right;\">0.84308 </td><td style=\"text-align: right;\">  0.7091  </td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_5fe46e44</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    9</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   13</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">0.00268283 </td><td style=\"text-align: right;\">0.97291 </td><td style=\"text-align: right;\">  0.65665 </td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_62f5ad32</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   32</td><td style=\"text-align: right;\">    9</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   59</td><td style=\"text-align: right;\">   18</td><td style=\"text-align: right;\">   58</td><td style=\"text-align: right;\">0.00671063 </td><td style=\"text-align: right;\">0.951966</td><td style=\"text-align: right;\">  0.66705 </td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_667ddb28</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   56</td><td style=\"text-align: right;\">   78</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   37</td><td style=\"text-align: right;\">   47</td><td style=\"text-align: right;\">   17</td><td style=\"text-align: right;\">0.0754174  </td><td style=\"text-align: right;\">2.3078  </td><td style=\"text-align: right;\">  0.10065 </td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_8327cfc2</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">   21</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   61</td><td style=\"text-align: right;\">   63</td><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\">0.00143656 </td><td style=\"text-align: right;\">0.864432</td><td style=\"text-align: right;\">  0.694025</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_47710e2a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   30</td><td style=\"text-align: right;\">    8</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   42</td><td style=\"text-align: right;\">   55</td><td style=\"text-align: right;\">   59</td><td style=\"text-align: right;\">0.00362154 </td><td style=\"text-align: right;\">0.951059</td><td style=\"text-align: right;\">  0.661825</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_55d4e40a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">   66</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">   59</td><td style=\"text-align: right;\">   53</td><td style=\"text-align: right;\">0.0010719  </td><td style=\"text-align: right;\">0.885036</td><td style=\"text-align: right;\">  0.686025</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_89953970</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   31</td><td style=\"text-align: right;\">   11</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   40</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">   63</td><td style=\"text-align: right;\">0.00205556 </td><td style=\"text-align: right;\">0.779461</td><td style=\"text-align: right;\">  0.723875</td><td style=\"text-align: right;\">                  20</td></tr>\n",
       "<tr><td>DEFAULT_8d5e591a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   78</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   32</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">   47</td><td style=\"text-align: right;\">0.000663896</td><td style=\"text-align: right;\">0.785714</td><td style=\"text-align: right;\">  0.72525 </td><td style=\"text-align: right;\">                  20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-08 00:01:24,617\tINFO tune.py:439 -- Total run time: 1558.01 seconds (1554.93 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'batch_size': 4, 'cv0': 44, 'cv1': 37, 'epochs': 30, 'fc0': 59, 'fc1': 16, 'fc2': 18, 'lr': 0.0007153381635252873}\n",
      "Best trial final validation loss: 0.6439739874005201\n",
      "Best trial final validation accuracy: 0.777375\n",
      "[44, 37]\n",
      "[59, 16, 18]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Best trial test set accuracy: 0.657\n",
      "\n",
      "Processed in 26.06845724185308 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layer_config_space = {}\n",
    "\n",
    "# for hp in [\"num_convs\",\"num_fcs\"]:\n",
    "#     layer_config_space[hp] = np.random.randint(2,2**3)\n",
    "# layer_config_space[\"num_convs\"] = np.random.randint(2,3)\n",
    "layer_config_space[\"num_convs\"] = 2\n",
    "layer_config_space[\"num_fcs\"] = np.random.randint(3,2**2)\n",
    "\n",
    "cpu_use = 1\n",
    "gpu_use = 0.25\n",
    "# data_dir = os.path.abspath(\"/home/grottesco/Source/RayTuneTut/data/\")\n",
    "# checkpoint_dir = os.path.abspath(\"/home/grottesco/Source/RayTuneTut/checkpoints\")\n",
    "print(\"Resource usage can be viewed at 127.0.0.1:8265\")\n",
    "start = time.time()\n",
    "model = search_neurons(layer_config_space)\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nProcessed in %s minutes\\n\" % ((end-start)/60,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!rm -rf ./data/* ./ray_results/layers/* ./ray_results/neurons/* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
