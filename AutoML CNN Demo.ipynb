{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial # for trials\n",
    "import numpy as np # for accuracy math\n",
    "import os # for paths\n",
    "import torch # for nn instantiation\n",
    "import torch.nn as nn # for nn objects\n",
    "import torch.nn.functional as F # for forward method\n",
    "import torch.optim as optim # for optimization\n",
    "from torch.utils.data import random_split # for train/test split\n",
    "import torchvision # for data transforms\n",
    "import torchvision.transforms as transforms # for transform methods\n",
    "from ray import tune # for trialing\n",
    "from ray.tune import CLIReporter # for trial reporting\n",
    "from ray.tune import JupyterNotebookReporter # for trial reporting\n",
    "from ray.tune.schedulers import ASHAScheduler # for trial scheduling\n",
    "from ray.tune.schedulers import HyperBandForBOHB # for trial scheduling\n",
    "from ray.tune.suggest.bohb import TuneBOHB # for trial selection/pruning\n",
    "import ConfigSpace as CS # for configuration bounds\n",
    "from collections import OrderedDict # for dynamic configuration definition\n",
    "from pathlib import Path # for OS agnostic path definition\n",
    "\n",
    "# import itertools package \n",
    "import itertools \n",
    "from itertools import permutations\n",
    "from itertools import product\n",
    "\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data and checkpoint locations\n",
    "p = Path('.')\n",
    "d = p / 'data'\n",
    "r = p / 'ray_results'\n",
    "l = p / 'checkpoints' / 'layers'\n",
    "n = p / 'checkpoints' / 'layers'\n",
    "\n",
    "## set number or fraction of GPUs (per training loop) you'd like to utilize, if any at all\n",
    "cpu_use = 1\n",
    "gpu_use = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#define feature space for hashing\n",
    "def feature_spacing():\n",
    "    conv = set(range(3**5)) - set(range(3**2))\n",
    "    full = set(range(2**5)) - set(range(2**2))\n",
    "    \n",
    "    c = 3**5 - 3**2\n",
    "    f = 2**5 - 2**2\n",
    "    \n",
    "    # create empty list to store the \n",
    "    # combinations \n",
    "    unique_combinations = []\n",
    "    total_uniques = 0\n",
    "    total_points = 1\n",
    "    \n",
    "    # do combo\n",
    "#     for combo in product(conv,conv,full):\n",
    "#         unique_combinations.append(combo)\n",
    "        \n",
    "#     for combo in product(conv,conv,full,full):\n",
    "#         unique_combinations.append(combo)\n",
    "        \n",
    "#     for combo in product(conv,conv,full,full,full):\n",
    "#         unique_combinations.append(combo)\n",
    "        \n",
    "#     for combo in product(conv,conv,full,full,full,full):\n",
    "#         unique_combinations.append(combo)\n",
    "\n",
    "    for ls in range(0,4):\n",
    "#         print(ls)\n",
    "        unique_combinations.append((c**2)*(f*(f+1)**ls))\n",
    "        total_uniques += (c**2)*f*((f+1)**ls)\n",
    "#         total_points = ((c**2)*f*((f+1)**ls))\n",
    "    \n",
    "    total_uniques -= ((c**2)*f)\n",
    "    total_points = total_uniques**2\n",
    "#     print(\"number of combos: %s\" % [\"%s-fc model: %s\" % (l,v) for l,v in enumerate(unique_combinations, 1)])\n",
    "#     print(\"total uniques:\",total_uniques)\n",
    "#     print(\"number of points/indices (with sparicities/noise): %s\" % total_points)\n",
    "#     print(\"\\n\")\n",
    "    \n",
    "    columns = [\"base\",\"nodes_req\",\"sparcity\",\"sparcity_pcnt\",\"denoise_pcnt\"]\n",
    "    values = [1,total_uniques,total_points - total_uniques,(total_points - total_uniques) / total_points,0]\n",
    "    results = {\n",
    "        \"base\": [1],\n",
    "        \"nodes_req\": [total_uniques],\n",
    "        \"sparcity\": [total_points - total_uniques],\n",
    "        \"sparcity_pcnt\": [(total_points - total_uniques) / total_points * 100],\n",
    "        \"denoise_pcnt\":[0]\n",
    "    }\n",
    "    \n",
    "    report = pd.DataFrame(results)\n",
    "    \n",
    "#     print(report.to_string())\n",
    "    \n",
    "    for base in range(2,11):\n",
    "        results[\"base\"] = [base]\n",
    "        results[\"nodes_req\"] = [math.ceil(math.log(total_uniques,(base)))]\n",
    "# #         print(\"number of base %s complex nodes required:\" % (base), math.ceil(math.log(total_uniques,(base))))\n",
    "#         print(\"number of base %s complex nodes required:\" % (base), results[\"nodes_req\"])\n",
    "        results[\"sparcity\"] = [base**math.ceil(math.log(total_uniques,base)) - total_uniques]\n",
    "# #         print(\"sparcity:\",base**math.ceil(math.log(total_uniques,base)) - total_uniques,'points')\n",
    "#         print(\"sparcity:\",results[\"sparcity\"],'points')\n",
    "        results[\"sparcity_pcnt\"] = [(base**math.ceil(math.log(total_uniques,(base))) - base**math.log(total_uniques,(base)))/(base**math.ceil(math.log(total_uniques,(base))))*100]\n",
    "# #         print(\"sparcity percentage:\",(base**math.ceil(math.log(total_uniques,(base))) - base**math.log(total_uniques,(base)))/(base**math.ceil(math.log(total_uniques,(base))))*100,'%')\n",
    "#         print(\"sparcity percentage:\",results[\"sparcity percentage\"],'%')\n",
    "#         print(\"%s root-%s nodes per layer\" % (math.ceil(math.log(total_uniques,base+1)),base+1))\n",
    "#         print(\"\\n\")\n",
    "        results[\"denoise_pcnt\"] = [math.floor(((total_points-(math.ceil(math.log(total_uniques,base)))**2)/total_points)*100)]\n",
    "# #         print(\"noise reduced from total points:\",math.floor(((total_points-(math.ceil(math.log(total_uniques,base)))**2)/total_points)*100),'%')\n",
    "#         print(\"noise reduced from total points:\",results[\"denoise_pcnt\"],'%')\n",
    "    \n",
    "        report = report.append(pd.DataFrame(results))\n",
    "#     for root in range(1,8):\n",
    "#         print(\"ceilinged %s-root (%s-value per number component) of combos with complex numbers: %s\\n\" % (root*2, root+1, [[math.ceil(combo**(1/(root*2))),\"sparsity: %s%s\" % ((math.ceil(combo**(1/(root*2))) - combo**(1/(root*2)))/combo**(1/(root*2))*100,'%')] for combo in unique_combinations]))\n",
    "    \n",
    "    print(report.sort_values([\"sparcity_pcnt\",\"nodes_req\",\"base\"]).to_string())\n",
    "#     report.head()\n",
    "    \n",
    "#     print(len(product(conv,conv,full)))\n",
    "#     print(f1)\n",
    "feature_spacing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base = 8\n",
    "c = 3**5 - 3**2\n",
    "f = 2**5 - 2**2\n",
    "def decode(code=None):\n",
    "    conv = []\n",
    "    full = []\n",
    "    \n",
    "    print(math.ceil(math.log(c,base)))\n",
    "    print(base**math.ceil(math.log(c,base)) - c)\n",
    "    print(math.ceil(math.log(f,base)))\n",
    "    print(base**math.ceil(math.log(f,base)) - f)\n",
    "    \n",
    "    model = [conv,full]\n",
    "#     return model\n",
    "    print()\n",
    "    \n",
    "decode()\n",
    "[print(math.log(278,b)) for b in range(2,9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# math.sqrt(3**5)\n",
    "poss = ((2**5 - 2**2)+1)**3\n",
    "print(\"%s possibilities\" % poss)\n",
    "[print(\"%s root-%s nodes per layer\" % (math.ceil(math.log(poss,root)),root)) for root in range(2,5)]\n",
    "[print(\"%s root-%s nodes per layer\" % (math.log(poss,root),root)) for root in range(2,5)]\n",
    "# print(math.ceil(poss**(1/2)))\n",
    "# print(math.log(poss,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2**5 - 2**2)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = ['1', '2', '3']\n",
    "b = ['1', '2', '3']\n",
    "c = ['1', '2', '3']\n",
    "d = ['1', '2', '3']\n",
    "\n",
    "# for r in product(product(a, b, d),c): print(r)\n",
    "r = [comb for comb in product(a, b, d)]\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move data into sets for loading\n",
    "def load_data(data_dir=d.absolute()):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset,testset = [torchvision.datasets.CIFAR10(root=data_dir, train=is_train, download=True, transform=transform) for is_train in [True,False]]\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamically-generated nn that takes a 3-channel image and outputs a label\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_layers=[[6, 16],[120,84]]):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_convs,hidden_fcs = hidden_layers\n",
    "        print(hidden_convs)\n",
    "        print(hidden_fcs)\n",
    "        uf_input = 0\n",
    "        layer_list = OrderedDict()\n",
    "        \n",
    "        layer_list['conv1'] = nn.Conv2d(3, hidden_convs[0], 5)\n",
    "        layer_list['pool1'] = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        layer_input = layer_list['conv1'].out_channels\n",
    "        \n",
    "        for layer_num, channels in enumerate(hidden_convs[1:], 2):\n",
    "            layer_list[\"conv%s\" % layer_num]  = nn.Conv2d(layer_input, channels, 5)\n",
    "            layer_list[\"pool%s\" % layer_num] = nn.MaxPool2d(2, 2)\n",
    "            layer_input = layer_list[\"conv%s\" % layer_num].out_channels\n",
    "        \n",
    "        \n",
    "        layer_list[\"flat\"] = nn.Flatten()\n",
    "        \n",
    "        layer_list['fc1'] = nn.Linear(layer_input*5*5, hidden_fcs[0])\n",
    "        layer_list[\"relu1\"]  = nn.ReLU()\n",
    "        \n",
    "        layer_input = layer_list['fc1'].out_features\n",
    "        for (layer_num, features) in enumerate(hidden_fcs[1:], 2):\n",
    "            layer_list[\"fc%s\" % layer_num]  = nn.Linear(layer_input, features)\n",
    "            layer_list[\"relu%s\" % layer_num]  = nn.ReLU()\n",
    "            layer_input = layer_list[\"fc%s\" % layer_num].out_features\n",
    "            \n",
    "        \n",
    "        layer_list['fco'] = nn.Linear(hidden_fcs[-1], 10)\n",
    "    \n",
    "        self.layers = nn.Sequential(layer_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train nn on data\n",
    "def train_cifar(neuron_config, checkpoint_dir=None):\n",
    "    \n",
    "    data_dir=d.absolute()\n",
    "    \n",
    "    def cv_discrim(s): return 'cv' in s\n",
    "    def fc_discrim(s): return 'fc' in s\n",
    "    cvs = [neuron_config[hp] for hp in list(filter(cv_discrim, neuron_config.keys()))]\n",
    "    fcs = [neuron_config[hp] for hp in list(filter(fc_discrim, neuron_config.keys()))]\n",
    "#     cvs = neuron_config[\"cvs\"]\n",
    "#     fcs = neuron_config[\"fcs\"]\n",
    "    \n",
    "    net = Net([cvs, fcs])\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=neuron_config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader,valloader = [torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(neuron_config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=2) for subset in [train_subset,val_subset]]\n",
    "\n",
    "    for epoch in range(neuron_config[\"epochs\"]):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=(correct / total))\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy score\n",
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine configuration boundary for nn based on number of layers\n",
    "def configure_neurons(num_convs,num_fcs):\n",
    "    config_space = CS.ConfigurationSpace()\n",
    "    \n",
    "    config_space.add_hyperparameter(\n",
    "        CS.UniformFloatHyperparameter(name=\"lr\", lower=1e-4, upper=1e-1, log=True))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"batch_size\", choices=[2**n for n in range(1,8)]))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(name=\"epochs\", choices=[10*n for n in range(2,11)]))\n",
    "    \n",
    "    for hidden in range(2):\n",
    "        config_space.add_hyperparameter(\n",
    "            CS.UniformIntegerHyperparameter(\"cv%s\" % hidden, lower=3, upper=3**4))\n",
    "    \n",
    "    for hidden in range(num_fcs):\n",
    "        config_space.add_hyperparameter(\n",
    "            CS.UniformIntegerHyperparameter(\"fc%s\" % hidden, lower=2**2, upper=2**6))\n",
    "        \n",
    "    return config_space\n",
    "\n",
    "# def configure_neurons():\n",
    "#     config_space = {\n",
    "#         \"batch_size_seed\": tune.randint(2, 6),\n",
    "#         \"cv_seed\": tune.grid_search([2]),\n",
    "#         \"fc_seed\": tune.randint(2, 4),\n",
    "        \n",
    "#         \"lr\": tune.loguniform(1e-4,1e-1),\n",
    "#         \"batch_size\": tune.sample_from(lambda spec: 2**spec.config.batch_size_seed),\n",
    "#         \"epochs\": tune.qrandint(20, 40, 10),\n",
    "        \n",
    "#         \"cvs\": tune.sample_from(lambda spec: [tune.randint(3, 3**4) for layer in range(spec.config.cv_seed)]),\n",
    "#         \"fcs\": tune.sample_from(lambda spec: [tune.randint(2**2, 2**4) for layer in range(spec.config.fc_seed)])        \n",
    "#     }\n",
    "        \n",
    "#     return config_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neuron_config_space = configure_neurons()\n",
    "print(neuron_config_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform neuron configuration trials\n",
    "def search_neurons(layer_config, checkpoint_dir=None):\n",
    "    num_samples=40\n",
    "    max_num_epochs=40\n",
    "    gpus_per_trial=1\n",
    "    \n",
    "#     print(layer_config)\n",
    "    \n",
    "    neuron_config_space = configure_neurons(layer_config[\"num_convs\"], layer_config[\"num_fcs\"])\n",
    "#     neuron_config_space = configure_neurons()\n",
    "\n",
    "    # prefill data directories\n",
    "    load_data()\n",
    "    \n",
    "    experiment_metrics = dict(metric=\"accuracy\", mode=\"max\")\n",
    "    \n",
    "    scheduler = HyperBandForBOHB(\n",
    "#         metric=\"loss\",\n",
    "#         mode=\"min\",\n",
    "        max_t=20,\n",
    "        reduction_factor=2,\n",
    "        **experiment_metrics)\n",
    "    search = TuneBOHB(\n",
    "        neuron_config_space,\n",
    "        max_concurrent=8,\n",
    "#         metric=\"loss\",\n",
    "#         mode=\"min\",\n",
    "        **experiment_metrics)\n",
    "    reporter = JupyterNotebookReporter(\n",
    "        overwrite=True,\n",
    "#         parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\", \"epochs\"],\n",
    "        parameter_columns=neuron_config_space.get_hyperparameter_names(),\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_cifar),\n",
    "        verbose=2,\n",
    "        name=\"neurons\",\n",
    "        local_dir=r.absolute(),\n",
    "        resources_per_trial={\"cpu\": cpu_use, \"gpu\": gpu_use},\n",
    "        max_failures=3,\n",
    "#         config=neuron_config_space,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    \n",
    "    def cv_discrim(s): return 'cv' in s\n",
    "    def fc_discrim(s): return 'fc' in s\n",
    "    best_cvs = [best_trial.config[hp] for hp in list(filter(cv_discrim, best_trial.config.keys()))]\n",
    "    best_fcs = [best_trial.config[hp] for hp in list(filter(fc_discrim, best_trial.config.keys()))]\n",
    "# #     best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
    "    \n",
    "#     best_trained_model = Net(best_trial.config[\"cvs\"], best_trial.config[\"fcs\"])\n",
    "    best_trained_model = Net([best_cvs, best_fcs])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    \n",
    "    if checkpoint_dir != None:\n",
    "        tune.report(accuracy=test_acc)\n",
    "    \n",
    "#     with tune.checkpoint_dir(\"nodes\") as checkpoint_dir:\n",
    "#         path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "#         torch.save(best_trained_model.state_dict(), path)\n",
    "    \n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "    \n",
    "    return best_trained_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform layer count trials\n",
    "def search_layers(num_samples=10, max_num_epochs=10, gpus_per_trial=0):\n",
    "    data_dir=d.absolute()\n",
    "    load_data(data_dir)\n",
    "    layer_config_space = CS.ConfigurationSpace()\n",
    "\n",
    "    layer_config_space.add_hyperparameter(\n",
    "        CS.Constant(\"num_convs\", value=2))\n",
    "    layer_config_space.add_hyperparameter(\n",
    "        CS.UniformIntegerHyperparameter(\"num_fcs\", lower=2, upper=2**2))\n",
    "    \n",
    "    experiment_metrics = dict(metric=\"accuracy\", mode=\"max\")\n",
    "    \n",
    "\n",
    "    scheduler = HyperBandForBOHB(\n",
    "        max_t=max_num_epochs,\n",
    "        reduction_factor=2,\n",
    "        **experiment_metrics)\n",
    "    search = TuneBOHB(\n",
    "        layer_config_space,\n",
    "        max_concurrent=4,\n",
    "        **experiment_metrics)\n",
    "    reporter = CLIReporter(\n",
    "#         overwrite=True,\n",
    "        parameter_columns=layer_config_space.get_hyperparameter_names(),\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(search_neurons),\n",
    "        verbose=2,\n",
    "        name=\"layers\",\n",
    "        local_dir=r.absolute(),\n",
    "#         config=layer_config_space,\n",
    "        resources_per_trial={\"gpu\": gpus_per_trial},\n",
    "        max_failures=3,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = Net([best_trial.config[\"num_convs\"], best_trial.config[\"num_fcs\"]])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"),map_location=torch.device('cpu'))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "    \n",
    "    return best_trained_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform test\n",
    "model = Net()\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    model = search_layers(num_samples=10, max_num_epochs=10, gpus_per_trial=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource usage can be viewed at port 127.0.0.1:8265 or higher\n"
     ]
    }
   ],
   "source": [
    "print(\"Resource usage can be viewed at port 127.0.0.1:8265 or higher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.9/31.3 GiB<br>Using HyperBand: num_stopped=30 total_brackets=5\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=1, Milestone (r)=12, completed=100.0%): {TERMINATED: 16} \n",
       "  Bracket(Max Size (n)=2, Milestone (r)=12, completed=100.0%): {TERMINATED: 10} \n",
       "  Bracket(Max Size (n)=2, Milestone (r)=10, completed=100.0%): {TERMINATED: 7} \n",
       "  Bracket(Max Size (n)=3, Milestone (r)=10, completed=100.0%): {TERMINATED: 5} \n",
       "  Bracket(Max Size (n)=5, Milestone (r)=20, completed=100.0%): {TERMINATED: 2} <br>Resources requested: 0/8 CPUs, 0.0/2 GPUs, 0.0/17.09 GiB heap, 0.0/5.91 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /home/grottesco/Source/CIFAR-Trainer/ray_results/neurons<br>Number of trials: 40/40 (40 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  cv0</th><th style=\"text-align: right;\">  cv1</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  fc0</th><th style=\"text-align: right;\">  fc1</th><th style=\"text-align: right;\">  fc2</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">      loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DEFAULT_cc3d04b6</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">   21</td><td style=\"text-align: right;\">   52</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">0.000306276</td><td style=\"text-align: right;\">  2.29716 </td><td style=\"text-align: right;\">  0.119425</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_cc429d36</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">   50</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">   59</td><td style=\"text-align: right;\">   11</td><td style=\"text-align: right;\">0.00114468 </td><td style=\"text-align: right;\">  2.28035 </td><td style=\"text-align: right;\">  0.1449  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_cc43f1fe</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\">   34</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   18</td><td style=\"text-align: right;\">   13</td><td style=\"text-align: right;\">   15</td><td style=\"text-align: right;\">0.000244298</td><td style=\"text-align: right;\">  2.3017  </td><td style=\"text-align: right;\">  0.116575</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_cc450968</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   51</td><td style=\"text-align: right;\">   77</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   60</td><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">   57</td><td style=\"text-align: right;\">0.000846561</td><td style=\"text-align: right;\">  0.478983</td><td style=\"text-align: right;\">  0.834825</td><td style=\"text-align: right;\">                  12</td></tr>\n",
       "<tr><td>DEFAULT_cc46bba0</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   36</td><td style=\"text-align: right;\">    3</td><td style=\"text-align: right;\">      70</td><td style=\"text-align: right;\">   22</td><td style=\"text-align: right;\">   26</td><td style=\"text-align: right;\">   43</td><td style=\"text-align: right;\">0.00309518 </td><td style=\"text-align: right;\">  1.55878 </td><td style=\"text-align: right;\">  0.433175</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_cc4c2e3c</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   27</td><td style=\"text-align: right;\">   51</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">   22</td><td style=\"text-align: right;\">   53</td><td style=\"text-align: right;\">   39</td><td style=\"text-align: right;\">0.00192583 </td><td style=\"text-align: right;\">  0.960394</td><td style=\"text-align: right;\">  0.667275</td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>DEFAULT_cc509b20</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   71</td><td style=\"text-align: right;\">   63</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   58</td><td style=\"text-align: right;\">   62</td><td style=\"text-align: right;\">   59</td><td style=\"text-align: right;\">0.00147225 </td><td style=\"text-align: right;\">  1.50838 </td><td style=\"text-align: right;\">  0.447425</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_cc553356</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   67</td><td style=\"text-align: right;\">   80</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">   62</td><td style=\"text-align: right;\">   35</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">0.00784678 </td><td style=\"text-align: right;\">  2.31574 </td><td style=\"text-align: right;\">  0.0986  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_e0282b36</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   12</td><td style=\"text-align: right;\">   36</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   48</td><td style=\"text-align: right;\">   27</td><td style=\"text-align: right;\">   62</td><td style=\"text-align: right;\">0.0003928  </td><td style=\"text-align: right;\">  2.22213 </td><td style=\"text-align: right;\">  0.156275</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_e49a130a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   67</td><td style=\"text-align: right;\">   22</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   34</td><td style=\"text-align: right;\">   43</td><td style=\"text-align: right;\">   57</td><td style=\"text-align: right;\">0.0106555  </td><td style=\"text-align: right;\">  1.42692 </td><td style=\"text-align: right;\">  0.52525 </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_e4b25762</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   14</td><td style=\"text-align: right;\">   51</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   39</td><td style=\"text-align: right;\">   43</td><td style=\"text-align: right;\">   53</td><td style=\"text-align: right;\">0.0136802  </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">  0.099125</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_e5a46c00</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   39</td><td style=\"text-align: right;\">   70</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   10</td><td style=\"text-align: right;\">   61</td><td style=\"text-align: right;\">   53</td><td style=\"text-align: right;\">0.0466021  </td><td style=\"text-align: right;\">  2.31153 </td><td style=\"text-align: right;\">  0.10115 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_011caaec</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   50</td><td style=\"text-align: right;\">   59</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   10</td><td style=\"text-align: right;\">   44</td><td style=\"text-align: right;\">    6</td><td style=\"text-align: right;\">0.0085594  </td><td style=\"text-align: right;\">  1.48144 </td><td style=\"text-align: right;\">  0.467975</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_05fb9582</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   20</td><td style=\"text-align: right;\">    5</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">   32</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">   37</td><td style=\"text-align: right;\">0.0341667  </td><td style=\"text-align: right;\">  2.4841  </td><td style=\"text-align: right;\">  0.09895 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_061576aa</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   12</td><td style=\"text-align: right;\">   13</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">   23</td><td style=\"text-align: right;\">   24</td><td style=\"text-align: right;\">0.0524245  </td><td style=\"text-align: right;\">  2.30756 </td><td style=\"text-align: right;\">  0.099875</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_0d78eb5c</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">   55</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">   54</td><td style=\"text-align: right;\">   14</td><td style=\"text-align: right;\">0.00101709 </td><td style=\"text-align: right;\">  1.14312 </td><td style=\"text-align: right;\">  0.590375</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_0f206f2a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">   27</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   34</td><td style=\"text-align: right;\">   32</td><td style=\"text-align: right;\">   40</td><td style=\"text-align: right;\">0.0545099  </td><td style=\"text-align: right;\">  1.20254 </td><td style=\"text-align: right;\">  0.59035 </td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_1ae308fe</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">   53</td><td style=\"text-align: right;\">   53</td><td style=\"text-align: right;\">      90</td><td style=\"text-align: right;\">   50</td><td style=\"text-align: right;\">   33</td><td style=\"text-align: right;\">   14</td><td style=\"text-align: right;\">0.00911346 </td><td style=\"text-align: right;\">  0.623251</td><td style=\"text-align: right;\">  0.7869  </td><td style=\"text-align: right;\">                  12</td></tr>\n",
       "<tr><td>DEFAULT_26cb1102</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   67</td><td style=\"text-align: right;\">    3</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">   37</td><td style=\"text-align: right;\">   17</td><td style=\"text-align: right;\">   47</td><td style=\"text-align: right;\">0.00464934 </td><td style=\"text-align: right;\">  2.30639 </td><td style=\"text-align: right;\">  0.099375</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_2b20349e</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   25</td><td style=\"text-align: right;\">   73</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">   35</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">   55</td><td style=\"text-align: right;\">0.000151311</td><td style=\"text-align: right;\">  2.2922  </td><td style=\"text-align: right;\">  0.163675</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_2ce538a6</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   64</td><td style=\"text-align: right;\">   11</td><td style=\"text-align: right;\">      60</td><td style=\"text-align: right;\">   53</td><td style=\"text-align: right;\">   23</td><td style=\"text-align: right;\">   64</td><td style=\"text-align: right;\">0.0728979  </td><td style=\"text-align: right;\">  2.30683 </td><td style=\"text-align: right;\">  0.099925</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_34e7a386</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   52</td><td style=\"text-align: right;\">    3</td><td style=\"text-align: right;\">      90</td><td style=\"text-align: right;\">   37</td><td style=\"text-align: right;\">   45</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">0.0994009  </td><td style=\"text-align: right;\">  2.30689 </td><td style=\"text-align: right;\">  0.10055 </td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_398c49c8</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">   28</td><td style=\"text-align: right;\">   34</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">   27</td><td style=\"text-align: right;\">   15</td><td style=\"text-align: right;\">0.0158078  </td><td style=\"text-align: right;\">  0.847873</td><td style=\"text-align: right;\">  0.714475</td><td style=\"text-align: right;\">                   8</td></tr>\n",
       "<tr><td>DEFAULT_55ec4e2e</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   70</td><td style=\"text-align: right;\">   62</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">   44</td><td style=\"text-align: right;\">   42</td><td style=\"text-align: right;\">   47</td><td style=\"text-align: right;\">0.00658086 </td><td style=\"text-align: right;\">  0.594189</td><td style=\"text-align: right;\">  0.797975</td><td style=\"text-align: right;\">                  12</td></tr>\n",
       "<tr><td>DEFAULT_5643c2f8</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   17</td><td style=\"text-align: right;\">   57</td><td style=\"text-align: right;\">      70</td><td style=\"text-align: right;\">    8</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">   18</td><td style=\"text-align: right;\">0.00523323 </td><td style=\"text-align: right;\">  1.61806 </td><td style=\"text-align: right;\">  0.445625</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_57816652</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   42</td><td style=\"text-align: right;\">   79</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">    9</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">   40</td><td style=\"text-align: right;\">0.0038049  </td><td style=\"text-align: right;\">  2.31046 </td><td style=\"text-align: right;\">  0.098775</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "<tr><td>DEFAULT_591df264</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">   61</td><td style=\"text-align: right;\">   18</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">   62</td><td style=\"text-align: right;\">   64</td><td style=\"text-align: right;\">0.0987921  </td><td style=\"text-align: right;\">  2.30401 </td><td style=\"text-align: right;\">  0.10085 </td><td style=\"text-align: right;\">                   5</td></tr>\n",
       "<tr><td>DEFAULT_5d5b0164</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   32</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">      90</td><td style=\"text-align: right;\">    6</td><td style=\"text-align: right;\">   17</td><td style=\"text-align: right;\">   26</td><td style=\"text-align: right;\">0.000473934</td><td style=\"text-align: right;\">  1.19553 </td><td style=\"text-align: right;\">  0.565525</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_6e3ea76a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">   16</td><td style=\"text-align: right;\">   40</td><td style=\"text-align: right;\">      60</td><td style=\"text-align: right;\">   15</td><td style=\"text-align: right;\">   24</td><td style=\"text-align: right;\">   31</td><td style=\"text-align: right;\">0.0129762  </td><td style=\"text-align: right;\">  0.958314</td><td style=\"text-align: right;\">  0.66655 </td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_7f908a6a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">   61</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">   37</td><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">   34</td><td style=\"text-align: right;\">0.00849273 </td><td style=\"text-align: right;\">  0.809411</td><td style=\"text-align: right;\">  0.71965 </td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_93ccfe0a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   70</td><td style=\"text-align: right;\">    6</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">    9</td><td style=\"text-align: right;\">   11</td><td style=\"text-align: right;\">0.0333588  </td><td style=\"text-align: right;\">  2.30687 </td><td style=\"text-align: right;\">  0.100425</td><td style=\"text-align: right;\">                   5</td></tr>\n",
       "<tr><td>DEFAULT_b111f9c0</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   18</td><td style=\"text-align: right;\">   16</td><td style=\"text-align: right;\">      70</td><td style=\"text-align: right;\">   37</td><td style=\"text-align: right;\">   48</td><td style=\"text-align: right;\">   20</td><td style=\"text-align: right;\">0.000825751</td><td style=\"text-align: right;\">  1.03738 </td><td style=\"text-align: right;\">  0.646475</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_d3fc7172</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   73</td><td style=\"text-align: right;\">   51</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">   33</td><td style=\"text-align: right;\">   52</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">0.000281255</td><td style=\"text-align: right;\">  1.79647 </td><td style=\"text-align: right;\">  0.335575</td><td style=\"text-align: right;\">                   5</td></tr>\n",
       "<tr><td>DEFAULT_191f2c40</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   46</td><td style=\"text-align: right;\">   50</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">   16</td><td style=\"text-align: right;\">   40</td><td style=\"text-align: right;\">   53</td><td style=\"text-align: right;\">0.0168659  </td><td style=\"text-align: right;\">  2.30528 </td><td style=\"text-align: right;\">  0.10025 </td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_1d48bf0c</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   22</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">   37</td><td style=\"text-align: right;\">   64</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">0.0959432  </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">  0.09885 </td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_202aedda</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   37</td><td style=\"text-align: right;\">   70</td><td style=\"text-align: right;\">      60</td><td style=\"text-align: right;\">   28</td><td style=\"text-align: right;\">   11</td><td style=\"text-align: right;\">   26</td><td style=\"text-align: right;\">0.00247958 </td><td style=\"text-align: right;\">  2.30355 </td><td style=\"text-align: right;\">  0.100825</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_25a3efe6</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">   35</td><td style=\"text-align: right;\">   54</td><td style=\"text-align: right;\">      70</td><td style=\"text-align: right;\">   50</td><td style=\"text-align: right;\">   13</td><td style=\"text-align: right;\">   23</td><td style=\"text-align: right;\">0.0528016  </td><td style=\"text-align: right;\">  2.30533 </td><td style=\"text-align: right;\">  0.100025</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_bd87e29a</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   73</td><td style=\"text-align: right;\">   48</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">   26</td><td style=\"text-align: right;\">   56</td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">0.000379396</td><td style=\"text-align: right;\">  0.867497</td><td style=\"text-align: right;\">  0.691475</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "<tr><td>DEFAULT_c62941d2</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">   33</td><td style=\"text-align: right;\">   33</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">   39</td><td style=\"text-align: right;\">   53</td><td style=\"text-align: right;\">   39</td><td style=\"text-align: right;\">0.000344965</td><td style=\"text-align: right;\">  1.09408 </td><td style=\"text-align: right;\">  0.612175</td><td style=\"text-align: right;\">                  20</td></tr>\n",
       "<tr><td>DEFAULT_cfffd89c</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   61</td><td style=\"text-align: right;\">   36</td><td style=\"text-align: right;\">      60</td><td style=\"text-align: right;\">   17</td><td style=\"text-align: right;\">   27</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">0.0851353  </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">  0.0991  </td><td style=\"text-align: right;\">                  20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-20 10:07:49,801\tINFO tune.py:439 -- Total run time: 2289.83 seconds (2288.02 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'batch_size': 8, 'cv0': 51, 'cv1': 77, 'epochs': 40, 'fc0': 60, 'fc1': 49, 'fc2': 57, 'lr': 0.0008465611924609796}\n",
      "Best trial final validation loss: 0.47898316129520535\n",
      "Best trial final validation accuracy: 0.834825\n",
      "[51, 77]\n",
      "[60, 49, 57]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Best trial test set accuracy: 0.6628\n",
      "\n",
      "Processed in 38.335658899943034 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layer_config_space = {}\n",
    "\n",
    "# for hp in [\"num_convs\",\"num_fcs\"]:\n",
    "#     layer_config_space[hp] = np.random.randint(2,2**3)\n",
    "# layer_config_space[\"num_convs\"] = np.random.randint(2,3)\n",
    "layer_config_space[\"num_convs\"] = 2\n",
    "layer_config_space[\"num_fcs\"] = np.random.randint(3,2**2)\n",
    "\n",
    "# cpu_use = 1\n",
    "# gpu_use = 0.25\n",
    "# data_dir = os.path.abspath(\"/home/grottesco/Source/RayTuneTut/data/\")\n",
    "# checkpoint_dir = os.path.abspath(\"/home/grottesco/Source/RayTuneTut/checkpoints\")\n",
    "start = time.time()\n",
    "model = search_neurons(layer_config_space)\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nProcessed in %s minutes\\n\" % ((end-start)/60,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!rm -rf ./data/* ./ray_results/layers/* ./ray_results/neurons/* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
